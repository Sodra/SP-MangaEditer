<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1"><title>WebGPU Color Eraser</title><style>#canvasContainer{display:flex;justify-content:space-around;flex-wrap:wrap}canvas{border:1px solid #000;margin:10px}</style></head><body><input type="file" id="imageInput" accept="image/*"><div id="canvasContainer"><canvas id="originalCanvas"></canvas><canvas id="processedCanvas"></canvas></div><script type="module">const originalCanvas=document.getElementById("originalCanvas"),processedCanvas=document.getElementById("processedCanvas"),imageInput=document.getElementById("imageInput");let device,originalTexture,processedTexture,sampler,pipeline,bindGroup,uniformBuffer,imageWidth,imageHeight;const MAX_CANVAS_SIZE=800;async function initWebGPU(){if(!navigator.gpu)throw new Error("WebGPU not supported on this browser.");const e=await navigator.gpu.requestAdapter();if(!e)throw new Error("No appropriate GPUAdapter found.");device=await e.requestDevice();const t=device.createShaderModule({code:"\n                    struct Uniforms {\n                        selectedColor : vec4f,\n                        tolerance : f32,\n                    }\n                    @binding(0) @group(0) var<uniform> uniforms : Uniforms;\n                    @binding(1) @group(0) var inputTexture: texture_2d<f32>;\n                    @binding(2) @group(0) var inputSampler: sampler;\n\n                    struct VertexOutput {\n                        @builtin(position) position: vec4f,\n                        @location(0) texCoord: vec2f,\n                    }\n\n                    @vertex\n                    fn vertexMain(@builtin(vertex_index) vertexIndex: u32) -> VertexOutput {\n                        var pos = array<vec2f, 6>(\n                            vec2f(-1.0, -1.0),\n                            vec2f(1.0, -1.0),\n                            vec2f(1.0, 1.0),\n                            vec2f(-1.0, -1.0),\n                            vec2f(1.0, 1.0),\n                            vec2f(-1.0, 1.0)\n                        );\n                        var texCoord = array<vec2f, 6>(\n                            vec2f(0.0, 1.0),\n                            vec2f(1.0, 1.0),\n                            vec2f(1.0, 0.0),\n                            vec2f(0.0, 1.0),\n                            vec2f(1.0, 0.0),\n                            vec2f(0.0, 0.0)\n                        );\n                        var output: VertexOutput;\n                        output.position = vec4f(pos[vertexIndex], 0.0, 1.0);\n                        output.texCoord = texCoord[vertexIndex];\n                        return output;\n                    }\n\n                    @fragment\n                    fn fragmentMain(@location(0) texCoord: vec2f) -> @location(0) vec4f {\n                        let color = textureSample(inputTexture, inputSampler, texCoord);\n                        let diff = abs(color - uniforms.selectedColor);\n                        let maxDiff = max(max(diff.r, diff.g), diff.b);\n                        if (maxDiff <= uniforms.tolerance) {\n                            return vec4f(0.0, 0.0, 0.0, 0.0);\n                        }\n                        return color;\n                    }\n                "}),i=device.createBindGroupLayout({entries:[{binding:0,visibility:GPUShaderStage.FRAGMENT,buffer:{type:"uniform"}},{binding:1,visibility:GPUShaderStage.FRAGMENT,texture:{}},{binding:2,visibility:GPUShaderStage.FRAGMENT,sampler:{}}]});pipeline=device.createRenderPipeline({layout:device.createPipelineLayout({bindGroupLayouts:[i]}),vertex:{module:t,entryPoint:"vertexMain"},fragment:{module:t,entryPoint:"fragmentMain",targets:[{format:"bgra8unorm"}]},primitive:{topology:"triangle-list"}}),sampler=device.createSampler({magFilter:"linear",minFilter:"linear"}),uniformBuffer=device.createBuffer({size:32,usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST})}function calculateAspectRatioFit(e,t,i,n){const r=Math.min(i/e,n/t);return{width:e*r,height:t*r}}async function loadImage(e){const t=await createImageBitmap(e),{width:i,height:n}=calculateAspectRatioFit(t.width,t.height,800,800);imageWidth=Math.floor(i),imageHeight=Math.floor(n),originalCanvas.width=processedCanvas.width=imageWidth,originalCanvas.height=processedCanvas.height=imageHeight;originalCanvas.getContext("2d").drawImage(t,0,0,imageWidth,imageHeight);processedCanvas.getContext("2d").drawImage(t,0,0,imageWidth,imageHeight),originalTexture=device.createTexture({size:[imageWidth,imageHeight],format:"bgra8unorm",usage:GPUTextureUsage.TEXTURE_BINDING|GPUTextureUsage.COPY_DST|GPUTextureUsage.RENDER_ATTACHMENT}),device.queue.copyExternalImageToTexture({source:originalCanvas},{texture:originalTexture},[imageWidth,imageHeight]),processedTexture=device.createTexture({size:[imageWidth,imageHeight],format:"bgra8unorm",usage:GPUTextureUsage.RENDER_ATTACHMENT|GPUTextureUsage.COPY_SRC}),bindGroup=device.createBindGroup({layout:pipeline.getBindGroupLayout(0),entries:[{binding:0,resource:{buffer:uniformBuffer}},{binding:1,resource:originalTexture.createView()},{binding:2,resource:sampler}]}),render()}function render(e=-1,t=-1){const i=device.createCommandEncoder(),n=i.beginRenderPass({colorAttachments:[{view:processedTexture.createView(),loadOp:"clear",storeOp:"store"}]});if(n.setPipeline(pipeline),n.setBindGroup(0,bindGroup),-1!==e&&-1!==t){const i=originalCanvas.getContext("2d").getImageData(e,t,1,1),[n,r,a]=i.data,o=new Float32Array([n/255,r/255,a/255,1]),u=.1;device.queue.writeBuffer(uniformBuffer,0,o),device.queue.writeBuffer(uniformBuffer,16,new Float32Array([u]))}n.draw(6),n.end(),device.queue.submit([i.finish()]),copyTextureToCanvas(processedTexture,processedCanvas)}function copyTextureToCanvas(e,t){const i=256*Math.ceil(4*imageWidth/256),n=i*imageHeight,r=device.createBuffer({size:n,usage:GPUBufferUsage.COPY_DST|GPUBufferUsage.MAP_READ}),a=device.createCommandEncoder();a.copyTextureToBuffer({texture:e},{buffer:r,bytesPerRow:i},[imageWidth,imageHeight]),device.queue.submit([a.finish()]),r.mapAsync(GPUMapMode.READ).then((()=>{const e=r.getMappedRange(),n=new Uint8ClampedArray(e),a=new ImageData(imageWidth,imageHeight);for(let e=0;e<imageHeight;e++){const t=e*i;for(let i=0;i<imageWidth;i++){const r=t+4*i,o=4*(e*imageWidth+i);a.data[o]=n[r+2],a.data[o+1]=n[r+1],a.data[o+2]=n[r],a.data[o+3]=n[r+3]}}t.getContext("2d").putImageData(a,0,0),r.unmap()}))}imageInput.addEventListener("change",(e=>{e.target.files&&e.target.files[0]&&loadImage(e.target.files[0])})),originalCanvas.addEventListener("click",(e=>{const t=originalCanvas.getBoundingClientRect();render(e.clientX-t.left,e.clientY-t.top)})),initWebGPU().catch(console.error)</script></body></html>