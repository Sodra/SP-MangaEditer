const defaultObjectInfo = {
  KSampler: {
    input: {
      required: {
        model: [
          "MODEL",
          { tooltip: "The model used for denoising the input latent." },
        ],
        seed: [
          "INT",
          {
            default: 0,
            min: 0,
            max: 18446744073709551615,
            tooltip: "The random seed used for creating the noise.",
          },
        ],
        steps: [
          "INT",
          {
            default: 20,
            min: 1,
            max: 10000,
            tooltip: "The number of steps used in the denoising process.",
          },
        ],
        cfg: [
          "FLOAT",
          {
            default: 8.0,
            min: 0.0,
            max: 100.0,
            step: 0.1,
            round: 0.01,
            tooltip:
              "The Classifier-Free Guidance scale balances creativity and adherence to the prompt. Higher values result in images more closely matching the prompt however too high values will negatively impact quality.",
          },
        ],
        sampler_name: [
          [
            "euler",
            "euler_cfg_pp",
            "euler_ancestral",
            "euler_ancestral_cfg_pp",
            "heun",
            "heunpp2",
            "dpm_2",
            "dpm_2_ancestral",
            "lms",
            "dpm_fast",
            "dpm_adaptive",
            "dpmpp_2s_ancestral",
            "dpmpp_2s_ancestral_cfg_pp",
            "dpmpp_sde",
            "dpmpp_sde_gpu",
            "dpmpp_2m",
            "dpmpp_2m_cfg_pp",
            "dpmpp_2m_sde",
            "dpmpp_2m_sde_gpu",
            "dpmpp_3m_sde",
            "dpmpp_3m_sde_gpu",
            "ddpm",
            "lcm",
            "ipndm",
            "ipndm_v",
            "deis",
            "ddim",
            "uni_pc",
            "uni_pc_bh2",
          ],
          {
            tooltip:
              "The algorithm used when sampling, this can affect the quality, speed, and style of the generated output.",
          },
        ],
        scheduler: [
          [
            "normal",
            "karras",
            "exponential",
            "sgm_uniform",
            "simple",
            "ddim_uniform",
            "beta",
          ],
          {
            tooltip:
              "The scheduler controls how noise is gradually removed to form the image.",
          },
        ],
        positive: [
          "CONDITIONING",
          {
            tooltip:
              "The conditioning describing the attributes you want to include in the image.",
          },
        ],
        negative: [
          "CONDITIONING",
          {
            tooltip:
              "The conditioning describing the attributes you want to exclude from the image.",
          },
        ],
        latent_image: ["LATENT", { tooltip: "The latent image to denoise." }],
        denoise: [
          "FLOAT",
          {
            default: 1.0,
            min: 0.0,
            max: 1.0,
            step: 0.01,
            tooltip:
              "The amount of denoising applied, lower values will maintain the structure of the initial image allowing for image to image sampling.",
          },
        ],
      },
    },
    input_order: {
      required: [
        "model",
        "seed",
        "steps",
        "cfg",
        "sampler_name",
        "scheduler",
        "positive",
        "negative",
        "latent_image",
        "denoise",
      ],
    },
    output: ["LATENT"],
    output_is_list: [false],
    output_name: ["LATENT"],
    name: "KSampler",
    display_name: "KSampler",
    description:
      "Uses the provided model, positive and negative conditioning to denoise the latent image.",
    python_module: "nodes",
    category: "sampling",
    output_node: false,
    output_tooltips: ["The denoised latent."],
  },
  CheckpointLoaderSimple: {
    input: {
      required: {
        ckpt_name: [
          [
            "Pony\\boleromixPony_v141VAE.safetensors",
            "Pony\\boleromixSDXL_v13.safetensors",
            "XL\\real_sdxl10ArienmixxlAsian_v40Pruned.safetensors",
            "XL\\real_xxmix9realisticsdxl_v10.safetensors",
            "animatBackgroundV1_03.safetensors",
            "sd_xl_base_1.0_0.9vae.safetensors",
          ],
          { tooltip: "The name of the checkpoint (model) to load." },
        ],
      },
    },
    input_order: { required: ["ckpt_name"] },
    output: ["MODEL", "CLIP", "VAE"],
    output_is_list: [false, false, false],
    output_name: ["MODEL", "CLIP", "VAE"],
    name: "CheckpointLoaderSimple",
    display_name: "Load Checkpoint",
    description:
      "Loads a diffusion model checkpoint, diffusion models are used to denoise latents.",
    python_module: "nodes",
    category: "loaders",
    output_node: false,
    output_tooltips: [
      "The model used for denoising latents.",
      "The CLIP model used for encoding text prompts.",
      "The VAE model used for encoding and decoding images to and from latent space.",
    ],
  },
  CLIPTextEncode: {
    input: {
      required: {
        text: [
          "STRING",
          {
            multiline: true,
            dynamicPrompts: true,
            tooltip: "The text to be encoded.",
          },
        ],
        clip: [
          "CLIP",
          { tooltip: "The CLIP model used for encoding the text." },
        ],
      },
    },
    input_order: { required: ["text", "clip"] },
    output: ["CONDITIONING"],
    output_is_list: [false],
    output_name: ["CONDITIONING"],
    name: "CLIPTextEncode",
    display_name: "CLIP Text Encode (Prompt)",
    description:
      "Encodes a text prompt using a CLIP model into an embedding that can be used to guide the diffusion model towards generating specific images.",
    python_module: "nodes",
    category: "conditioning",
    output_node: false,
    output_tooltips: [
      "A conditioning containing the embedded text used to guide the diffusion model.",
    ],
  },
  CLIPSetLastLayer: {
    input: {
      required: {
        clip: ["CLIP"],
        stop_at_clip_layer: [
          "INT",
          { default: -1, min: -24, max: -1, step: 1 },
        ],
      },
    },
    input_order: { required: ["clip", "stop_at_clip_layer"] },
    output: ["CLIP"],
    output_is_list: [false],
    output_name: ["CLIP"],
    name: "CLIPSetLastLayer",
    display_name: "CLIP Set Last Layer",
    description: "",
    python_module: "nodes",
    category: "conditioning",
    output_node: false,
  },
  VAEDecode: {
    input: {
      required: {
        samples: ["LATENT", { tooltip: "The latent to be decoded." }],
        vae: [
          "VAE",
          { tooltip: "The VAE model used for decoding the latent." },
        ],
      },
    },
    input_order: { required: ["samples", "vae"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "VAEDecode",
    display_name: "VAE Decode",
    description: "Decodes latent images back into pixel space images.",
    python_module: "nodes",
    category: "latent",
    output_node: false,
    output_tooltips: ["The decoded image."],
  },
  VAEEncode: {
    input: { required: { pixels: ["IMAGE"], vae: ["VAE"] } },
    input_order: { required: ["pixels", "vae"] },
    output: ["LATENT"],
    output_is_list: [false],
    output_name: ["LATENT"],
    name: "VAEEncode",
    display_name: "VAE Encode",
    description: "",
    python_module: "nodes",
    category: "latent",
    output_node: false,
  },
  VAEEncodeForInpaint: {
    input: {
      required: {
        pixels: ["IMAGE"],
        vae: ["VAE"],
        mask: ["MASK"],
        grow_mask_by: ["INT", { default: 6, min: 0, max: 64, step: 1 }],
      },
    },
    input_order: { required: ["pixels", "vae", "mask", "grow_mask_by"] },
    output: ["LATENT"],
    output_is_list: [false],
    output_name: ["LATENT"],
    name: "VAEEncodeForInpaint",
    display_name: "VAE Encode (for Inpainting)",
    description: "",
    python_module: "nodes",
    category: "latent/inpaint",
    output_node: false,
  },
  VAELoader: {
    input: {
      required: { vae_name: [["ae.safetensors", "xlVAEC_f1.safetensors"]] },
    },
    input_order: { required: ["vae_name"] },
    output: ["VAE"],
    output_is_list: [false],
    output_name: ["VAE"],
    name: "VAELoader",
    display_name: "Load VAE",
    description: "",
    python_module: "nodes",
    category: "loaders",
    output_node: false,
  },
  EmptyLatentImage: {
    input: {
      required: {
        width: [
          "INT",
          {
            default: 512,
            min: 16,
            max: 16384,
            step: 8,
            tooltip: "The width of the latent images in pixels.",
          },
        ],
        height: [
          "INT",
          {
            default: 512,
            min: 16,
            max: 16384,
            step: 8,
            tooltip: "The height of the latent images in pixels.",
          },
        ],
        batch_size: [
          "INT",
          {
            default: 1,
            min: 1,
            max: 4096,
            tooltip: "The number of latent images in the batch.",
          },
        ],
      },
    },
    input_order: { required: ["width", "height", "batch_size"] },
    output: ["LATENT"],
    output_is_list: [false],
    output_name: ["LATENT"],
    name: "EmptyLatentImage",
    display_name: "Empty Latent Image",
    description:
      "Create a new batch of empty latent images to be denoised via sampling.",
    python_module: "nodes",
    category: "latent",
    output_node: false,
    output_tooltips: ["The empty latent image batch."],
  },
  LatentUpscale: {
    input: {
      required: {
        samples: ["LATENT"],
        upscale_method: [
          ["nearest-exact", "bilinear", "area", "bicubic", "bislerp"],
        ],
        width: ["INT", { default: 512, min: 0, max: 16384, step: 8 }],
        height: ["INT", { default: 512, min: 0, max: 16384, step: 8 }],
        crop: [["disabled", "center"]],
      },
    },
    input_order: {
      required: ["samples", "upscale_method", "width", "height", "crop"],
    },
    output: ["LATENT"],
    output_is_list: [false],
    output_name: ["LATENT"],
    name: "LatentUpscale",
    display_name: "Upscale Latent",
    description: "",
    python_module: "nodes",
    category: "latent",
    output_node: false,
  },
  LatentUpscaleBy: {
    input: {
      required: {
        samples: ["LATENT"],
        upscale_method: [
          ["nearest-exact", "bilinear", "area", "bicubic", "bislerp"],
        ],
        scale_by: ["FLOAT", { default: 1.5, min: 0.01, max: 8.0, step: 0.01 }],
      },
    },
    input_order: { required: ["samples", "upscale_method", "scale_by"] },
    output: ["LATENT"],
    output_is_list: [false],
    output_name: ["LATENT"],
    name: "LatentUpscaleBy",
    display_name: "Upscale Latent By",
    description: "",
    python_module: "nodes",
    category: "latent",
    output_node: false,
  },
  LatentFromBatch: {
    input: {
      required: {
        samples: ["LATENT"],
        batch_index: ["INT", { default: 0, min: 0, max: 63 }],
        length: ["INT", { default: 1, min: 1, max: 64 }],
      },
    },
    input_order: { required: ["samples", "batch_index", "length"] },
    output: ["LATENT"],
    output_is_list: [false],
    output_name: ["LATENT"],
    name: "LatentFromBatch",
    display_name: "Latent From Batch",
    description: "",
    python_module: "nodes",
    category: "latent/batch",
    output_node: false,
  },
  RepeatLatentBatch: {
    input: {
      required: {
        samples: ["LATENT"],
        amount: ["INT", { default: 1, min: 1, max: 64 }],
      },
    },
    input_order: { required: ["samples", "amount"] },
    output: ["LATENT"],
    output_is_list: [false],
    output_name: ["LATENT"],
    name: "RepeatLatentBatch",
    display_name: "Repeat Latent Batch",
    description: "",
    python_module: "nodes",
    category: "latent/batch",
    output_node: false,
  },
  SaveImage: {
    input: {
      required: {
        images: ["IMAGE", { tooltip: "The images to save." }],
        filename_prefix: [
          "STRING",
          {
            default: "ComfyUI",
            tooltip:
              "The prefix for the file to save. This may include formatting information such as %date:yyyy-MM-dd% or %Empty Latent Image.width% to include values from nodes.",
          },
        ],
      },
      hidden: { prompt: "PROMPT", extra_pnginfo: "EXTRA_PNGINFO" },
    },
    input_order: {
      required: ["images", "filename_prefix"],
      hidden: ["prompt", "extra_pnginfo"],
    },
    output: [],
    output_is_list: [],
    output_name: [],
    name: "SaveImage",
    display_name: "Save Image",
    description: "Saves the input images to your ComfyUI output directory.",
    python_module: "nodes",
    category: "image",
    output_node: true,
  },
  PreviewImage: {
    input: {
      required: { images: ["IMAGE"] },
      hidden: { prompt: "PROMPT", extra_pnginfo: "EXTRA_PNGINFO" },
    },
    input_order: { required: ["images"], hidden: ["prompt", "extra_pnginfo"] },
    output: [],
    output_is_list: [],
    output_name: [],
    name: "PreviewImage",
    display_name: "Preview Image",
    description: "Saves the input images to your ComfyUI output directory.",
    python_module: "nodes",
    category: "image",
    output_node: true,
  },
  LoadImage: {
    input: {
      required: {
        image: [
          [
            "00000-2766569857.png",
            "00016-2678844265.png",
            "00017-749375916.png",
            "00051-493598238.png",
            "005.jpg",
            "010.jpg",
            "20240819_001358_873_SP-MangaEditor.png",
            "20240819_002252_983_SP-MangaEditor.png",
            "dark-skin.webp",
            "example.png",
            "p02.jpg",
            "police-station.webp",
            "tan-skin.webp",
          ],
          { image_upload: true },
        ],
      },
    },
    input_order: { required: ["image"] },
    output: ["IMAGE", "MASK"],
    output_is_list: [false, false],
    output_name: ["IMAGE", "MASK"],
    name: "LoadImage",
    display_name: "Load Image",
    description: "",
    python_module: "nodes",
    category: "image",
    output_node: false,
  },
  LoadImageMask: {
    input: {
      required: {
        image: [
          [
            "00000-2766569857.png",
            "00016-2678844265.png",
            "00017-749375916.png",
            "00051-493598238.png",
            "005.jpg",
            "010.jpg",
            "20240819_001358_873_SP-MangaEditor.png",
            "20240819_002252_983_SP-MangaEditor.png",
            "dark-skin.webp",
            "example.png",
            "p02.jpg",
            "police-station.webp",
            "tan-skin.webp",
          ],
          { image_upload: true },
        ],
        channel: [["alpha", "red", "green", "blue"]],
      },
    },
    input_order: { required: ["image", "channel"] },
    output: ["MASK"],
    output_is_list: [false],
    output_name: ["MASK"],
    name: "LoadImageMask",
    display_name: "Load Image (as Mask)",
    description: "",
    python_module: "nodes",
    category: "mask",
    output_node: false,
  },
  ImageScale: {
    input: {
      required: {
        image: ["IMAGE"],
        upscale_method: [
          ["nearest-exact", "bilinear", "area", "bicubic", "lanczos"],
        ],
        width: ["INT", { default: 512, min: 0, max: 16384, step: 1 }],
        height: ["INT", { default: 512, min: 0, max: 16384, step: 1 }],
        crop: [["disabled", "center"]],
      },
    },
    input_order: {
      required: ["image", "upscale_method", "width", "height", "crop"],
    },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "ImageScale",
    display_name: "Upscale Image",
    description: "",
    python_module: "nodes",
    category: "image/upscaling",
    output_node: false,
  },
  ImageScaleBy: {
    input: {
      required: {
        image: ["IMAGE"],
        upscale_method: [
          ["nearest-exact", "bilinear", "area", "bicubic", "lanczos"],
        ],
        scale_by: ["FLOAT", { default: 1.0, min: 0.01, max: 8.0, step: 0.01 }],
      },
    },
    input_order: { required: ["image", "upscale_method", "scale_by"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "ImageScaleBy",
    display_name: "Upscale Image By",
    description: "",
    python_module: "nodes",
    category: "image/upscaling",
    output_node: false,
  },
  ImageInvert: {
    input: { required: { image: ["IMAGE"] } },
    input_order: { required: ["image"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "ImageInvert",
    display_name: "Invert Image",
    description: "",
    python_module: "nodes",
    category: "image",
    output_node: false,
  },
  ImageBatch: {
    input: { required: { image1: ["IMAGE"], image2: ["IMAGE"] } },
    input_order: { required: ["image1", "image2"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "ImageBatch",
    display_name: "Batch Images",
    description: "",
    python_module: "nodes",
    category: "image",
    output_node: false,
  },
  ImagePadForOutpaint: {
    input: {
      required: {
        image: ["IMAGE"],
        left: ["INT", { default: 0, min: 0, max: 16384, step: 8 }],
        top: ["INT", { default: 0, min: 0, max: 16384, step: 8 }],
        right: ["INT", { default: 0, min: 0, max: 16384, step: 8 }],
        bottom: ["INT", { default: 0, min: 0, max: 16384, step: 8 }],
        feathering: ["INT", { default: 40, min: 0, max: 16384, step: 1 }],
      },
    },
    input_order: {
      required: ["image", "left", "top", "right", "bottom", "feathering"],
    },
    output: ["IMAGE", "MASK"],
    output_is_list: [false, false],
    output_name: ["IMAGE", "MASK"],
    name: "ImagePadForOutpaint",
    display_name: "Pad Image for Outpainting",
    description: "",
    python_module: "nodes",
    category: "image",
    output_node: false,
  },
  EmptyImage: {
    input: {
      required: {
        width: ["INT", { default: 512, min: 1, max: 16384, step: 1 }],
        height: ["INT", { default: 512, min: 1, max: 16384, step: 1 }],
        batch_size: ["INT", { default: 1, min: 1, max: 4096 }],
        color: [
          "INT",
          { default: 0, min: 0, max: 16777215, step: 1, display: "color" },
        ],
      },
    },
    input_order: { required: ["width", "height", "batch_size", "color"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "EmptyImage",
    display_name: "EmptyImage",
    description: "",
    python_module: "nodes",
    category: "image",
    output_node: false,
  },
  ConditioningAverage: {
    input: {
      required: {
        conditioning_to: ["CONDITIONING"],
        conditioning_from: ["CONDITIONING"],
        conditioning_to_strength: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
      },
    },
    input_order: {
      required: [
        "conditioning_to",
        "conditioning_from",
        "conditioning_to_strength",
      ],
    },
    output: ["CONDITIONING"],
    output_is_list: [false],
    output_name: ["CONDITIONING"],
    name: "ConditioningAverage",
    display_name: "ConditioningAverage",
    description: "",
    python_module: "nodes",
    category: "conditioning",
    output_node: false,
  },
  ConditioningCombine: {
    input: {
      required: {
        conditioning_1: ["CONDITIONING"],
        conditioning_2: ["CONDITIONING"],
      },
    },
    input_order: { required: ["conditioning_1", "conditioning_2"] },
    output: ["CONDITIONING"],
    output_is_list: [false],
    output_name: ["CONDITIONING"],
    name: "ConditioningCombine",
    display_name: "Conditioning (Combine)",
    description: "",
    python_module: "nodes",
    category: "conditioning",
    output_node: false,
  },
  ConditioningConcat: {
    input: {
      required: {
        conditioning_to: ["CONDITIONING"],
        conditioning_from: ["CONDITIONING"],
      },
    },
    input_order: { required: ["conditioning_to", "conditioning_from"] },
    output: ["CONDITIONING"],
    output_is_list: [false],
    output_name: ["CONDITIONING"],
    name: "ConditioningConcat",
    display_name: "Conditioning (Concat)",
    description: "",
    python_module: "nodes",
    category: "conditioning",
    output_node: false,
  },
  ConditioningSetArea: {
    input: {
      required: {
        conditioning: ["CONDITIONING"],
        width: ["INT", { default: 64, min: 64, max: 16384, step: 8 }],
        height: ["INT", { default: 64, min: 64, max: 16384, step: 8 }],
        x: ["INT", { default: 0, min: 0, max: 16384, step: 8 }],
        y: ["INT", { default: 0, min: 0, max: 16384, step: 8 }],
        strength: ["FLOAT", { default: 1.0, min: 0.0, max: 10.0, step: 0.01 }],
      },
    },
    input_order: {
      required: ["conditioning", "width", "height", "x", "y", "strength"],
    },
    output: ["CONDITIONING"],
    output_is_list: [false],
    output_name: ["CONDITIONING"],
    name: "ConditioningSetArea",
    display_name: "Conditioning (Set Area)",
    description: "",
    python_module: "nodes",
    category: "conditioning",
    output_node: false,
  },
  ConditioningSetAreaPercentage: {
    input: {
      required: {
        conditioning: ["CONDITIONING"],
        width: ["FLOAT", { default: 1.0, min: 0, max: 1.0, step: 0.01 }],
        height: ["FLOAT", { default: 1.0, min: 0, max: 1.0, step: 0.01 }],
        x: ["FLOAT", { default: 0, min: 0, max: 1.0, step: 0.01 }],
        y: ["FLOAT", { default: 0, min: 0, max: 1.0, step: 0.01 }],
        strength: ["FLOAT", { default: 1.0, min: 0.0, max: 10.0, step: 0.01 }],
      },
    },
    input_order: {
      required: ["conditioning", "width", "height", "x", "y", "strength"],
    },
    output: ["CONDITIONING"],
    output_is_list: [false],
    output_name: ["CONDITIONING"],
    name: "ConditioningSetAreaPercentage",
    display_name: "Conditioning (Set Area with Percentage)",
    description: "",
    python_module: "nodes",
    category: "conditioning",
    output_node: false,
  },
  ConditioningSetAreaStrength: {
    input: {
      required: {
        conditioning: ["CONDITIONING"],
        strength: ["FLOAT", { default: 1.0, min: 0.0, max: 10.0, step: 0.01 }],
      },
    },
    input_order: { required: ["conditioning", "strength"] },
    output: ["CONDITIONING"],
    output_is_list: [false],
    output_name: ["CONDITIONING"],
    name: "ConditioningSetAreaStrength",
    display_name: "ConditioningSetAreaStrength",
    description: "",
    python_module: "nodes",
    category: "conditioning",
    output_node: false,
  },
  ConditioningSetMask: {
    input: {
      required: {
        conditioning: ["CONDITIONING"],
        mask: ["MASK"],
        strength: ["FLOAT", { default: 1.0, min: 0.0, max: 10.0, step: 0.01 }],
        set_cond_area: [["default", "mask bounds"]],
      },
    },
    input_order: {
      required: ["conditioning", "mask", "strength", "set_cond_area"],
    },
    output: ["CONDITIONING"],
    output_is_list: [false],
    output_name: ["CONDITIONING"],
    name: "ConditioningSetMask",
    display_name: "Conditioning (Set Mask)",
    description: "",
    python_module: "nodes",
    category: "conditioning",
    output_node: false,
  },
  KSamplerAdvanced: {
    input: {
      required: {
        model: ["MODEL"],
        add_noise: [["enable", "disable"]],
        noise_seed: ["INT", { default: 0, min: 0, max: 18446744073709551615 }],
        steps: ["INT", { default: 20, min: 1, max: 10000 }],
        cfg: [
          "FLOAT",
          { default: 8.0, min: 0.0, max: 100.0, step: 0.1, round: 0.01 },
        ],
        sampler_name: [
          [
            "euler",
            "euler_cfg_pp",
            "euler_ancestral",
            "euler_ancestral_cfg_pp",
            "heun",
            "heunpp2",
            "dpm_2",
            "dpm_2_ancestral",
            "lms",
            "dpm_fast",
            "dpm_adaptive",
            "dpmpp_2s_ancestral",
            "dpmpp_2s_ancestral_cfg_pp",
            "dpmpp_sde",
            "dpmpp_sde_gpu",
            "dpmpp_2m",
            "dpmpp_2m_cfg_pp",
            "dpmpp_2m_sde",
            "dpmpp_2m_sde_gpu",
            "dpmpp_3m_sde",
            "dpmpp_3m_sde_gpu",
            "ddpm",
            "lcm",
            "ipndm",
            "ipndm_v",
            "deis",
            "ddim",
            "uni_pc",
            "uni_pc_bh2",
          ],
        ],
        scheduler: [
          [
            "normal",
            "karras",
            "exponential",
            "sgm_uniform",
            "simple",
            "ddim_uniform",
            "beta",
          ],
        ],
        positive: ["CONDITIONING"],
        negative: ["CONDITIONING"],
        latent_image: ["LATENT"],
        start_at_step: ["INT", { default: 0, min: 0, max: 10000 }],
        end_at_step: ["INT", { default: 10000, min: 0, max: 10000 }],
        return_with_leftover_noise: [["disable", "enable"]],
      },
    },
    input_order: {
      required: [
        "model",
        "add_noise",
        "noise_seed",
        "steps",
        "cfg",
        "sampler_name",
        "scheduler",
        "positive",
        "negative",
        "latent_image",
        "start_at_step",
        "end_at_step",
        "return_with_leftover_noise",
      ],
    },
    output: ["LATENT"],
    output_is_list: [false],
    output_name: ["LATENT"],
    name: "KSamplerAdvanced",
    display_name: "KSampler (Advanced)",
    description: "",
    python_module: "nodes",
    category: "sampling",
    output_node: false,
  },
  SetLatentNoiseMask: {
    input: { required: { samples: ["LATENT"], mask: ["MASK"] } },
    input_order: { required: ["samples", "mask"] },
    output: ["LATENT"],
    output_is_list: [false],
    output_name: ["LATENT"],
    name: "SetLatentNoiseMask",
    display_name: "Set Latent Noise Mask",
    description: "",
    python_module: "nodes",
    category: "latent/inpaint",
    output_node: false,
  },
  LatentComposite: {
    input: {
      required: {
        samples_to: ["LATENT"],
        samples_from: ["LATENT"],
        x: ["INT", { default: 0, min: 0, max: 16384, step: 8 }],
        y: ["INT", { default: 0, min: 0, max: 16384, step: 8 }],
        feather: ["INT", { default: 0, min: 0, max: 16384, step: 8 }],
      },
    },
    input_order: {
      required: ["samples_to", "samples_from", "x", "y", "feather"],
    },
    output: ["LATENT"],
    output_is_list: [false],
    output_name: ["LATENT"],
    name: "LatentComposite",
    display_name: "Latent Composite",
    description: "",
    python_module: "nodes",
    category: "latent",
    output_node: false,
  },
  LatentBlend: {
    input: {
      required: {
        samples1: ["LATENT"],
        samples2: ["LATENT"],
        blend_factor: ["FLOAT", { default: 0.5, min: 0, max: 1, step: 0.01 }],
      },
    },
    input_order: { required: ["samples1", "samples2", "blend_factor"] },
    output: ["LATENT"],
    output_is_list: [false],
    output_name: ["LATENT"],
    name: "LatentBlend",
    display_name: "Latent Blend",
    description: "",
    python_module: "nodes",
    category: "_for_testing",
    output_node: false,
  },
  LatentRotate: {
    input: {
      required: {
        samples: ["LATENT"],
        rotation: [["none", "90 degrees", "180 degrees", "270 degrees"]],
      },
    },
    input_order: { required: ["samples", "rotation"] },
    output: ["LATENT"],
    output_is_list: [false],
    output_name: ["LATENT"],
    name: "LatentRotate",
    display_name: "Rotate Latent",
    description: "",
    python_module: "nodes",
    category: "latent/transform",
    output_node: false,
  },
  LatentFlip: {
    input: {
      required: {
        samples: ["LATENT"],
        flip_method: [["x-axis: vertically", "y-axis: horizontally"]],
      },
    },
    input_order: { required: ["samples", "flip_method"] },
    output: ["LATENT"],
    output_is_list: [false],
    output_name: ["LATENT"],
    name: "LatentFlip",
    display_name: "Flip Latent",
    description: "",
    python_module: "nodes",
    category: "latent/transform",
    output_node: false,
  },
  LatentCrop: {
    input: {
      required: {
        samples: ["LATENT"],
        width: ["INT", { default: 512, min: 64, max: 16384, step: 8 }],
        height: ["INT", { default: 512, min: 64, max: 16384, step: 8 }],
        x: ["INT", { default: 0, min: 0, max: 16384, step: 8 }],
        y: ["INT", { default: 0, min: 0, max: 16384, step: 8 }],
      },
    },
    input_order: { required: ["samples", "width", "height", "x", "y"] },
    output: ["LATENT"],
    output_is_list: [false],
    output_name: ["LATENT"],
    name: "LatentCrop",
    display_name: "Crop Latent",
    description: "",
    python_module: "nodes",
    category: "latent/transform",
    output_node: false,
  },
  LoraLoader: {
    input: {
      required: {
        model: [
          "MODEL",
          { tooltip: "The diffusion model the LoRA will be applied to." },
        ],
        clip: [
          "CLIP",
          { tooltip: "The CLIP model the LoRA will be applied to." },
        ],
        lora_name: [
          [
            "CleanLineArt.safetensors",
            "Flux\\Doujinshi-000001.safetensors",
            "xl_one finger selfie challenge(kohaku_delta)2.safetensors",
          ],
          { tooltip: "The name of the LoRA." },
        ],
        strength_model: [
          "FLOAT",
          {
            default: 1.0,
            min: -100.0,
            max: 100.0,
            step: 0.01,
            tooltip:
              "How strongly to modify the diffusion model. This value can be negative.",
          },
        ],
        strength_clip: [
          "FLOAT",
          {
            default: 1.0,
            min: -100.0,
            max: 100.0,
            step: 0.01,
            tooltip:
              "How strongly to modify the CLIP model. This value can be negative.",
          },
        ],
      },
    },
    input_order: {
      required: [
        "model",
        "clip",
        "lora_name",
        "strength_model",
        "strength_clip",
      ],
    },
    output: ["MODEL", "CLIP"],
    output_is_list: [false, false],
    output_name: ["MODEL", "CLIP"],
    name: "LoraLoader",
    display_name: "Load LoRA",
    description:
      "LoRAs are used to modify diffusion and CLIP models, altering the way in which latents are denoised such as applying styles. Multiple LoRA nodes can be linked together.",
    python_module: "nodes",
    category: "loaders",
    output_node: false,
    output_tooltips: [
      "The modified diffusion model.",
      "The modified CLIP model.",
    ],
  },
  CLIPLoader: {
    input: {
      required: {
        clip_name: [
          [
            "ViT-L-14_openai_artists.safetensors",
            "ViT-L-14_openai_flavors.safetensors",
            "ViT-L-14_openai_mediums.safetensors",
            "ViT-L-14_openai_movements.safetensors",
            "ViT-L-14_openai_negative.safetensors",
            "ViT-L-14_openai_trendings.safetensors",
          ],
        ],
        type: [["stable_diffusion", "stable_cascade", "sd3", "stable_audio"]],
      },
    },
    input_order: { required: ["clip_name", "type"] },
    output: ["CLIP"],
    output_is_list: [false],
    output_name: ["CLIP"],
    name: "CLIPLoader",
    display_name: "Load CLIP",
    description: "",
    python_module: "nodes",
    category: "advanced/loaders",
    output_node: false,
  },
  UNETLoader: {
    input: {
      required: {
        unet_name: [[]],
        weight_dtype: [
          ["default", "fp8_e4m3fn", "fp8_e4m3fn_fast", "fp8_e5m2"],
        ],
      },
    },
    input_order: { required: ["unet_name", "weight_dtype"] },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "UNETLoader",
    display_name: "Load Diffusion Model",
    description: "",
    python_module: "nodes",
    category: "advanced/loaders",
    output_node: false,
  },
  DualCLIPLoader: {
    input: {
      required: {
        clip_name1: [
          [
            "ViT-L-14_openai_artists.safetensors",
            "ViT-L-14_openai_flavors.safetensors",
            "ViT-L-14_openai_mediums.safetensors",
            "ViT-L-14_openai_movements.safetensors",
            "ViT-L-14_openai_negative.safetensors",
            "ViT-L-14_openai_trendings.safetensors",
          ],
        ],
        clip_name2: [
          [
            "ViT-L-14_openai_artists.safetensors",
            "ViT-L-14_openai_flavors.safetensors",
            "ViT-L-14_openai_mediums.safetensors",
            "ViT-L-14_openai_movements.safetensors",
            "ViT-L-14_openai_negative.safetensors",
            "ViT-L-14_openai_trendings.safetensors",
          ],
        ],
        type: [["sdxl", "sd3", "flux"]],
      },
    },
    input_order: { required: ["clip_name1", "clip_name2", "type"] },
    output: ["CLIP"],
    output_is_list: [false],
    output_name: ["CLIP"],
    name: "DualCLIPLoader",
    display_name: "DualCLIPLoader",
    description: "",
    python_module: "nodes",
    category: "advanced/loaders",
    output_node: false,
  },
  CLIPVisionEncode: {
    input: { required: { clip_vision: ["CLIP_VISION"], image: ["IMAGE"] } },
    input_order: { required: ["clip_vision", "image"] },
    output: ["CLIP_VISION_OUTPUT"],
    output_is_list: [false],
    output_name: ["CLIP_VISION_OUTPUT"],
    name: "CLIPVisionEncode",
    display_name: "CLIP Vision Encode",
    description: "",
    python_module: "nodes",
    category: "conditioning",
    output_node: false,
  },
  StyleModelApply: {
    input: {
      required: {
        conditioning: ["CONDITIONING"],
        style_model: ["STYLE_MODEL"],
        clip_vision_output: ["CLIP_VISION_OUTPUT"],
      },
    },
    input_order: {
      required: ["conditioning", "style_model", "clip_vision_output"],
    },
    output: ["CONDITIONING"],
    output_is_list: [false],
    output_name: ["CONDITIONING"],
    name: "StyleModelApply",
    display_name: "Apply Style Model",
    description: "",
    python_module: "nodes",
    category: "conditioning/style_model",
    output_node: false,
  },
  unCLIPConditioning: {
    input: {
      required: {
        conditioning: ["CONDITIONING"],
        clip_vision_output: ["CLIP_VISION_OUTPUT"],
        strength: [
          "FLOAT",
          { default: 1.0, min: -10.0, max: 10.0, step: 0.01 },
        ],
        noise_augmentation: [
          "FLOAT",
          { default: 0.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
      },
    },
    input_order: {
      required: [
        "conditioning",
        "clip_vision_output",
        "strength",
        "noise_augmentation",
      ],
    },
    output: ["CONDITIONING"],
    output_is_list: [false],
    output_name: ["CONDITIONING"],
    name: "unCLIPConditioning",
    display_name: "unCLIPConditioning",
    description: "",
    python_module: "nodes",
    category: "conditioning",
    output_node: false,
  },
  ControlNetApply: {
    input: {
      required: {
        conditioning: ["CONDITIONING"],
        control_net: ["CONTROL_NET"],
        image: ["IMAGE"],
        strength: ["FLOAT", { default: 1.0, min: 0.0, max: 10.0, step: 0.01 }],
      },
    },
    input_order: {
      required: ["conditioning", "control_net", "image", "strength"],
    },
    output: ["CONDITIONING"],
    output_is_list: [false],
    output_name: ["CONDITIONING"],
    name: "ControlNetApply",
    display_name: "Apply ControlNet (OLD)",
    description: "",
    python_module: "nodes",
    category: "conditioning/controlnet",
    output_node: false,
    deprecated: true,
  },
  ControlNetApplyAdvanced: {
    input: {
      required: {
        positive: ["CONDITIONING"],
        negative: ["CONDITIONING"],
        control_net: ["CONTROL_NET"],
        image: ["IMAGE"],
        strength: ["FLOAT", { default: 1.0, min: 0.0, max: 10.0, step: 0.01 }],
        start_percent: [
          "FLOAT",
          { default: 0.0, min: 0.0, max: 1.0, step: 0.001 },
        ],
        end_percent: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.001 },
        ],
      },
      optional: { vae: ["VAE"] },
    },
    input_order: {
      required: [
        "positive",
        "negative",
        "control_net",
        "image",
        "strength",
        "start_percent",
        "end_percent",
      ],
      optional: ["vae"],
    },
    output: ["CONDITIONING", "CONDITIONING"],
    output_is_list: [false, false],
    output_name: ["positive", "negative"],
    name: "ControlNetApplyAdvanced",
    display_name: "Apply ControlNet",
    description: "",
    python_module: "nodes",
    category: "conditioning/controlnet",
    output_node: false,
  },
  ControlNetLoader: {
    input: {
      required: {
        control_net_name: [
          [
            "MLSD\\diffusion_pytorch_model.safetensors",
            "canny\\diffusion_pytorch_model.safetensors",
            "control-lora-canny-rank128.safetensors",
            "control-lora-depth-rank128.safetensors",
            "control-lora-recolor-rank128.safetensors",
            "control-lora-sketch-rank128-metadata.safetensors",
            "control_v11e_sd15_ip2p.pth",
            "control_v11e_sd15_shuffle.pth",
            "control_v11f1e_sd15_tile.pth",
            "control_v11f1p_sd15_depth.pth",
            "control_v11p_sd15_canny.pth",
            "control_v11p_sd15_inpaint.pth",
            "control_v11p_sd15_lineart.pth",
            "control_v11p_sd15_mlsd.pth",
            "control_v11p_sd15_normalbae.pth",
            "control_v11p_sd15_openpose.pth",
            "control_v11p_sd15_scribble.pth",
            "control_v11p_sd15_seg.pth",
            "control_v11p_sd15_softedge.pth",
            "control_v11p_sd15s2_lineart_anime.pth",
            "depth\\diffusion_pytorch_model.safetensors",
            "inpaint\\diffusion_pytorch_model.safetensors",
            "ip2p\\diffusion_pytorch_model.safetensors",
            "lineart\\diffusion_pytorch_model.safetensors",
            "lineart_anime\\diffusion_pytorch_model.safetensors",
            "normalbae\\diffusion_pytorch_model.safetensors",
            "openpose\\diffusion_pytorch_model.safetensors",
            "scribble\\diffusion_pytorch_model.safetensors",
            "sd_control_collection\\OpenPoseXL2.safetensors",
            "sd_control_collection\\diffusers_xl_canny_full.safetensors",
            "sd_control_collection\\diffusers_xl_canny_mid.safetensors",
            "sd_control_collection\\diffusers_xl_canny_small.safetensors",
            "sd_control_collection\\diffusers_xl_depth_full.safetensors",
            "sd_control_collection\\diffusers_xl_depth_mid.safetensors",
            "sd_control_collection\\diffusers_xl_depth_small.safetensors",
            "sd_control_collection\\ioclab_sd15_recolor.safetensors",
            "sd_control_collection\\ip-adapter_sd15.pth",
            "sd_control_collection\\ip-adapter_sd15_plus.pth",
            "sd_control_collection\\ip-adapter_xl.pth",
            "sd_control_collection\\kohya_controllllite_xl_blur.safetensors",
            "sd_control_collection\\kohya_controllllite_xl_blur_anime.safetensors",
            "sd_control_collection\\kohya_controllllite_xl_blur_anime_beta.safetensors",
            "sd_control_collection\\kohya_controllllite_xl_canny.safetensors",
            "sd_control_collection\\kohya_controllllite_xl_canny_anime.safetensors",
            "sd_control_collection\\kohya_controllllite_xl_depth.safetensors",
            "sd_control_collection\\kohya_controllllite_xl_depth_anime.safetensors",
            "sd_control_collection\\kohya_controllllite_xl_openpose_anime.safetensors",
            "sd_control_collection\\kohya_controllllite_xl_openpose_anime_v2.safetensors",
            "sd_control_collection\\kohya_controllllite_xl_scribble_anime.safetensors",
            "sd_control_collection\\sai_xl_canny_128lora.safetensors",
            "sd_control_collection\\sai_xl_canny_256lora.safetensors",
            "sd_control_collection\\sai_xl_depth_128lora.safetensors",
            "sd_control_collection\\sai_xl_depth_256lora.safetensors",
            "sd_control_collection\\sai_xl_recolor_128lora.safetensors",
            "sd_control_collection\\sai_xl_recolor_256lora.safetensors",
            "sd_control_collection\\sai_xl_sketch_128lora.safetensors",
            "sd_control_collection\\sai_xl_sketch_256lora.safetensors",
            "sd_control_collection\\sargezt_xl_depth.safetensors",
            "sd_control_collection\\sargezt_xl_depth_faid_vidit.safetensors",
            "sd_control_collection\\sargezt_xl_depth_zeed.safetensors",
            "sd_control_collection\\sargezt_xl_softedge.safetensors",
            "sd_control_collection\\t2i-adapter_diffusers_xl_canny.safetensors",
            "sd_control_collection\\t2i-adapter_diffusers_xl_depth_midas.safetensors",
            "sd_control_collection\\t2i-adapter_diffusers_xl_depth_zoe.safetensors",
            "sd_control_collection\\t2i-adapter_diffusers_xl_lineart.safetensors",
            "sd_control_collection\\t2i-adapter_diffusers_xl_openpose.safetensors",
            "sd_control_collection\\t2i-adapter_diffusers_xl_sketch.safetensors",
            "sd_control_collection\\t2i-adapter_xl_canny.safetensors",
            "sd_control_collection\\t2i-adapter_xl_openpose.safetensors",
            "sd_control_collection\\t2i-adapter_xl_sketch.safetensors",
            "sd_control_collection\\thibaud_xl_openpose.safetensors",
            "seg\\diffusion_pytorch_model.safetensors",
            "shuffle\\diffusion_pytorch_model.safetensors",
            "softedge\\diffusion_pytorch_model.safetensors",
            "t2i-adapter-canny-sdxl-1.0\\diffusion_pytorch_model.safetensors",
            "t2i-adapter-depth-midas-sdxl-1.0\\diffusion_pytorch_model.safetensors",
            "t2i-adapter-depth-zoe-sdxl-1.0\\diffusion_pytorch_model.safetensors",
            "t2i-adapter-openpose-sdxl-1.0\\diffusion_pytorch_model.safetensors",
            "t2i-adapter-sketch-sdxl-1.0\\diffusion_pytorch_model.safetensors",
            "t2iadapter_canny_sd15v2\\diffusion_pytorch_model.bin",
            "t2iadapter_depth_sd15v2\\diffusion_pytorch_model.bin",
            "t2iadapter_sketch_sd15v2\\diffusion_pytorch_model.bin",
            "t2iadapter_zoedepth_sd15v1\\diffusion_pytorch_model.bin",
            "tile\\diffusion_pytorch_model.bin",
          ],
        ],
      },
    },
    input_order: { required: ["control_net_name"] },
    output: ["CONTROL_NET"],
    output_is_list: [false],
    output_name: ["CONTROL_NET"],
    name: "ControlNetLoader",
    display_name: "Load ControlNet Model",
    description: "",
    python_module: "nodes",
    category: "loaders",
    output_node: false,
  },
  DiffControlNetLoader: {
    input: {
      required: {
        model: ["MODEL"],
        control_net_name: [
          [
            "MLSD\\diffusion_pytorch_model.safetensors",
            "canny\\diffusion_pytorch_model.safetensors",
            "control-lora-canny-rank128.safetensors",
            "control-lora-depth-rank128.safetensors",
            "control-lora-recolor-rank128.safetensors",
            "control-lora-sketch-rank128-metadata.safetensors",
            "control_v11e_sd15_ip2p.pth",
            "control_v11e_sd15_shuffle.pth",
            "control_v11f1e_sd15_tile.pth",
            "control_v11f1p_sd15_depth.pth",
            "control_v11p_sd15_canny.pth",
            "control_v11p_sd15_inpaint.pth",
            "control_v11p_sd15_lineart.pth",
            "control_v11p_sd15_mlsd.pth",
            "control_v11p_sd15_normalbae.pth",
            "control_v11p_sd15_openpose.pth",
            "control_v11p_sd15_scribble.pth",
            "control_v11p_sd15_seg.pth",
            "control_v11p_sd15_softedge.pth",
            "control_v11p_sd15s2_lineart_anime.pth",
            "depth\\diffusion_pytorch_model.safetensors",
            "inpaint\\diffusion_pytorch_model.safetensors",
            "ip2p\\diffusion_pytorch_model.safetensors",
            "lineart\\diffusion_pytorch_model.safetensors",
            "lineart_anime\\diffusion_pytorch_model.safetensors",
            "normalbae\\diffusion_pytorch_model.safetensors",
            "openpose\\diffusion_pytorch_model.safetensors",
            "scribble\\diffusion_pytorch_model.safetensors",
            "sd_control_collection\\OpenPoseXL2.safetensors",
            "sd_control_collection\\diffusers_xl_canny_full.safetensors",
            "sd_control_collection\\diffusers_xl_canny_mid.safetensors",
            "sd_control_collection\\diffusers_xl_canny_small.safetensors",
            "sd_control_collection\\diffusers_xl_depth_full.safetensors",
            "sd_control_collection\\diffusers_xl_depth_mid.safetensors",
            "sd_control_collection\\diffusers_xl_depth_small.safetensors",
            "sd_control_collection\\ioclab_sd15_recolor.safetensors",
            "sd_control_collection\\ip-adapter_sd15.pth",
            "sd_control_collection\\ip-adapter_sd15_plus.pth",
            "sd_control_collection\\ip-adapter_xl.pth",
            "sd_control_collection\\kohya_controllllite_xl_blur.safetensors",
            "sd_control_collection\\kohya_controllllite_xl_blur_anime.safetensors",
            "sd_control_collection\\kohya_controllllite_xl_blur_anime_beta.safetensors",
            "sd_control_collection\\kohya_controllllite_xl_canny.safetensors",
            "sd_control_collection\\kohya_controllllite_xl_canny_anime.safetensors",
            "sd_control_collection\\kohya_controllllite_xl_depth.safetensors",
            "sd_control_collection\\kohya_controllllite_xl_depth_anime.safetensors",
            "sd_control_collection\\kohya_controllllite_xl_openpose_anime.safetensors",
            "sd_control_collection\\kohya_controllllite_xl_openpose_anime_v2.safetensors",
            "sd_control_collection\\kohya_controllllite_xl_scribble_anime.safetensors",
            "sd_control_collection\\sai_xl_canny_128lora.safetensors",
            "sd_control_collection\\sai_xl_canny_256lora.safetensors",
            "sd_control_collection\\sai_xl_depth_128lora.safetensors",
            "sd_control_collection\\sai_xl_depth_256lora.safetensors",
            "sd_control_collection\\sai_xl_recolor_128lora.safetensors",
            "sd_control_collection\\sai_xl_recolor_256lora.safetensors",
            "sd_control_collection\\sai_xl_sketch_128lora.safetensors",
            "sd_control_collection\\sai_xl_sketch_256lora.safetensors",
            "sd_control_collection\\sargezt_xl_depth.safetensors",
            "sd_control_collection\\sargezt_xl_depth_faid_vidit.safetensors",
            "sd_control_collection\\sargezt_xl_depth_zeed.safetensors",
            "sd_control_collection\\sargezt_xl_softedge.safetensors",
            "sd_control_collection\\t2i-adapter_diffusers_xl_canny.safetensors",
            "sd_control_collection\\t2i-adapter_diffusers_xl_depth_midas.safetensors",
            "sd_control_collection\\t2i-adapter_diffusers_xl_depth_zoe.safetensors",
            "sd_control_collection\\t2i-adapter_diffusers_xl_lineart.safetensors",
            "sd_control_collection\\t2i-adapter_diffusers_xl_openpose.safetensors",
            "sd_control_collection\\t2i-adapter_diffusers_xl_sketch.safetensors",
            "sd_control_collection\\t2i-adapter_xl_canny.safetensors",
            "sd_control_collection\\t2i-adapter_xl_openpose.safetensors",
            "sd_control_collection\\t2i-adapter_xl_sketch.safetensors",
            "sd_control_collection\\thibaud_xl_openpose.safetensors",
            "seg\\diffusion_pytorch_model.safetensors",
            "shuffle\\diffusion_pytorch_model.safetensors",
            "softedge\\diffusion_pytorch_model.safetensors",
            "t2i-adapter-canny-sdxl-1.0\\diffusion_pytorch_model.safetensors",
            "t2i-adapter-depth-midas-sdxl-1.0\\diffusion_pytorch_model.safetensors",
            "t2i-adapter-depth-zoe-sdxl-1.0\\diffusion_pytorch_model.safetensors",
            "t2i-adapter-openpose-sdxl-1.0\\diffusion_pytorch_model.safetensors",
            "t2i-adapter-sketch-sdxl-1.0\\diffusion_pytorch_model.safetensors",
            "t2iadapter_canny_sd15v2\\diffusion_pytorch_model.bin",
            "t2iadapter_depth_sd15v2\\diffusion_pytorch_model.bin",
            "t2iadapter_sketch_sd15v2\\diffusion_pytorch_model.bin",
            "t2iadapter_zoedepth_sd15v1\\diffusion_pytorch_model.bin",
            "tile\\diffusion_pytorch_model.bin",
          ],
        ],
      },
    },
    input_order: { required: ["model", "control_net_name"] },
    output: ["CONTROL_NET"],
    output_is_list: [false],
    output_name: ["CONTROL_NET"],
    name: "DiffControlNetLoader",
    display_name: "Load ControlNet Model (diff)",
    description: "",
    python_module: "nodes",
    category: "loaders",
    output_node: false,
  },
  StyleModelLoader: {
    input: { required: { style_model_name: [[]] } },
    input_order: { required: ["style_model_name"] },
    output: ["STYLE_MODEL"],
    output_is_list: [false],
    output_name: ["STYLE_MODEL"],
    name: "StyleModelLoader",
    display_name: "Load Style Model",
    description: "",
    python_module: "nodes",
    category: "loaders",
    output_node: false,
  },
  CLIPVisionLoader: {
    input: {
      required: {
        clip_name: [
          [
            "ip_adapter_sd_image_encoder\\model.safetensors",
            "ip_adapter_sdxl_image_encoder\\model.safetensors",
          ],
        ],
      },
    },
    input_order: { required: ["clip_name"] },
    output: ["CLIP_VISION"],
    output_is_list: [false],
    output_name: ["CLIP_VISION"],
    name: "CLIPVisionLoader",
    display_name: "Load CLIP Vision",
    description: "",
    python_module: "nodes",
    category: "loaders",
    output_node: false,
  },
  VAEDecodeTiled: {
    input: {
      required: {
        samples: ["LATENT"],
        vae: ["VAE"],
        tile_size: ["INT", { default: 512, min: 320, max: 4096, step: 64 }],
      },
    },
    input_order: { required: ["samples", "vae", "tile_size"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "VAEDecodeTiled",
    display_name: "VAE Decode (Tiled)",
    description: "",
    python_module: "nodes",
    category: "_for_testing",
    output_node: false,
  },
  VAEEncodeTiled: {
    input: {
      required: {
        pixels: ["IMAGE"],
        vae: ["VAE"],
        tile_size: ["INT", { default: 512, min: 320, max: 4096, step: 64 }],
      },
    },
    input_order: { required: ["pixels", "vae", "tile_size"] },
    output: ["LATENT"],
    output_is_list: [false],
    output_name: ["LATENT"],
    name: "VAEEncodeTiled",
    display_name: "VAE Encode (Tiled)",
    description: "",
    python_module: "nodes",
    category: "_for_testing",
    output_node: false,
  },
  unCLIPCheckpointLoader: {
    input: {
      required: {
        ckpt_name: [
          [
            "Flux\\blue_pencil-flux1-v0.1.0-nf4.safetensors",
            "Flux\\carnivalUnchained_v10.safetensors",
            "Flux\\flux1-dev-bnb-nf4-v2.safetensors",
            "Flux\\fluximation_v1NF4.safetensors",
            "Flux\\lemonmixFLUX_protoFP8.safetensors",
            "Flux\\xeHentaiAnimeFlux_04.safetensors",
            "Pony\\boleromixPony_v141VAE.safetensors",
            "Pony\\boleromixSDXL_v13.safetensors",
            "SD1.0\\anime\\RealBackground_v12.safetensors",
            "SD1.0\\anime\\akinamixBE.safetensors",
            "SD1.0\\anime\\ambientgrapemixForAnime2D_v11.ckpt",
            "SD1.0\\anime\\animeScreencapStyle_assV13.safetensors",
            "SD1.0\\anime\\coffeensfw_v10.safetensors",
            "SD1.0\\anime\\colorfulAnimeXLXL_v20.safetensors",
            "SD1.0\\anime\\yden_v20.safetensors",
            "SD1.0\\other\\chosenIrisesMix_chosenIrisesMixV10.safetensors",
            "SD1.0\\other\\fantasyBackground_v10PrunedFp16.safetensors",
            "SD1.0\\other\\idkwimixNSFW_deformedV2.safetensors",
            "SD1.0\\other\\orientalPunkMix_orientalPunkFlower.ckpt",
            "SD1.0\\other\\threeDelicacyWonton_sanxianwontonmixv1.safetensors",
            "SD1.0\\real\\Guofengrealmix_v10.safetensors",
            "SD1.0\\real\\chilledReGenericV3_v10.safetensors",
            "SD1.0\\real\\chilloutmix_NiPrunedFp32Fix.ckpt",
            "SD1.0\\real\\fantasticmix_v40.safetensors",
            "SD1.0\\real\\snapdd00_v1.safetensors",
            "SD1.0\\real\\xxmix9realistic_v25.safetensors",
            "SD1.0\\semi_real\\comiNoirClassicV2.safetensors",
            "XL\\9527DetailRealistic_v50Bakedvae.safetensors",
            "XL\\NSFWAnimexl_10.safetensors",
            "XL\\anime2.5_animeArtDiffusionXL_alpha3.safetensors",
            "XL\\anime2.5_bluePencilXL_v401.safetensors",
            "XL\\anime2.5_breakdomainxl_V06d.safetensors",
            "XL\\anime2.5_counterfeitxl_v25.safetensors",
            "XL\\anime2.5_deepblueXL_v060.safetensors",
            "XL\\anime2.5_explicitFreedomNSFW_alpha.safetensors",
            "XL\\anime2.5_himawarimix_xlV2.safetensors",
            "XL\\anime2.5_kohakuXLBeta_beta7.safetensors",
            "XL\\anime2.5_reproductionSDXL_2v12.safetensors",
            "XL\\anime2.5_yesmixXL_v10.safetensors",
            "XL\\anime_aamXLAnimeMix_v10.civitai.safetensors",
            "XL\\anime_animagineXLV3_v30.safetensors",
            "XL\\anime_hassakuXLSfwNsfwBeta_betaV04.safetensors",
            "XL\\anime_notAnimefullFinalXL_v10.safetensors",
            "XL\\anime_sdxlYamersAnimeUltra_yamersAnimeV2.safetensors",
            "XL\\baxlBlueArchiveFlatCelluloidStyleFineTune_xlv3.safetensors",
            "XL\\real_4Guofeng4XL_v10Beta.safetensors",
            "XL\\real_cherrypickerXL_v27.safetensors",
            "XL\\real_realvisxlV40_v40LightningBakedvae.safetensors",
            "XL\\real_sdvn6Realxl_detailface.safetensors",
            "XL\\real_sdxl10ArienmixxlAsian_v40Pruned.safetensors",
            "XL\\real_xxmix9realisticsdxl_v10.safetensors",
            "animatBackgroundV1_03.safetensors",
            "sd_xl_base_1.0_0.9vae.safetensors",
          ],
        ],
      },
    },
    input_order: { required: ["ckpt_name"] },
    output: ["MODEL", "CLIP", "VAE", "CLIP_VISION"],
    output_is_list: [false, false, false, false],
    output_name: ["MODEL", "CLIP", "VAE", "CLIP_VISION"],
    name: "unCLIPCheckpointLoader",
    display_name: "unCLIPCheckpointLoader",
    description: "",
    python_module: "nodes",
    category: "loaders",
    output_node: false,
  },
  GLIGENLoader: {
    input: { required: { gligen_name: [[]] } },
    input_order: { required: ["gligen_name"] },
    output: ["GLIGEN"],
    output_is_list: [false],
    output_name: ["GLIGEN"],
    name: "GLIGENLoader",
    display_name: "GLIGENLoader",
    description: "",
    python_module: "nodes",
    category: "loaders",
    output_node: false,
  },
  GLIGENTextBoxApply: {
    input: {
      required: {
        conditioning_to: ["CONDITIONING"],
        clip: ["CLIP"],
        gligen_textbox_model: ["GLIGEN"],
        text: ["STRING", { multiline: true, dynamicPrompts: true }],
        width: ["INT", { default: 64, min: 8, max: 16384, step: 8 }],
        height: ["INT", { default: 64, min: 8, max: 16384, step: 8 }],
        x: ["INT", { default: 0, min: 0, max: 16384, step: 8 }],
        y: ["INT", { default: 0, min: 0, max: 16384, step: 8 }],
      },
    },
    input_order: {
      required: [
        "conditioning_to",
        "clip",
        "gligen_textbox_model",
        "text",
        "width",
        "height",
        "x",
        "y",
      ],
    },
    output: ["CONDITIONING"],
    output_is_list: [false],
    output_name: ["CONDITIONING"],
    name: "GLIGENTextBoxApply",
    display_name: "GLIGENTextBoxApply",
    description: "",
    python_module: "nodes",
    category: "conditioning/gligen",
    output_node: false,
  },
  InpaintModelConditioning: {
    input: {
      required: {
        positive: ["CONDITIONING"],
        negative: ["CONDITIONING"],
        vae: ["VAE"],
        pixels: ["IMAGE"],
        mask: ["MASK"],
      },
    },
    input_order: {
      required: ["positive", "negative", "vae", "pixels", "mask"],
    },
    output: ["CONDITIONING", "CONDITIONING", "LATENT"],
    output_is_list: [false, false, false],
    output_name: ["positive", "negative", "latent"],
    name: "InpaintModelConditioning",
    display_name: "InpaintModelConditioning",
    description: "",
    python_module: "nodes",
    category: "conditioning/inpaint",
    output_node: false,
  },
  CheckpointLoader: {
    input: {
      required: {
        config_name: [
          [
            "anything_v3.yaml",
            "v1-inference.yaml",
            "v1-inference_clip_skip_2.yaml",
            "v1-inference_clip_skip_2_fp16.yaml",
            "v1-inference_fp16.yaml",
            "v1-inpainting-inference.yaml",
            "v2-inference-v.yaml",
            "v2-inference-v_fp32.yaml",
            "v2-inference.yaml",
            "v2-inference_fp32.yaml",
            "v2-inpainting-inference.yaml",
          ],
        ],
        ckpt_name: [
          [
            "Flux\\blue_pencil-flux1-v0.1.0-nf4.safetensors",
            "Flux\\carnivalUnchained_v10.safetensors",
            "Flux\\flux1-dev-bnb-nf4-v2.safetensors",
            "Flux\\fluximation_v1NF4.safetensors",
            "Flux\\lemonmixFLUX_protoFP8.safetensors",
            "Flux\\xeHentaiAnimeFlux_04.safetensors",
            "XL\\real_sdxl10ArienmixxlAsian_v40Pruned.safetensors",
            "XL\\real_xxmix9realisticsdxl_v10.safetensors",
            "animatBackgroundV1_03.safetensors",
            "sd_xl_base_1.0_0.9vae.safetensors",
          ],
        ],
      },
    },
    input_order: { required: ["config_name", "ckpt_name"] },
    output: ["MODEL", "CLIP", "VAE"],
    output_is_list: [false, false, false],
    output_name: ["MODEL", "CLIP", "VAE"],
    name: "CheckpointLoader",
    display_name: "Load Checkpoint With Config (DEPRECATED)",
    description: "",
    python_module: "nodes",
    category: "advanced/loaders",
    output_node: false,
    deprecated: true,
  },
  DiffusersLoader: {
    input: { required: { model_path: [[]] } },
    input_order: { required: ["model_path"] },
    output: ["MODEL", "CLIP", "VAE"],
    output_is_list: [false, false, false],
    output_name: ["MODEL", "CLIP", "VAE"],
    name: "DiffusersLoader",
    display_name: "DiffusersLoader",
    description: "",
    python_module: "nodes",
    category: "advanced/loaders/deprecated",
    output_node: false,
  },
  LoadLatent: {
    input: { required: { latent: [[]] } },
    input_order: { required: ["latent"] },
    output: ["LATENT"],
    output_is_list: [false],
    output_name: ["LATENT"],
    name: "LoadLatent",
    display_name: "LoadLatent",
    description: "",
    python_module: "nodes",
    category: "_for_testing",
    output_node: false,
  },
  SaveLatent: {
    input: {
      required: {
        samples: ["LATENT"],
        filename_prefix: ["STRING", { default: "latents/ComfyUI" }],
      },
      hidden: { prompt: "PROMPT", extra_pnginfo: "EXTRA_PNGINFO" },
    },
    input_order: {
      required: ["samples", "filename_prefix"],
      hidden: ["prompt", "extra_pnginfo"],
    },
    output: [],
    output_is_list: [],
    output_name: [],
    name: "SaveLatent",
    display_name: "SaveLatent",
    description: "",
    python_module: "nodes",
    category: "_for_testing",
    output_node: true,
  },
  ConditioningZeroOut: {
    input: { required: { conditioning: ["CONDITIONING"] } },
    input_order: { required: ["conditioning"] },
    output: ["CONDITIONING"],
    output_is_list: [false],
    output_name: ["CONDITIONING"],
    name: "ConditioningZeroOut",
    display_name: "ConditioningZeroOut",
    description: "",
    python_module: "nodes",
    category: "advanced/conditioning",
    output_node: false,
  },
  ConditioningSetTimestepRange: {
    input: {
      required: {
        conditioning: ["CONDITIONING"],
        start: ["FLOAT", { default: 0.0, min: 0.0, max: 1.0, step: 0.001 }],
        end: ["FLOAT", { default: 1.0, min: 0.0, max: 1.0, step: 0.001 }],
      },
    },
    input_order: { required: ["conditioning", "start", "end"] },
    output: ["CONDITIONING"],
    output_is_list: [false],
    output_name: ["CONDITIONING"],
    name: "ConditioningSetTimestepRange",
    display_name: "ConditioningSetTimestepRange",
    description: "",
    python_module: "nodes",
    category: "advanced/conditioning",
    output_node: false,
  },
  LoraLoaderModelOnly: {
    input: {
      required: {
        model: ["MODEL"],
        lora_name: [
          [
            "CleanLineArt.safetensors",
            "Flux\\Doujinshi-000001.safetensors",
            "Flux\\Doujinshi-v2-000001.safetensors",
            "Flux\\Doujinshi-v2-000002.safetensors",
            "Flux\\Doujinshi-v2.safetensors",
            "pregnant-05.safetensors",
            "satoukuukiXL_ANI31_lokr_V42310.safetensors",
            "sd_xl_offset_example-lora_1.0.safetensors",
            "sketch_style.safetensors",
            "takedaXL_ANI31_lokr_V4236.safetensors",
            "wafuku gothic_XL_V1.0.safetensors",
            "xl_one finger selfie challenge(kohaku_delta)2.safetensors",
          ],
        ],
        strength_model: [
          "FLOAT",
          { default: 1.0, min: -100.0, max: 100.0, step: 0.01 },
        ],
      },
    },
    input_order: { required: ["model", "lora_name", "strength_model"] },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "LoraLoaderModelOnly",
    display_name: "LoraLoaderModelOnly",
    description:
      "LoRAs are used to modify diffusion and CLIP models, altering the way in which latents are denoised such as applying styles. Multiple LoRA nodes can be linked together.",
    python_module: "nodes",
    category: "loaders",
    output_node: false,
    output_tooltips: [
      "The modified diffusion model.",
      "The modified CLIP model.",
    ],
  },
  LatentAdd: {
    input: { required: { samples1: ["LATENT"], samples2: ["LATENT"] } },
    input_order: { required: ["samples1", "samples2"] },
    output: ["LATENT"],
    output_is_list: [false],
    output_name: ["LATENT"],
    name: "LatentAdd",
    display_name: "LatentAdd",
    description: "",
    python_module: "comfy_extras.nodes_latent",
    category: "latent/advanced",
    output_node: false,
  },
  LatentSubtract: {
    input: { required: { samples1: ["LATENT"], samples2: ["LATENT"] } },
    input_order: { required: ["samples1", "samples2"] },
    output: ["LATENT"],
    output_is_list: [false],
    output_name: ["LATENT"],
    name: "LatentSubtract",
    display_name: "LatentSubtract",
    description: "",
    python_module: "comfy_extras.nodes_latent",
    category: "latent/advanced",
    output_node: false,
  },
  LatentMultiply: {
    input: {
      required: {
        samples: ["LATENT"],
        multiplier: [
          "FLOAT",
          { default: 1.0, min: -10.0, max: 10.0, step: 0.01 },
        ],
      },
    },
    input_order: { required: ["samples", "multiplier"] },
    output: ["LATENT"],
    output_is_list: [false],
    output_name: ["LATENT"],
    name: "LatentMultiply",
    display_name: "LatentMultiply",
    description: "",
    python_module: "comfy_extras.nodes_latent",
    category: "latent/advanced",
    output_node: false,
  },
  LatentInterpolate: {
    input: {
      required: {
        samples1: ["LATENT"],
        samples2: ["LATENT"],
        ratio: ["FLOAT", { default: 1.0, min: 0.0, max: 1.0, step: 0.01 }],
      },
    },
    input_order: { required: ["samples1", "samples2", "ratio"] },
    output: ["LATENT"],
    output_is_list: [false],
    output_name: ["LATENT"],
    name: "LatentInterpolate",
    display_name: "LatentInterpolate",
    description: "",
    python_module: "comfy_extras.nodes_latent",
    category: "latent/advanced",
    output_node: false,
  },
  LatentBatch: {
    input: { required: { samples1: ["LATENT"], samples2: ["LATENT"] } },
    input_order: { required: ["samples1", "samples2"] },
    output: ["LATENT"],
    output_is_list: [false],
    output_name: ["LATENT"],
    name: "LatentBatch",
    display_name: "LatentBatch",
    description: "",
    python_module: "comfy_extras.nodes_latent",
    category: "latent/batch",
    output_node: false,
  },
  LatentBatchSeedBehavior: {
    input: {
      required: {
        samples: ["LATENT"],
        seed_behavior: [["random", "fixed"], { default: "fixed" }],
      },
    },
    input_order: { required: ["samples", "seed_behavior"] },
    output: ["LATENT"],
    output_is_list: [false],
    output_name: ["LATENT"],
    name: "LatentBatchSeedBehavior",
    display_name: "LatentBatchSeedBehavior",
    description: "",
    python_module: "comfy_extras.nodes_latent",
    category: "latent/advanced",
    output_node: false,
  },
  HypernetworkLoader: {
    input: {
      required: {
        model: ["MODEL"],
        hypernetwork_name: [[]],
        strength: [
          "FLOAT",
          { default: 1.0, min: -10.0, max: 10.0, step: 0.01 },
        ],
      },
    },
    input_order: { required: ["model", "hypernetwork_name", "strength"] },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "HypernetworkLoader",
    display_name: "HypernetworkLoader",
    description: "",
    python_module: "comfy_extras.nodes_hypernetwork",
    category: "loaders",
    output_node: false,
  },
  UpscaleModelLoader: {
    input: {
      required: {
        model_name: [
          [
            "4x-UltraSharp.pth",
            "RealESRGAN_x4plus.pth",
            "RealESRGAN_x4plus_anime_6B.pth",
            "SwinIR_4x.pth",
          ],
        ],
      },
    },
    input_order: { required: ["model_name"] },
    output: ["UPSCALE_MODEL"],
    output_is_list: [false],
    output_name: ["UPSCALE_MODEL"],
    name: "UpscaleModelLoader",
    display_name: "Load Upscale Model",
    description: "",
    python_module: "comfy_extras.nodes_upscale_model",
    category: "loaders",
    output_node: false,
  },
  ImageUpscaleWithModel: {
    input: { required: { upscale_model: ["UPSCALE_MODEL"], image: ["IMAGE"] } },
    input_order: { required: ["upscale_model", "image"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "ImageUpscaleWithModel",
    display_name: "Upscale Image (using Model)",
    description: "",
    python_module: "comfy_extras.nodes_upscale_model",
    category: "image/upscaling",
    output_node: false,
  },
  ImageBlend: {
    input: {
      required: {
        image1: ["IMAGE"],
        image2: ["IMAGE"],
        blend_factor: [
          "FLOAT",
          { default: 0.5, min: 0.0, max: 1.0, step: 0.01 },
        ],
        blend_mode: [
          [
            "normal",
            "multiply",
            "screen",
            "overlay",
            "soft_light",
            "difference",
          ],
        ],
      },
    },
    input_order: {
      required: ["image1", "image2", "blend_factor", "blend_mode"],
    },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "ImageBlend",
    display_name: "ImageBlend",
    description: "",
    python_module: "comfy_extras.nodes_post_processing",
    category: "image/postprocessing",
    output_node: false,
  },
  ImageBlur: {
    input: {
      required: {
        image: ["IMAGE"],
        blur_radius: ["INT", { default: 1, min: 1, max: 31, step: 1 }],
        sigma: ["FLOAT", { default: 1.0, min: 0.1, max: 10.0, step: 0.1 }],
      },
    },
    input_order: { required: ["image", "blur_radius", "sigma"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "ImageBlur",
    display_name: "ImageBlur",
    description: "",
    python_module: "comfy_extras.nodes_post_processing",
    category: "image/postprocessing",
    output_node: false,
  },
  ImageQuantize: {
    input: {
      required: {
        image: ["IMAGE"],
        colors: ["INT", { default: 256, min: 1, max: 256, step: 1 }],
        dither: [
          [
            "none",
            "floyd-steinberg",
            "bayer-2",
            "bayer-4",
            "bayer-8",
            "bayer-16",
          ],
        ],
      },
    },
    input_order: { required: ["image", "colors", "dither"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "ImageQuantize",
    display_name: "ImageQuantize",
    description: "",
    python_module: "comfy_extras.nodes_post_processing",
    category: "image/postprocessing",
    output_node: false,
  },
  ImageSharpen: {
    input: {
      required: {
        image: ["IMAGE"],
        sharpen_radius: ["INT", { default: 1, min: 1, max: 31, step: 1 }],
        sigma: ["FLOAT", { default: 1.0, min: 0.1, max: 10.0, step: 0.01 }],
        alpha: ["FLOAT", { default: 1.0, min: 0.0, max: 5.0, step: 0.01 }],
      },
    },
    input_order: { required: ["image", "sharpen_radius", "sigma", "alpha"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "ImageSharpen",
    display_name: "ImageSharpen",
    description: "",
    python_module: "comfy_extras.nodes_post_processing",
    category: "image/postprocessing",
    output_node: false,
  },
  ImageScaleToTotalPixels: {
    input: {
      required: {
        image: ["IMAGE"],
        upscale_method: [
          ["nearest-exact", "bilinear", "area", "bicubic", "lanczos"],
        ],
        megapixels: [
          "FLOAT",
          { default: 1.0, min: 0.01, max: 16.0, step: 0.01 },
        ],
      },
    },
    input_order: { required: ["image", "upscale_method", "megapixels"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "ImageScaleToTotalPixels",
    display_name: "ImageScaleToTotalPixels",
    description: "",
    python_module: "comfy_extras.nodes_post_processing",
    category: "image/upscaling",
    output_node: false,
  },
  LatentCompositeMasked: {
    input: {
      required: {
        destination: ["LATENT"],
        source: ["LATENT"],
        x: ["INT", { default: 0, min: 0, max: 16384, step: 8 }],
        y: ["INT", { default: 0, min: 0, max: 16384, step: 8 }],
        resize_source: ["BOOLEAN", { default: false }],
      },
      optional: { mask: ["MASK"] },
    },
    input_order: {
      required: ["destination", "source", "x", "y", "resize_source"],
      optional: ["mask"],
    },
    output: ["LATENT"],
    output_is_list: [false],
    output_name: ["LATENT"],
    name: "LatentCompositeMasked",
    display_name: "LatentCompositeMasked",
    description: "",
    python_module: "comfy_extras.nodes_mask",
    category: "latent",
    output_node: false,
  },
  ImageCompositeMasked: {
    input: {
      required: {
        destination: ["IMAGE"],
        source: ["IMAGE"],
        x: ["INT", { default: 0, min: 0, max: 16384, step: 1 }],
        y: ["INT", { default: 0, min: 0, max: 16384, step: 1 }],
        resize_source: ["BOOLEAN", { default: false }],
      },
      optional: { mask: ["MASK"] },
    },
    input_order: {
      required: ["destination", "source", "x", "y", "resize_source"],
      optional: ["mask"],
    },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "ImageCompositeMasked",
    display_name: "ImageCompositeMasked",
    description: "",
    python_module: "comfy_extras.nodes_mask",
    category: "image",
    output_node: false,
  },
  MaskToImage: {
    input: { required: { mask: ["MASK"] } },
    input_order: { required: ["mask"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "MaskToImage",
    display_name: "Convert Mask to Image",
    description: "",
    python_module: "comfy_extras.nodes_mask",
    category: "mask",
    output_node: false,
  },
  ImageToMask: {
    input: {
      required: {
        image: ["IMAGE"],
        channel: [["red", "green", "blue", "alpha"]],
      },
    },
    input_order: { required: ["image", "channel"] },
    output: ["MASK"],
    output_is_list: [false],
    output_name: ["MASK"],
    name: "ImageToMask",
    display_name: "Convert Image to Mask",
    description: "",
    python_module: "comfy_extras.nodes_mask",
    category: "mask",
    output_node: false,
  },
  ImageColorToMask: {
    input: {
      required: {
        image: ["IMAGE"],
        color: [
          "INT",
          { default: 0, min: 0, max: 16777215, step: 1, display: "color" },
        ],
      },
    },
    input_order: { required: ["image", "color"] },
    output: ["MASK"],
    output_is_list: [false],
    output_name: ["MASK"],
    name: "ImageColorToMask",
    display_name: "ImageColorToMask",
    description: "",
    python_module: "comfy_extras.nodes_mask",
    category: "mask",
    output_node: false,
  },
  SolidMask: {
    input: {
      required: {
        value: ["FLOAT", { default: 1.0, min: 0.0, max: 1.0, step: 0.01 }],
        width: ["INT", { default: 512, min: 1, max: 16384, step: 1 }],
        height: ["INT", { default: 512, min: 1, max: 16384, step: 1 }],
      },
    },
    input_order: { required: ["value", "width", "height"] },
    output: ["MASK"],
    output_is_list: [false],
    output_name: ["MASK"],
    name: "SolidMask",
    display_name: "SolidMask",
    description: "",
    python_module: "comfy_extras.nodes_mask",
    category: "mask",
    output_node: false,
  },
  InvertMask: {
    input: { required: { mask: ["MASK"] } },
    input_order: { required: ["mask"] },
    output: ["MASK"],
    output_is_list: [false],
    output_name: ["MASK"],
    name: "InvertMask",
    display_name: "InvertMask",
    description: "",
    python_module: "comfy_extras.nodes_mask",
    category: "mask",
    output_node: false,
  },
  CropMask: {
    input: {
      required: {
        mask: ["MASK"],
        x: ["INT", { default: 0, min: 0, max: 16384, step: 1 }],
        y: ["INT", { default: 0, min: 0, max: 16384, step: 1 }],
        width: ["INT", { default: 512, min: 1, max: 16384, step: 1 }],
        height: ["INT", { default: 512, min: 1, max: 16384, step: 1 }],
      },
    },
    input_order: { required: ["mask", "x", "y", "width", "height"] },
    output: ["MASK"],
    output_is_list: [false],
    output_name: ["MASK"],
    name: "CropMask",
    display_name: "CropMask",
    description: "",
    python_module: "comfy_extras.nodes_mask",
    category: "mask",
    output_node: false,
  },
  MaskComposite: {
    input: {
      required: {
        destination: ["MASK"],
        source: ["MASK"],
        x: ["INT", { default: 0, min: 0, max: 16384, step: 1 }],
        y: ["INT", { default: 0, min: 0, max: 16384, step: 1 }],
        operation: [["multiply", "add", "subtract", "and", "or", "xor"]],
      },
    },
    input_order: { required: ["destination", "source", "x", "y", "operation"] },
    output: ["MASK"],
    output_is_list: [false],
    output_name: ["MASK"],
    name: "MaskComposite",
    display_name: "MaskComposite",
    description: "",
    python_module: "comfy_extras.nodes_mask",
    category: "mask",
    output_node: false,
  },
  FeatherMask: {
    input: {
      required: {
        mask: ["MASK"],
        left: ["INT", { default: 0, min: 0, max: 16384, step: 1 }],
        top: ["INT", { default: 0, min: 0, max: 16384, step: 1 }],
        right: ["INT", { default: 0, min: 0, max: 16384, step: 1 }],
        bottom: ["INT", { default: 0, min: 0, max: 16384, step: 1 }],
      },
    },
    input_order: { required: ["mask", "left", "top", "right", "bottom"] },
    output: ["MASK"],
    output_is_list: [false],
    output_name: ["MASK"],
    name: "FeatherMask",
    display_name: "FeatherMask",
    description: "",
    python_module: "comfy_extras.nodes_mask",
    category: "mask",
    output_node: false,
  },
  GrowMask: {
    input: {
      required: {
        mask: ["MASK"],
        expand: ["INT", { default: 0, min: -16384, max: 16384, step: 1 }],
        tapered_corners: ["BOOLEAN", { default: true }],
      },
    },
    input_order: { required: ["mask", "expand", "tapered_corners"] },
    output: ["MASK"],
    output_is_list: [false],
    output_name: ["MASK"],
    name: "GrowMask",
    display_name: "GrowMask",
    description: "",
    python_module: "comfy_extras.nodes_mask",
    category: "mask",
    output_node: false,
  },
  ThresholdMask: {
    input: {
      required: {
        mask: ["MASK"],
        value: ["FLOAT", { default: 0.5, min: 0.0, max: 1.0, step: 0.01 }],
      },
    },
    input_order: { required: ["mask", "value"] },
    output: ["MASK"],
    output_is_list: [false],
    output_name: ["MASK"],
    name: "ThresholdMask",
    display_name: "ThresholdMask",
    description: "",
    python_module: "comfy_extras.nodes_mask",
    category: "mask",
    output_node: false,
  },
  PorterDuffImageComposite: {
    input: {
      required: {
        source: ["IMAGE"],
        source_alpha: ["MASK"],
        destination: ["IMAGE"],
        destination_alpha: ["MASK"],
        mode: [
          [
            "ADD",
            "CLEAR",
            "DARKEN",
            "DST",
            "DST_ATOP",
            "DST_IN",
            "DST_OUT",
            "DST_OVER",
            "LIGHTEN",
            "MULTIPLY",
            "OVERLAY",
            "SCREEN",
            "SRC",
            "SRC_ATOP",
            "SRC_IN",
            "SRC_OUT",
            "SRC_OVER",
            "XOR",
          ],
          { default: "DST" },
        ],
      },
    },
    input_order: {
      required: [
        "source",
        "source_alpha",
        "destination",
        "destination_alpha",
        "mode",
      ],
    },
    output: ["IMAGE", "MASK"],
    output_is_list: [false, false],
    output_name: ["IMAGE", "MASK"],
    name: "PorterDuffImageComposite",
    display_name: "Porter-Duff Image Composite",
    description: "",
    python_module: "comfy_extras.nodes_compositing",
    category: "mask/compositing",
    output_node: false,
  },
  SplitImageWithAlpha: {
    input: { required: { image: ["IMAGE"] } },
    input_order: { required: ["image"] },
    output: ["IMAGE", "MASK"],
    output_is_list: [false, false],
    output_name: ["IMAGE", "MASK"],
    name: "SplitImageWithAlpha",
    display_name: "Split Image with Alpha",
    description: "",
    python_module: "comfy_extras.nodes_compositing",
    category: "mask/compositing",
    output_node: false,
  },
  JoinImageWithAlpha: {
    input: { required: { image: ["IMAGE"], alpha: ["MASK"] } },
    input_order: { required: ["image", "alpha"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "JoinImageWithAlpha",
    display_name: "Join Image with Alpha",
    description: "",
    python_module: "comfy_extras.nodes_compositing",
    category: "mask/compositing",
    output_node: false,
  },
  RebatchLatents: {
    input: {
      required: {
        latents: ["LATENT"],
        batch_size: ["INT", { default: 1, min: 1, max: 4096 }],
      },
    },
    input_order: { required: ["latents", "batch_size"] },
    output: ["LATENT"],
    output_is_list: [true],
    output_name: ["LATENT"],
    name: "RebatchLatents",
    display_name: "Rebatch Latents",
    description: "",
    python_module: "comfy_extras.nodes_rebatch",
    category: "latent/batch",
    output_node: false,
  },
  RebatchImages: {
    input: {
      required: {
        images: ["IMAGE"],
        batch_size: ["INT", { default: 1, min: 1, max: 4096 }],
      },
    },
    input_order: { required: ["images", "batch_size"] },
    output: ["IMAGE"],
    output_is_list: [true],
    output_name: ["IMAGE"],
    name: "RebatchImages",
    display_name: "Rebatch Images",
    description: "",
    python_module: "comfy_extras.nodes_rebatch",
    category: "image/batch",
    output_node: false,
  },
  ModelMergeSimple: {
    input: {
      required: {
        model1: ["MODEL"],
        model2: ["MODEL"],
        ratio: ["FLOAT", { default: 1.0, min: 0.0, max: 1.0, step: 0.01 }],
      },
    },
    input_order: { required: ["model1", "model2", "ratio"] },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "ModelMergeSimple",
    display_name: "ModelMergeSimple",
    description: "",
    python_module: "comfy_extras.nodes_model_merging",
    category: "advanced/model_merging",
    output_node: false,
  },
  ModelMergeBlocks: {
    input: {
      required: {
        model1: ["MODEL"],
        model2: ["MODEL"],
        input: ["FLOAT", { default: 1.0, min: 0.0, max: 1.0, step: 0.01 }],
        middle: ["FLOAT", { default: 1.0, min: 0.0, max: 1.0, step: 0.01 }],
        out: ["FLOAT", { default: 1.0, min: 0.0, max: 1.0, step: 0.01 }],
      },
    },
    input_order: { required: ["model1", "model2", "input", "middle", "out"] },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "ModelMergeBlocks",
    display_name: "ModelMergeBlocks",
    description: "",
    python_module: "comfy_extras.nodes_model_merging",
    category: "advanced/model_merging",
    output_node: false,
  },
  ModelMergeSubtract: {
    input: {
      required: {
        model1: ["MODEL"],
        model2: ["MODEL"],
        multiplier: [
          "FLOAT",
          { default: 1.0, min: -10.0, max: 10.0, step: 0.01 },
        ],
      },
    },
    input_order: { required: ["model1", "model2", "multiplier"] },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "ModelMergeSubtract",
    display_name: "ModelMergeSubtract",
    description: "",
    python_module: "comfy_extras.nodes_model_merging",
    category: "advanced/model_merging",
    output_node: false,
  },
  ModelMergeAdd: {
    input: { required: { model1: ["MODEL"], model2: ["MODEL"] } },
    input_order: { required: ["model1", "model2"] },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "ModelMergeAdd",
    display_name: "ModelMergeAdd",
    description: "",
    python_module: "comfy_extras.nodes_model_merging",
    category: "advanced/model_merging",
    output_node: false,
  },
  CheckpointSave: {
    input: {
      required: {
        model: ["MODEL"],
        clip: ["CLIP"],
        vae: ["VAE"],
        filename_prefix: ["STRING", { default: "checkpoints/ComfyUI" }],
      },
      hidden: { prompt: "PROMPT", extra_pnginfo: "EXTRA_PNGINFO" },
    },
    input_order: {
      required: ["model", "clip", "vae", "filename_prefix"],
      hidden: ["prompt", "extra_pnginfo"],
    },
    output: [],
    output_is_list: [],
    output_name: [],
    name: "CheckpointSave",
    display_name: "Save Checkpoint",
    description: "",
    python_module: "comfy_extras.nodes_model_merging",
    category: "advanced/model_merging",
    output_node: true,
  },
  CLIPMergeSimple: {
    input: {
      required: {
        clip1: ["CLIP"],
        clip2: ["CLIP"],
        ratio: ["FLOAT", { default: 1.0, min: 0.0, max: 1.0, step: 0.01 }],
      },
    },
    input_order: { required: ["clip1", "clip2", "ratio"] },
    output: ["CLIP"],
    output_is_list: [false],
    output_name: ["CLIP"],
    name: "CLIPMergeSimple",
    display_name: "CLIPMergeSimple",
    description: "",
    python_module: "comfy_extras.nodes_model_merging",
    category: "advanced/model_merging",
    output_node: false,
  },
  CLIPMergeSubtract: {
    input: {
      required: {
        clip1: ["CLIP"],
        clip2: ["CLIP"],
        multiplier: [
          "FLOAT",
          { default: 1.0, min: -10.0, max: 10.0, step: 0.01 },
        ],
      },
    },
    input_order: { required: ["clip1", "clip2", "multiplier"] },
    output: ["CLIP"],
    output_is_list: [false],
    output_name: ["CLIP"],
    name: "CLIPMergeSubtract",
    display_name: "CLIPMergeSubtract",
    description: "",
    python_module: "comfy_extras.nodes_model_merging",
    category: "advanced/model_merging",
    output_node: false,
  },
  CLIPMergeAdd: {
    input: { required: { clip1: ["CLIP"], clip2: ["CLIP"] } },
    input_order: { required: ["clip1", "clip2"] },
    output: ["CLIP"],
    output_is_list: [false],
    output_name: ["CLIP"],
    name: "CLIPMergeAdd",
    display_name: "CLIPMergeAdd",
    description: "",
    python_module: "comfy_extras.nodes_model_merging",
    category: "advanced/model_merging",
    output_node: false,
  },
  CLIPSave: {
    input: {
      required: {
        clip: ["CLIP"],
        filename_prefix: ["STRING", { default: "clip/ComfyUI" }],
      },
      hidden: { prompt: "PROMPT", extra_pnginfo: "EXTRA_PNGINFO" },
    },
    input_order: {
      required: ["clip", "filename_prefix"],
      hidden: ["prompt", "extra_pnginfo"],
    },
    output: [],
    output_is_list: [],
    output_name: [],
    name: "CLIPSave",
    display_name: "CLIPSave",
    description: "",
    python_module: "comfy_extras.nodes_model_merging",
    category: "advanced/model_merging",
    output_node: true,
  },
  VAESave: {
    input: {
      required: {
        vae: ["VAE"],
        filename_prefix: ["STRING", { default: "vae/ComfyUI_vae" }],
      },
      hidden: { prompt: "PROMPT", extra_pnginfo: "EXTRA_PNGINFO" },
    },
    input_order: {
      required: ["vae", "filename_prefix"],
      hidden: ["prompt", "extra_pnginfo"],
    },
    output: [],
    output_is_list: [],
    output_name: [],
    name: "VAESave",
    display_name: "VAESave",
    description: "",
    python_module: "comfy_extras.nodes_model_merging",
    category: "advanced/model_merging",
    output_node: true,
  },
  ModelSave: {
    input: {
      required: {
        model: ["MODEL"],
        filename_prefix: ["STRING", { default: "diffusion_models/ComfyUI" }],
      },
      hidden: { prompt: "PROMPT", extra_pnginfo: "EXTRA_PNGINFO" },
    },
    input_order: {
      required: ["model", "filename_prefix"],
      hidden: ["prompt", "extra_pnginfo"],
    },
    output: [],
    output_is_list: [],
    output_name: [],
    name: "ModelSave",
    display_name: "ModelSave",
    description: "",
    python_module: "comfy_extras.nodes_model_merging",
    category: "advanced/model_merging",
    output_node: true,
  },
  TomePatchModel: {
    input: {
      required: {
        model: ["MODEL"],
        ratio: ["FLOAT", { default: 0.3, min: 0.0, max: 1.0, step: 0.01 }],
      },
    },
    input_order: { required: ["model", "ratio"] },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "TomePatchModel",
    display_name: "TomePatchModel",
    description: "",
    python_module: "comfy_extras.nodes_tomesd",
    category: "model_patches/unet",
    output_node: false,
  },
  CLIPTextEncodeSDXLRefiner: {
    input: {
      required: {
        ascore: ["FLOAT", { default: 6.0, min: 0.0, max: 1000.0, step: 0.01 }],
        width: ["INT", { default: 1024.0, min: 0, max: 16384 }],
        height: ["INT", { default: 1024.0, min: 0, max: 16384 }],
        text: ["STRING", { multiline: true, dynamicPrompts: true }],
        clip: ["CLIP"],
      },
    },
    input_order: { required: ["ascore", "width", "height", "text", "clip"] },
    output: ["CONDITIONING"],
    output_is_list: [false],
    output_name: ["CONDITIONING"],
    name: "CLIPTextEncodeSDXLRefiner",
    display_name: "CLIPTextEncodeSDXLRefiner",
    description: "",
    python_module: "comfy_extras.nodes_clip_sdxl",
    category: "advanced/conditioning",
    output_node: false,
  },
  CLIPTextEncodeSDXL: {
    input: {
      required: {
        width: ["INT", { default: 1024.0, min: 0, max: 16384 }],
        height: ["INT", { default: 1024.0, min: 0, max: 16384 }],
        crop_w: ["INT", { default: 0, min: 0, max: 16384 }],
        crop_h: ["INT", { default: 0, min: 0, max: 16384 }],
        target_width: ["INT", { default: 1024.0, min: 0, max: 16384 }],
        target_height: ["INT", { default: 1024.0, min: 0, max: 16384 }],
        text_g: ["STRING", { multiline: true, dynamicPrompts: true }],
        clip: ["CLIP"],
        text_l: ["STRING", { multiline: true, dynamicPrompts: true }],
      },
    },
    input_order: {
      required: [
        "width",
        "height",
        "crop_w",
        "crop_h",
        "target_width",
        "target_height",
        "text_g",
        "clip",
        "text_l",
      ],
    },
    output: ["CONDITIONING"],
    output_is_list: [false],
    output_name: ["CONDITIONING"],
    name: "CLIPTextEncodeSDXL",
    display_name: "CLIPTextEncodeSDXL",
    description: "",
    python_module: "comfy_extras.nodes_clip_sdxl",
    category: "advanced/conditioning",
    output_node: false,
  },
  Canny: {
    input: {
      required: {
        image: ["IMAGE"],
        low_threshold: [
          "FLOAT",
          { default: 0.4, min: 0.01, max: 0.99, step: 0.01 },
        ],
        high_threshold: [
          "FLOAT",
          { default: 0.8, min: 0.01, max: 0.99, step: 0.01 },
        ],
      },
    },
    input_order: { required: ["image", "low_threshold", "high_threshold"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "Canny",
    display_name: "Canny",
    description: "",
    python_module: "comfy_extras.nodes_canny",
    category: "image/preprocessors",
    output_node: false,
  },
  FreeU: {
    input: {
      required: {
        model: ["MODEL"],
        b1: ["FLOAT", { default: 1.1, min: 0.0, max: 10.0, step: 0.01 }],
        b2: ["FLOAT", { default: 1.2, min: 0.0, max: 10.0, step: 0.01 }],
        s1: ["FLOAT", { default: 0.9, min: 0.0, max: 10.0, step: 0.01 }],
        s2: ["FLOAT", { default: 0.2, min: 0.0, max: 10.0, step: 0.01 }],
      },
    },
    input_order: { required: ["model", "b1", "b2", "s1", "s2"] },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "FreeU",
    display_name: "FreeU",
    description: "",
    python_module: "comfy_extras.nodes_freelunch",
    category: "model_patches/unet",
    output_node: false,
  },
  FreeU_V2: {
    input: {
      required: {
        model: ["MODEL"],
        b1: ["FLOAT", { default: 1.3, min: 0.0, max: 10.0, step: 0.01 }],
        b2: ["FLOAT", { default: 1.4, min: 0.0, max: 10.0, step: 0.01 }],
        s1: ["FLOAT", { default: 0.9, min: 0.0, max: 10.0, step: 0.01 }],
        s2: ["FLOAT", { default: 0.2, min: 0.0, max: 10.0, step: 0.01 }],
      },
    },
    input_order: { required: ["model", "b1", "b2", "s1", "s2"] },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "FreeU_V2",
    display_name: "FreeU_V2",
    description: "",
    python_module: "comfy_extras.nodes_freelunch",
    category: "model_patches/unet",
    output_node: false,
  },
  SamplerCustom: {
    input: {
      required: {
        model: ["MODEL"],
        add_noise: ["BOOLEAN", { default: true }],
        noise_seed: ["INT", { default: 0, min: 0, max: 18446744073709551615 }],
        cfg: [
          "FLOAT",
          { default: 8.0, min: 0.0, max: 100.0, step: 0.1, round: 0.01 },
        ],
        positive: ["CONDITIONING"],
        negative: ["CONDITIONING"],
        sampler: ["SAMPLER"],
        sigmas: ["SIGMAS"],
        latent_image: ["LATENT"],
      },
    },
    input_order: {
      required: [
        "model",
        "add_noise",
        "noise_seed",
        "cfg",
        "positive",
        "negative",
        "sampler",
        "sigmas",
        "latent_image",
      ],
    },
    output: ["LATENT", "LATENT"],
    output_is_list: [false, false],
    output_name: ["output", "denoised_output"],
    name: "SamplerCustom",
    display_name: "SamplerCustom",
    description: "",
    python_module: "comfy_extras.nodes_custom_sampler",
    category: "sampling/custom_sampling",
    output_node: false,
  },
  BasicScheduler: {
    input: {
      required: {
        model: ["MODEL"],
        scheduler: [
          [
            "normal",
            "karras",
            "exponential",
            "sgm_uniform",
            "simple",
            "ddim_uniform",
            "beta",
          ],
        ],
        steps: ["INT", { default: 20, min: 1, max: 10000 }],
        denoise: ["FLOAT", { default: 1.0, min: 0.0, max: 1.0, step: 0.01 }],
      },
    },
    input_order: { required: ["model", "scheduler", "steps", "denoise"] },
    output: ["SIGMAS"],
    output_is_list: [false],
    output_name: ["SIGMAS"],
    name: "BasicScheduler",
    display_name: "BasicScheduler",
    description: "",
    python_module: "comfy_extras.nodes_custom_sampler",
    category: "sampling/custom_sampling/schedulers",
    output_node: false,
  },
  KarrasScheduler: {
    input: {
      required: {
        steps: ["INT", { default: 20, min: 1, max: 10000 }],
        sigma_max: [
          "FLOAT",
          {
            default: 14.614642,
            min: 0.0,
            max: 5000.0,
            step: 0.01,
            round: false,
          },
        ],
        sigma_min: [
          "FLOAT",
          {
            default: 0.0291675,
            min: 0.0,
            max: 5000.0,
            step: 0.01,
            round: false,
          },
        ],
        rho: [
          "FLOAT",
          { default: 7.0, min: 0.0, max: 100.0, step: 0.01, round: false },
        ],
      },
    },
    input_order: { required: ["steps", "sigma_max", "sigma_min", "rho"] },
    output: ["SIGMAS"],
    output_is_list: [false],
    output_name: ["SIGMAS"],
    name: "KarrasScheduler",
    display_name: "KarrasScheduler",
    description: "",
    python_module: "comfy_extras.nodes_custom_sampler",
    category: "sampling/custom_sampling/schedulers",
    output_node: false,
  },
  ExponentialScheduler: {
    input: {
      required: {
        steps: ["INT", { default: 20, min: 1, max: 10000 }],
        sigma_max: [
          "FLOAT",
          {
            default: 14.614642,
            min: 0.0,
            max: 5000.0,
            step: 0.01,
            round: false,
          },
        ],
        sigma_min: [
          "FLOAT",
          {
            default: 0.0291675,
            min: 0.0,
            max: 5000.0,
            step: 0.01,
            round: false,
          },
        ],
      },
    },
    input_order: { required: ["steps", "sigma_max", "sigma_min"] },
    output: ["SIGMAS"],
    output_is_list: [false],
    output_name: ["SIGMAS"],
    name: "ExponentialScheduler",
    display_name: "ExponentialScheduler",
    description: "",
    python_module: "comfy_extras.nodes_custom_sampler",
    category: "sampling/custom_sampling/schedulers",
    output_node: false,
  },
  PolyexponentialScheduler: {
    input: {
      required: {
        steps: ["INT", { default: 20, min: 1, max: 10000 }],
        sigma_max: [
          "FLOAT",
          {
            default: 14.614642,
            min: 0.0,
            max: 5000.0,
            step: 0.01,
            round: false,
          },
        ],
        sigma_min: [
          "FLOAT",
          {
            default: 0.0291675,
            min: 0.0,
            max: 5000.0,
            step: 0.01,
            round: false,
          },
        ],
        rho: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 100.0, step: 0.01, round: false },
        ],
      },
    },
    input_order: { required: ["steps", "sigma_max", "sigma_min", "rho"] },
    output: ["SIGMAS"],
    output_is_list: [false],
    output_name: ["SIGMAS"],
    name: "PolyexponentialScheduler",
    display_name: "PolyexponentialScheduler",
    description: "",
    python_module: "comfy_extras.nodes_custom_sampler",
    category: "sampling/custom_sampling/schedulers",
    output_node: false,
  },
  LaplaceScheduler: {
    input: {
      required: {
        steps: ["INT", { default: 20, min: 1, max: 10000 }],
        sigma_max: [
          "FLOAT",
          {
            default: 14.614642,
            min: 0.0,
            max: 5000.0,
            step: 0.01,
            round: false,
          },
        ],
        sigma_min: [
          "FLOAT",
          {
            default: 0.0291675,
            min: 0.0,
            max: 5000.0,
            step: 0.01,
            round: false,
          },
        ],
        mu: [
          "FLOAT",
          { default: 0.0, min: -10.0, max: 10.0, step: 0.1, round: false },
        ],
        beta: [
          "FLOAT",
          { default: 0.5, min: 0.0, max: 10.0, step: 0.1, round: false },
        ],
      },
    },
    input_order: {
      required: ["steps", "sigma_max", "sigma_min", "mu", "beta"],
    },
    output: ["SIGMAS"],
    output_is_list: [false],
    output_name: ["SIGMAS"],
    name: "LaplaceScheduler",
    display_name: "LaplaceScheduler",
    description: "",
    python_module: "comfy_extras.nodes_custom_sampler",
    category: "sampling/custom_sampling/schedulers",
    output_node: false,
  },
  VPScheduler: {
    input: {
      required: {
        steps: ["INT", { default: 20, min: 1, max: 10000 }],
        beta_d: [
          "FLOAT",
          { default: 19.9, min: 0.0, max: 5000.0, step: 0.01, round: false },
        ],
        beta_min: [
          "FLOAT",
          { default: 0.1, min: 0.0, max: 5000.0, step: 0.01, round: false },
        ],
        eps_s: [
          "FLOAT",
          { default: 0.001, min: 0.0, max: 1.0, step: 0.0001, round: false },
        ],
      },
    },
    input_order: { required: ["steps", "beta_d", "beta_min", "eps_s"] },
    output: ["SIGMAS"],
    output_is_list: [false],
    output_name: ["SIGMAS"],
    name: "VPScheduler",
    display_name: "VPScheduler",
    description: "",
    python_module: "comfy_extras.nodes_custom_sampler",
    category: "sampling/custom_sampling/schedulers",
    output_node: false,
  },
  BetaSamplingScheduler: {
    input: {
      required: {
        model: ["MODEL"],
        steps: ["INT", { default: 20, min: 1, max: 10000 }],
        alpha: [
          "FLOAT",
          { default: 0.6, min: 0.0, max: 50.0, step: 0.01, round: false },
        ],
        beta: [
          "FLOAT",
          { default: 0.6, min: 0.0, max: 50.0, step: 0.01, round: false },
        ],
      },
    },
    input_order: { required: ["model", "steps", "alpha", "beta"] },
    output: ["SIGMAS"],
    output_is_list: [false],
    output_name: ["SIGMAS"],
    name: "BetaSamplingScheduler",
    display_name: "BetaSamplingScheduler",
    description: "",
    python_module: "comfy_extras.nodes_custom_sampler",
    category: "sampling/custom_sampling/schedulers",
    output_node: false,
  },
  SDTurboScheduler: {
    input: {
      required: {
        model: ["MODEL"],
        steps: ["INT", { default: 1, min: 1, max: 10 }],
        denoise: ["FLOAT", { default: 1.0, min: 0, max: 1.0, step: 0.01 }],
      },
    },
    input_order: { required: ["model", "steps", "denoise"] },
    output: ["SIGMAS"],
    output_is_list: [false],
    output_name: ["SIGMAS"],
    name: "SDTurboScheduler",
    display_name: "SDTurboScheduler",
    description: "",
    python_module: "comfy_extras.nodes_custom_sampler",
    category: "sampling/custom_sampling/schedulers",
    output_node: false,
  },
  KSamplerSelect: {
    input: {
      required: {
        sampler_name: [
          [
            "euler",
            "euler_cfg_pp",
            "euler_ancestral",
            "euler_ancestral_cfg_pp",
            "heun",
            "heunpp2",
            "dpm_2",
            "dpm_2_ancestral",
            "lms",
            "dpm_fast",
            "dpm_adaptive",
            "dpmpp_2s_ancestral",
            "dpmpp_2s_ancestral_cfg_pp",
            "dpmpp_sde",
            "dpmpp_sde_gpu",
            "dpmpp_2m",
            "dpmpp_2m_cfg_pp",
            "dpmpp_2m_sde",
            "dpmpp_2m_sde_gpu",
            "dpmpp_3m_sde",
            "dpmpp_3m_sde_gpu",
            "ddpm",
            "lcm",
            "ipndm",
            "ipndm_v",
            "deis",
            "ddim",
            "uni_pc",
            "uni_pc_bh2",
          ],
        ],
      },
    },
    input_order: { required: ["sampler_name"] },
    output: ["SAMPLER"],
    output_is_list: [false],
    output_name: ["SAMPLER"],
    name: "KSamplerSelect",
    display_name: "KSamplerSelect",
    description: "",
    python_module: "comfy_extras.nodes_custom_sampler",
    category: "sampling/custom_sampling/samplers",
    output_node: false,
  },
  SamplerEulerAncestral: {
    input: {
      required: {
        eta: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 100.0, step: 0.01, round: false },
        ],
        s_noise: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 100.0, step: 0.01, round: false },
        ],
      },
    },
    input_order: { required: ["eta", "s_noise"] },
    output: ["SAMPLER"],
    output_is_list: [false],
    output_name: ["SAMPLER"],
    name: "SamplerEulerAncestral",
    display_name: "SamplerEulerAncestral",
    description: "",
    python_module: "comfy_extras.nodes_custom_sampler",
    category: "sampling/custom_sampling/samplers",
    output_node: false,
  },
  SamplerEulerAncestralCFGPP: {
    input: {
      required: {
        eta: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01, round: false },
        ],
        s_noise: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 10.0, step: 0.01, round: false },
        ],
      },
    },
    input_order: { required: ["eta", "s_noise"] },
    output: ["SAMPLER"],
    output_is_list: [false],
    output_name: ["SAMPLER"],
    name: "SamplerEulerAncestralCFGPP",
    display_name: "SamplerEulerAncestralCFG++",
    description: "",
    python_module: "comfy_extras.nodes_custom_sampler",
    category: "sampling/custom_sampling/samplers",
    output_node: false,
  },
  SamplerLMS: {
    input: { required: { order: ["INT", { default: 4, min: 1, max: 100 }] } },
    input_order: { required: ["order"] },
    output: ["SAMPLER"],
    output_is_list: [false],
    output_name: ["SAMPLER"],
    name: "SamplerLMS",
    display_name: "SamplerLMS",
    description: "",
    python_module: "comfy_extras.nodes_custom_sampler",
    category: "sampling/custom_sampling/samplers",
    output_node: false,
  },
  SamplerDPMPP_3M_SDE: {
    input: {
      required: {
        eta: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 100.0, step: 0.01, round: false },
        ],
        s_noise: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 100.0, step: 0.01, round: false },
        ],
        noise_device: [["gpu", "cpu"]],
      },
    },
    input_order: { required: ["eta", "s_noise", "noise_device"] },
    output: ["SAMPLER"],
    output_is_list: [false],
    output_name: ["SAMPLER"],
    name: "SamplerDPMPP_3M_SDE",
    display_name: "SamplerDPMPP_3M_SDE",
    description: "",
    python_module: "comfy_extras.nodes_custom_sampler",
    category: "sampling/custom_sampling/samplers",
    output_node: false,
  },
  SamplerDPMPP_2M_SDE: {
    input: {
      required: {
        solver_type: [["midpoint", "heun"]],
        eta: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 100.0, step: 0.01, round: false },
        ],
        s_noise: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 100.0, step: 0.01, round: false },
        ],
        noise_device: [["gpu", "cpu"]],
      },
    },
    input_order: {
      required: ["solver_type", "eta", "s_noise", "noise_device"],
    },
    output: ["SAMPLER"],
    output_is_list: [false],
    output_name: ["SAMPLER"],
    name: "SamplerDPMPP_2M_SDE",
    display_name: "SamplerDPMPP_2M_SDE",
    description: "",
    python_module: "comfy_extras.nodes_custom_sampler",
    category: "sampling/custom_sampling/samplers",
    output_node: false,
  },
  SamplerDPMPP_SDE: {
    input: {
      required: {
        eta: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 100.0, step: 0.01, round: false },
        ],
        s_noise: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 100.0, step: 0.01, round: false },
        ],
        r: [
          "FLOAT",
          { default: 0.5, min: 0.0, max: 100.0, step: 0.01, round: false },
        ],
        noise_device: [["gpu", "cpu"]],
      },
    },
    input_order: { required: ["eta", "s_noise", "r", "noise_device"] },
    output: ["SAMPLER"],
    output_is_list: [false],
    output_name: ["SAMPLER"],
    name: "SamplerDPMPP_SDE",
    display_name: "SamplerDPMPP_SDE",
    description: "",
    python_module: "comfy_extras.nodes_custom_sampler",
    category: "sampling/custom_sampling/samplers",
    output_node: false,
  },
  SamplerDPMPP_2S_Ancestral: {
    input: {
      required: {
        eta: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 100.0, step: 0.01, round: false },
        ],
        s_noise: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 100.0, step: 0.01, round: false },
        ],
      },
    },
    input_order: { required: ["eta", "s_noise"] },
    output: ["SAMPLER"],
    output_is_list: [false],
    output_name: ["SAMPLER"],
    name: "SamplerDPMPP_2S_Ancestral",
    display_name: "SamplerDPMPP_2S_Ancestral",
    description: "",
    python_module: "comfy_extras.nodes_custom_sampler",
    category: "sampling/custom_sampling/samplers",
    output_node: false,
  },
  SamplerDPMAdaptative: {
    input: {
      required: {
        order: ["INT", { default: 3, min: 2, max: 3 }],
        rtol: [
          "FLOAT",
          { default: 0.05, min: 0.0, max: 100.0, step: 0.01, round: false },
        ],
        atol: [
          "FLOAT",
          { default: 0.0078, min: 0.0, max: 100.0, step: 0.01, round: false },
        ],
        h_init: [
          "FLOAT",
          { default: 0.05, min: 0.0, max: 100.0, step: 0.01, round: false },
        ],
        pcoeff: [
          "FLOAT",
          { default: 0.0, min: 0.0, max: 100.0, step: 0.01, round: false },
        ],
        icoeff: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 100.0, step: 0.01, round: false },
        ],
        dcoeff: [
          "FLOAT",
          { default: 0.0, min: 0.0, max: 100.0, step: 0.01, round: false },
        ],
        accept_safety: [
          "FLOAT",
          { default: 0.81, min: 0.0, max: 100.0, step: 0.01, round: false },
        ],
        eta: [
          "FLOAT",
          { default: 0.0, min: 0.0, max: 100.0, step: 0.01, round: false },
        ],
        s_noise: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 100.0, step: 0.01, round: false },
        ],
      },
    },
    input_order: {
      required: [
        "order",
        "rtol",
        "atol",
        "h_init",
        "pcoeff",
        "icoeff",
        "dcoeff",
        "accept_safety",
        "eta",
        "s_noise",
      ],
    },
    output: ["SAMPLER"],
    output_is_list: [false],
    output_name: ["SAMPLER"],
    name: "SamplerDPMAdaptative",
    display_name: "SamplerDPMAdaptative",
    description: "",
    python_module: "comfy_extras.nodes_custom_sampler",
    category: "sampling/custom_sampling/samplers",
    output_node: false,
  },
  SplitSigmas: {
    input: {
      required: {
        sigmas: ["SIGMAS"],
        step: ["INT", { default: 0, min: 0, max: 10000 }],
      },
    },
    input_order: { required: ["sigmas", "step"] },
    output: ["SIGMAS", "SIGMAS"],
    output_is_list: [false, false],
    output_name: ["high_sigmas", "low_sigmas"],
    name: "SplitSigmas",
    display_name: "SplitSigmas",
    description: "",
    python_module: "comfy_extras.nodes_custom_sampler",
    category: "sampling/custom_sampling/sigmas",
    output_node: false,
  },
  SplitSigmasDenoise: {
    input: {
      required: {
        sigmas: ["SIGMAS"],
        denoise: ["FLOAT", { default: 1.0, min: 0.0, max: 1.0, step: 0.01 }],
      },
    },
    input_order: { required: ["sigmas", "denoise"] },
    output: ["SIGMAS", "SIGMAS"],
    output_is_list: [false, false],
    output_name: ["high_sigmas", "low_sigmas"],
    name: "SplitSigmasDenoise",
    display_name: "SplitSigmasDenoise",
    description: "",
    python_module: "comfy_extras.nodes_custom_sampler",
    category: "sampling/custom_sampling/sigmas",
    output_node: false,
  },
  FlipSigmas: {
    input: { required: { sigmas: ["SIGMAS"] } },
    input_order: { required: ["sigmas"] },
    output: ["SIGMAS"],
    output_is_list: [false],
    output_name: ["SIGMAS"],
    name: "FlipSigmas",
    display_name: "FlipSigmas",
    description: "",
    python_module: "comfy_extras.nodes_custom_sampler",
    category: "sampling/custom_sampling/sigmas",
    output_node: false,
  },
  CFGGuider: {
    input: {
      required: {
        model: ["MODEL"],
        positive: ["CONDITIONING"],
        negative: ["CONDITIONING"],
        cfg: [
          "FLOAT",
          { default: 8.0, min: 0.0, max: 100.0, step: 0.1, round: 0.01 },
        ],
      },
    },
    input_order: { required: ["model", "positive", "negative", "cfg"] },
    output: ["GUIDER"],
    output_is_list: [false],
    output_name: ["GUIDER"],
    name: "CFGGuider",
    display_name: "CFGGuider",
    description: "",
    python_module: "comfy_extras.nodes_custom_sampler",
    category: "sampling/custom_sampling/guiders",
    output_node: false,
  },
  DualCFGGuider: {
    input: {
      required: {
        model: ["MODEL"],
        cond1: ["CONDITIONING"],
        cond2: ["CONDITIONING"],
        negative: ["CONDITIONING"],
        cfg_conds: [
          "FLOAT",
          { default: 8.0, min: 0.0, max: 100.0, step: 0.1, round: 0.01 },
        ],
        cfg_cond2_negative: [
          "FLOAT",
          { default: 8.0, min: 0.0, max: 100.0, step: 0.1, round: 0.01 },
        ],
      },
    },
    input_order: {
      required: [
        "model",
        "cond1",
        "cond2",
        "negative",
        "cfg_conds",
        "cfg_cond2_negative",
      ],
    },
    output: ["GUIDER"],
    output_is_list: [false],
    output_name: ["GUIDER"],
    name: "DualCFGGuider",
    display_name: "DualCFGGuider",
    description: "",
    python_module: "comfy_extras.nodes_custom_sampler",
    category: "sampling/custom_sampling/guiders",
    output_node: false,
  },
  BasicGuider: {
    input: { required: { model: ["MODEL"], conditioning: ["CONDITIONING"] } },
    input_order: { required: ["model", "conditioning"] },
    output: ["GUIDER"],
    output_is_list: [false],
    output_name: ["GUIDER"],
    name: "BasicGuider",
    display_name: "BasicGuider",
    description: "",
    python_module: "comfy_extras.nodes_custom_sampler",
    category: "sampling/custom_sampling/guiders",
    output_node: false,
  },
  RandomNoise: {
    input: {
      required: {
        noise_seed: ["INT", { default: 0, min: 0, max: 18446744073709551615 }],
      },
    },
    input_order: { required: ["noise_seed"] },
    output: ["NOISE"],
    output_is_list: [false],
    output_name: ["NOISE"],
    name: "RandomNoise",
    display_name: "RandomNoise",
    description: "",
    python_module: "comfy_extras.nodes_custom_sampler",
    category: "sampling/custom_sampling/noise",
    output_node: false,
  },
  DisableNoise: {
    input: { required: {} },
    input_order: { required: [] },
    output: ["NOISE"],
    output_is_list: [false],
    output_name: ["NOISE"],
    name: "DisableNoise",
    display_name: "DisableNoise",
    description: "",
    python_module: "comfy_extras.nodes_custom_sampler",
    category: "sampling/custom_sampling/noise",
    output_node: false,
  },
  AddNoise: {
    input: {
      required: {
        model: ["MODEL"],
        noise: ["NOISE"],
        sigmas: ["SIGMAS"],
        latent_image: ["LATENT"],
      },
    },
    input_order: { required: ["model", "noise", "sigmas", "latent_image"] },
    output: ["LATENT"],
    output_is_list: [false],
    output_name: ["LATENT"],
    name: "AddNoise",
    display_name: "AddNoise",
    description: "",
    python_module: "comfy_extras.nodes_custom_sampler",
    category: "_for_testing/custom_sampling/noise",
    output_node: false,
  },
  SamplerCustomAdvanced: {
    input: {
      required: {
        noise: ["NOISE"],
        guider: ["GUIDER"],
        sampler: ["SAMPLER"],
        sigmas: ["SIGMAS"],
        latent_image: ["LATENT"],
      },
    },
    input_order: {
      required: ["noise", "guider", "sampler", "sigmas", "latent_image"],
    },
    output: ["LATENT", "LATENT"],
    output_is_list: [false, false],
    output_name: ["output", "denoised_output"],
    name: "SamplerCustomAdvanced",
    display_name: "SamplerCustomAdvanced",
    description: "",
    python_module: "comfy_extras.nodes_custom_sampler",
    category: "sampling/custom_sampling",
    output_node: false,
  },
  HyperTile: {
    input: {
      required: {
        model: ["MODEL"],
        tile_size: ["INT", { default: 256, min: 1, max: 2048 }],
        swap_size: ["INT", { default: 2, min: 1, max: 128 }],
        max_depth: ["INT", { default: 0, min: 0, max: 10 }],
        scale_depth: ["BOOLEAN", { default: false }],
      },
    },
    input_order: {
      required: ["model", "tile_size", "swap_size", "max_depth", "scale_depth"],
    },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "HyperTile",
    display_name: "HyperTile",
    description: "",
    python_module: "comfy_extras.nodes_hypertile",
    category: "model_patches/unet",
    output_node: false,
  },
  ModelSamplingDiscrete: {
    input: {
      required: {
        model: ["MODEL"],
        sampling: [["eps", "v_prediction", "lcm", "x0"]],
        zsnr: ["BOOLEAN", { default: false }],
      },
    },
    input_order: { required: ["model", "sampling", "zsnr"] },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "ModelSamplingDiscrete",
    display_name: "ModelSamplingDiscrete",
    description: "",
    python_module: "comfy_extras.nodes_model_advanced",
    category: "advanced/model",
    output_node: false,
  },
  ModelSamplingContinuousEDM: {
    input: {
      required: {
        model: ["MODEL"],
        sampling: [["v_prediction", "edm_playground_v2.5", "eps"]],
        sigma_max: [
          "FLOAT",
          { default: 120.0, min: 0.0, max: 1000.0, step: 0.001, round: false },
        ],
        sigma_min: [
          "FLOAT",
          { default: 0.002, min: 0.0, max: 1000.0, step: 0.001, round: false },
        ],
      },
    },
    input_order: { required: ["model", "sampling", "sigma_max", "sigma_min"] },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "ModelSamplingContinuousEDM",
    display_name: "ModelSamplingContinuousEDM",
    description: "",
    python_module: "comfy_extras.nodes_model_advanced",
    category: "advanced/model",
    output_node: false,
  },
  ModelSamplingContinuousV: {
    input: {
      required: {
        model: ["MODEL"],
        sampling: [["v_prediction"]],
        sigma_max: [
          "FLOAT",
          { default: 500.0, min: 0.0, max: 1000.0, step: 0.001, round: false },
        ],
        sigma_min: [
          "FLOAT",
          { default: 0.03, min: 0.0, max: 1000.0, step: 0.001, round: false },
        ],
      },
    },
    input_order: { required: ["model", "sampling", "sigma_max", "sigma_min"] },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "ModelSamplingContinuousV",
    display_name: "ModelSamplingContinuousV",
    description: "",
    python_module: "comfy_extras.nodes_model_advanced",
    category: "advanced/model",
    output_node: false,
  },
  ModelSamplingStableCascade: {
    input: {
      required: {
        model: ["MODEL"],
        shift: ["FLOAT", { default: 2.0, min: 0.0, max: 100.0, step: 0.01 }],
      },
    },
    input_order: { required: ["model", "shift"] },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "ModelSamplingStableCascade",
    display_name: "ModelSamplingStableCascade",
    description: "",
    python_module: "comfy_extras.nodes_model_advanced",
    category: "advanced/model",
    output_node: false,
  },
  ModelSamplingSD3: {
    input: {
      required: {
        model: ["MODEL"],
        shift: ["FLOAT", { default: 3.0, min: 0.0, max: 100.0, step: 0.01 }],
      },
    },
    input_order: { required: ["model", "shift"] },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "ModelSamplingSD3",
    display_name: "ModelSamplingSD3",
    description: "",
    python_module: "comfy_extras.nodes_model_advanced",
    category: "advanced/model",
    output_node: false,
  },
  ModelSamplingAuraFlow: {
    input: {
      required: {
        model: ["MODEL"],
        shift: ["FLOAT", { default: 1.73, min: 0.0, max: 100.0, step: 0.01 }],
      },
    },
    input_order: { required: ["model", "shift"] },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "ModelSamplingAuraFlow",
    display_name: "ModelSamplingAuraFlow",
    description: "",
    python_module: "comfy_extras.nodes_model_advanced",
    category: "advanced/model",
    output_node: false,
  },
  ModelSamplingFlux: {
    input: {
      required: {
        model: ["MODEL"],
        max_shift: [
          "FLOAT",
          { default: 1.15, min: 0.0, max: 100.0, step: 0.01 },
        ],
        base_shift: [
          "FLOAT",
          { default: 0.5, min: 0.0, max: 100.0, step: 0.01 },
        ],
        width: ["INT", { default: 1024, min: 16, max: 16384, step: 8 }],
        height: ["INT", { default: 1024, min: 16, max: 16384, step: 8 }],
      },
    },
    input_order: {
      required: ["model", "max_shift", "base_shift", "width", "height"],
    },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "ModelSamplingFlux",
    display_name: "ModelSamplingFlux",
    description: "",
    python_module: "comfy_extras.nodes_model_advanced",
    category: "advanced/model",
    output_node: false,
  },
  RescaleCFG: {
    input: {
      required: {
        model: ["MODEL"],
        multiplier: ["FLOAT", { default: 0.7, min: 0.0, max: 1.0, step: 0.01 }],
      },
    },
    input_order: { required: ["model", "multiplier"] },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "RescaleCFG",
    display_name: "RescaleCFG",
    description: "",
    python_module: "comfy_extras.nodes_model_advanced",
    category: "advanced/model",
    output_node: false,
  },
  PatchModelAddDownscale: {
    input: {
      required: {
        model: ["MODEL"],
        block_number: ["INT", { default: 3, min: 1, max: 32, step: 1 }],
        downscale_factor: [
          "FLOAT",
          { default: 2.0, min: 0.1, max: 9.0, step: 0.001 },
        ],
        start_percent: [
          "FLOAT",
          { default: 0.0, min: 0.0, max: 1.0, step: 0.001 },
        ],
        end_percent: [
          "FLOAT",
          { default: 0.35, min: 0.0, max: 1.0, step: 0.001 },
        ],
        downscale_after_skip: ["BOOLEAN", { default: true }],
        downscale_method: [
          ["bicubic", "nearest-exact", "bilinear", "area", "bislerp"],
        ],
        upscale_method: [
          ["bicubic", "nearest-exact", "bilinear", "area", "bislerp"],
        ],
      },
    },
    input_order: {
      required: [
        "model",
        "block_number",
        "downscale_factor",
        "start_percent",
        "end_percent",
        "downscale_after_skip",
        "downscale_method",
        "upscale_method",
      ],
    },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "PatchModelAddDownscale",
    display_name: "PatchModelAddDownscale (Kohya Deep Shrink)",
    description: "",
    python_module: "comfy_extras.nodes_model_downscale",
    category: "model_patches/unet",
    output_node: false,
  },
  ImageCrop: {
    input: {
      required: {
        image: ["IMAGE"],
        width: ["INT", { default: 512, min: 1, max: 16384, step: 1 }],
        height: ["INT", { default: 512, min: 1, max: 16384, step: 1 }],
        x: ["INT", { default: 0, min: 0, max: 16384, step: 1 }],
        y: ["INT", { default: 0, min: 0, max: 16384, step: 1 }],
      },
    },
    input_order: { required: ["image", "width", "height", "x", "y"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "ImageCrop",
    display_name: "ImageCrop",
    description: "",
    python_module: "comfy_extras.nodes_images",
    category: "image/transform",
    output_node: false,
  },
  RepeatImageBatch: {
    input: {
      required: {
        image: ["IMAGE"],
        amount: ["INT", { default: 1, min: 1, max: 4096 }],
      },
    },
    input_order: { required: ["image", "amount"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "RepeatImageBatch",
    display_name: "RepeatImageBatch",
    description: "",
    python_module: "comfy_extras.nodes_images",
    category: "image/batch",
    output_node: false,
  },
  ImageFromBatch: {
    input: {
      required: {
        image: ["IMAGE"],
        batch_index: ["INT", { default: 0, min: 0, max: 4095 }],
        length: ["INT", { default: 1, min: 1, max: 4096 }],
      },
    },
    input_order: { required: ["image", "batch_index", "length"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "ImageFromBatch",
    display_name: "ImageFromBatch",
    description: "",
    python_module: "comfy_extras.nodes_images",
    category: "image/batch",
    output_node: false,
  },
  SaveAnimatedWEBP: {
    input: {
      required: {
        images: ["IMAGE"],
        filename_prefix: ["STRING", { default: "ComfyUI" }],
        fps: ["FLOAT", { default: 6.0, min: 0.01, max: 1000.0, step: 0.01 }],
        lossless: ["BOOLEAN", { default: true }],
        quality: ["INT", { default: 80, min: 0, max: 100 }],
        method: [["default", "fastest", "slowest"]],
      },
      hidden: { prompt: "PROMPT", extra_pnginfo: "EXTRA_PNGINFO" },
    },
    input_order: {
      required: [
        "images",
        "filename_prefix",
        "fps",
        "lossless",
        "quality",
        "method",
      ],
      hidden: ["prompt", "extra_pnginfo"],
    },
    output: [],
    output_is_list: [],
    output_name: [],
    name: "SaveAnimatedWEBP",
    display_name: "SaveAnimatedWEBP",
    description: "",
    python_module: "comfy_extras.nodes_images",
    category: "image/animation",
    output_node: true,
  },
  SaveAnimatedPNG: {
    input: {
      required: {
        images: ["IMAGE"],
        filename_prefix: ["STRING", { default: "ComfyUI" }],
        fps: ["FLOAT", { default: 6.0, min: 0.01, max: 1000.0, step: 0.01 }],
        compress_level: ["INT", { default: 4, min: 0, max: 9 }],
      },
      hidden: { prompt: "PROMPT", extra_pnginfo: "EXTRA_PNGINFO" },
    },
    input_order: {
      required: ["images", "filename_prefix", "fps", "compress_level"],
      hidden: ["prompt", "extra_pnginfo"],
    },
    output: [],
    output_is_list: [],
    output_name: [],
    name: "SaveAnimatedPNG",
    display_name: "SaveAnimatedPNG",
    description: "",
    python_module: "comfy_extras.nodes_images",
    category: "image/animation",
    output_node: true,
  },
  ImageOnlyCheckpointLoader: {
    input: {
      required: {
        ckpt_name: [
          [
            "Flux\\blue_pencil-flux1-v0.1.0-nf4.safetensors",
            "Flux\\carnivalUnchained_v10.safetensors",
            "Flux\\flux1-dev-bnb-nf4-v2.safetensors",
            "Flux\\fluximation_v1NF4.safetensors",
            "Flux\\lemonmixFLUX_protoFP8.safetensors",
            "Flux\\xeHentaiAnimeFlux_04.safetensors",
            "Pony\\boleromixPony_v141VAE.safetensors",
            "Pony\\boleromixSDXL_v13.safetensors",
            "SD1.0\\anime\\RealBackground_v12.safetensors",
            "SD1.0\\anime\\akinamixBE.safetensors",
            "SD1.0\\anime\\ambientgrapemixForAnime2D_v11.ckpt",
            "SD1.0\\anime\\animeScreencapStyle_assV13.safetensors",
            "SD1.0\\anime\\coffeensfw_v10.safetensors",
            "SD1.0\\anime\\colorfulAnimeXLXL_v20.safetensors",
            "SD1.0\\anime\\yden_v20.safetensors",
            "SD1.0\\other\\chosenIrisesMix_chosenIrisesMixV10.safetensors",
            "SD1.0\\other\\fantasyBackground_v10PrunedFp16.safetensors",
            "SD1.0\\other\\idkwimixNSFW_deformedV2.safetensors",
            "SD1.0\\other\\orientalPunkMix_orientalPunkFlower.ckpt",
            "SD1.0\\other\\threeDelicacyWonton_sanxianwontonmixv1.safetensors",
            "SD1.0\\real\\Guofengrealmix_v10.safetensors",
            "SD1.0\\real\\chilledReGenericV3_v10.safetensors",
            "SD1.0\\real\\chilloutmix_NiPrunedFp32Fix.ckpt",
            "SD1.0\\real\\fantasticmix_v40.safetensors",
            "SD1.0\\real\\snapdd00_v1.safetensors",
            "SD1.0\\real\\xxmix9realistic_v25.safetensors",
            "SD1.0\\semi_real\\comiNoirClassicV2.safetensors",
            "XL\\9527DetailRealistic_v50Bakedvae.safetensors",
            "XL\\NSFWAnimexl_10.safetensors",
            "XL\\anime2.5_animeArtDiffusionXL_alpha3.safetensors",
            "XL\\anime2.5_bluePencilXL_v401.safetensors",
            "XL\\anime2.5_breakdomainxl_V06d.safetensors",
            "XL\\anime2.5_counterfeitxl_v25.safetensors",
            "XL\\anime2.5_deepblueXL_v060.safetensors",
            "XL\\anime2.5_explicitFreedomNSFW_alpha.safetensors",
            "XL\\anime2.5_himawarimix_xlV2.safetensors",
            "XL\\anime2.5_kohakuXLBeta_beta7.safetensors",
            "XL\\anime2.5_reproductionSDXL_2v12.safetensors",
            "XL\\anime2.5_yesmixXL_v10.safetensors",
            "XL\\anime_aamXLAnimeMix_v10.civitai.safetensors",
            "XL\\anime_animagineXLV3_v30.safetensors",
            "XL\\anime_hassakuXLSfwNsfwBeta_betaV04.safetensors",
            "XL\\anime_notAnimefullFinalXL_v10.safetensors",
            "XL\\anime_sdxlYamersAnimeUltra_yamersAnimeV2.safetensors",
            "XL\\baxlBlueArchiveFlatCelluloidStyleFineTune_xlv3.safetensors",
            "XL\\real_4Guofeng4XL_v10Beta.safetensors",
            "XL\\real_cherrypickerXL_v27.safetensors",
            "XL\\real_realvisxlV40_v40LightningBakedvae.safetensors",
            "XL\\real_sdvn6Realxl_detailface.safetensors",
            "XL\\real_sdxl10ArienmixxlAsian_v40Pruned.safetensors",
            "XL\\real_xxmix9realisticsdxl_v10.safetensors",
            "animatBackgroundV1_03.safetensors",
            "sd_xl_base_1.0_0.9vae.safetensors",
          ],
        ],
      },
    },
    input_order: { required: ["ckpt_name"] },
    output: ["MODEL", "CLIP_VISION", "VAE"],
    output_is_list: [false, false, false],
    output_name: ["MODEL", "CLIP_VISION", "VAE"],
    name: "ImageOnlyCheckpointLoader",
    display_name: "Image Only Checkpoint Loader (img2vid model)",
    description: "",
    python_module: "comfy_extras.nodes_video_model",
    category: "loaders/video_models",
    output_node: false,
  },
  SVD_img2vid_Conditioning: {
    input: {
      required: {
        clip_vision: ["CLIP_VISION"],
        init_image: ["IMAGE"],
        vae: ["VAE"],
        width: ["INT", { default: 1024, min: 16, max: 16384, step: 8 }],
        height: ["INT", { default: 576, min: 16, max: 16384, step: 8 }],
        video_frames: ["INT", { default: 14, min: 1, max: 4096 }],
        motion_bucket_id: ["INT", { default: 127, min: 1, max: 1023 }],
        fps: ["INT", { default: 6, min: 1, max: 1024 }],
        augmentation_level: [
          "FLOAT",
          { default: 0.0, min: 0.0, max: 10.0, step: 0.01 },
        ],
      },
    },
    input_order: {
      required: [
        "clip_vision",
        "init_image",
        "vae",
        "width",
        "height",
        "video_frames",
        "motion_bucket_id",
        "fps",
        "augmentation_level",
      ],
    },
    output: ["CONDITIONING", "CONDITIONING", "LATENT"],
    output_is_list: [false, false, false],
    output_name: ["positive", "negative", "latent"],
    name: "SVD_img2vid_Conditioning",
    display_name: "SVD_img2vid_Conditioning",
    description: "",
    python_module: "comfy_extras.nodes_video_model",
    category: "conditioning/video_models",
    output_node: false,
  },
  VideoLinearCFGGuidance: {
    input: {
      required: {
        model: ["MODEL"],
        min_cfg: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 100.0, step: 0.5, round: 0.01 },
        ],
      },
    },
    input_order: { required: ["model", "min_cfg"] },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "VideoLinearCFGGuidance",
    display_name: "VideoLinearCFGGuidance",
    description: "",
    python_module: "comfy_extras.nodes_video_model",
    category: "sampling/video_models",
    output_node: false,
  },
  VideoTriangleCFGGuidance: {
    input: {
      required: {
        model: ["MODEL"],
        min_cfg: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 100.0, step: 0.5, round: 0.01 },
        ],
      },
    },
    input_order: { required: ["model", "min_cfg"] },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "VideoTriangleCFGGuidance",
    display_name: "VideoTriangleCFGGuidance",
    description: "",
    python_module: "comfy_extras.nodes_video_model",
    category: "sampling/video_models",
    output_node: false,
  },
  ImageOnlyCheckpointSave: {
    input: {
      required: {
        model: ["MODEL"],
        clip_vision: ["CLIP_VISION"],
        vae: ["VAE"],
        filename_prefix: ["STRING", { default: "checkpoints/ComfyUI" }],
      },
      hidden: { prompt: "PROMPT", extra_pnginfo: "EXTRA_PNGINFO" },
    },
    input_order: {
      required: ["model", "clip_vision", "vae", "filename_prefix"],
      hidden: ["prompt", "extra_pnginfo"],
    },
    output: [],
    output_is_list: [],
    output_name: [],
    name: "ImageOnlyCheckpointSave",
    display_name: "ImageOnlyCheckpointSave",
    description: "",
    python_module: "comfy_extras.nodes_video_model",
    category: "advanced/model_merging",
    output_node: true,
  },
  SelfAttentionGuidance: {
    input: {
      required: {
        model: ["MODEL"],
        scale: ["FLOAT", { default: 0.5, min: -2.0, max: 5.0, step: 0.01 }],
        blur_sigma: ["FLOAT", { default: 2.0, min: 0.0, max: 10.0, step: 0.1 }],
      },
    },
    input_order: { required: ["model", "scale", "blur_sigma"] },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "SelfAttentionGuidance",
    display_name: "Self-Attention Guidance",
    description: "",
    python_module: "comfy_extras.nodes_sag",
    category: "_for_testing",
    output_node: false,
  },
  PerpNeg: {
    input: {
      required: {
        model: ["MODEL"],
        empty_conditioning: ["CONDITIONING"],
        neg_scale: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 100.0, step: 0.01 },
        ],
      },
    },
    input_order: { required: ["model", "empty_conditioning", "neg_scale"] },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "PerpNeg",
    display_name: "Perp-Neg (DEPRECATED by PerpNegGuider)",
    description: "",
    python_module: "comfy_extras.nodes_perpneg",
    category: "_for_testing",
    output_node: false,
    deprecated: true,
  },
  PerpNegGuider: {
    input: {
      required: {
        model: ["MODEL"],
        positive: ["CONDITIONING"],
        negative: ["CONDITIONING"],
        empty_conditioning: ["CONDITIONING"],
        cfg: [
          "FLOAT",
          { default: 8.0, min: 0.0, max: 100.0, step: 0.1, round: 0.01 },
        ],
        neg_scale: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 100.0, step: 0.01 },
        ],
      },
    },
    input_order: {
      required: [
        "model",
        "positive",
        "negative",
        "empty_conditioning",
        "cfg",
        "neg_scale",
      ],
    },
    output: ["GUIDER"],
    output_is_list: [false],
    output_name: ["GUIDER"],
    name: "PerpNegGuider",
    display_name: "PerpNegGuider",
    description: "",
    python_module: "comfy_extras.nodes_perpneg",
    category: "_for_testing",
    output_node: false,
  },
  StableZero123_Conditioning: {
    input: {
      required: {
        clip_vision: ["CLIP_VISION"],
        init_image: ["IMAGE"],
        vae: ["VAE"],
        width: ["INT", { default: 256, min: 16, max: 16384, step: 8 }],
        height: ["INT", { default: 256, min: 16, max: 16384, step: 8 }],
        batch_size: ["INT", { default: 1, min: 1, max: 4096 }],
        elevation: [
          "FLOAT",
          { default: 0.0, min: -180.0, max: 180.0, step: 0.1, round: false },
        ],
        azimuth: [
          "FLOAT",
          { default: 0.0, min: -180.0, max: 180.0, step: 0.1, round: false },
        ],
      },
    },
    input_order: {
      required: [
        "clip_vision",
        "init_image",
        "vae",
        "width",
        "height",
        "batch_size",
        "elevation",
        "azimuth",
      ],
    },
    output: ["CONDITIONING", "CONDITIONING", "LATENT"],
    output_is_list: [false, false, false],
    output_name: ["positive", "negative", "latent"],
    name: "StableZero123_Conditioning",
    display_name: "StableZero123_Conditioning",
    description: "",
    python_module: "comfy_extras.nodes_stable3d",
    category: "conditioning/3d_models",
    output_node: false,
  },
  StableZero123_Conditioning_Batched: {
    input: {
      required: {
        clip_vision: ["CLIP_VISION"],
        init_image: ["IMAGE"],
        vae: ["VAE"],
        width: ["INT", { default: 256, min: 16, max: 16384, step: 8 }],
        height: ["INT", { default: 256, min: 16, max: 16384, step: 8 }],
        batch_size: ["INT", { default: 1, min: 1, max: 4096 }],
        elevation: [
          "FLOAT",
          { default: 0.0, min: -180.0, max: 180.0, step: 0.1, round: false },
        ],
        azimuth: [
          "FLOAT",
          { default: 0.0, min: -180.0, max: 180.0, step: 0.1, round: false },
        ],
        elevation_batch_increment: [
          "FLOAT",
          { default: 0.0, min: -180.0, max: 180.0, step: 0.1, round: false },
        ],
        azimuth_batch_increment: [
          "FLOAT",
          { default: 0.0, min: -180.0, max: 180.0, step: 0.1, round: false },
        ],
      },
    },
    input_order: {
      required: [
        "clip_vision",
        "init_image",
        "vae",
        "width",
        "height",
        "batch_size",
        "elevation",
        "azimuth",
        "elevation_batch_increment",
        "azimuth_batch_increment",
      ],
    },
    output: ["CONDITIONING", "CONDITIONING", "LATENT"],
    output_is_list: [false, false, false],
    output_name: ["positive", "negative", "latent"],
    name: "StableZero123_Conditioning_Batched",
    display_name: "StableZero123_Conditioning_Batched",
    description: "",
    python_module: "comfy_extras.nodes_stable3d",
    category: "conditioning/3d_models",
    output_node: false,
  },
  SV3D_Conditioning: {
    input: {
      required: {
        clip_vision: ["CLIP_VISION"],
        init_image: ["IMAGE"],
        vae: ["VAE"],
        width: ["INT", { default: 576, min: 16, max: 16384, step: 8 }],
        height: ["INT", { default: 576, min: 16, max: 16384, step: 8 }],
        video_frames: ["INT", { default: 21, min: 1, max: 4096 }],
        elevation: [
          "FLOAT",
          { default: 0.0, min: -90.0, max: 90.0, step: 0.1, round: false },
        ],
      },
    },
    input_order: {
      required: [
        "clip_vision",
        "init_image",
        "vae",
        "width",
        "height",
        "video_frames",
        "elevation",
      ],
    },
    output: ["CONDITIONING", "CONDITIONING", "LATENT"],
    output_is_list: [false, false, false],
    output_name: ["positive", "negative", "latent"],
    name: "SV3D_Conditioning",
    display_name: "SV3D_Conditioning",
    description: "",
    python_module: "comfy_extras.nodes_stable3d",
    category: "conditioning/3d_models",
    output_node: false,
  },
  SD_4XUpscale_Conditioning: {
    input: {
      required: {
        images: ["IMAGE"],
        positive: ["CONDITIONING"],
        negative: ["CONDITIONING"],
        scale_ratio: [
          "FLOAT",
          { default: 4.0, min: 0.0, max: 10.0, step: 0.01 },
        ],
        noise_augmentation: [
          "FLOAT",
          { default: 0.0, min: 0.0, max: 1.0, step: 0.001 },
        ],
      },
    },
    input_order: {
      required: [
        "images",
        "positive",
        "negative",
        "scale_ratio",
        "noise_augmentation",
      ],
    },
    output: ["CONDITIONING", "CONDITIONING", "LATENT"],
    output_is_list: [false, false, false],
    output_name: ["positive", "negative", "latent"],
    name: "SD_4XUpscale_Conditioning",
    display_name: "SD_4XUpscale_Conditioning",
    description: "",
    python_module: "comfy_extras.nodes_sdupscale",
    category: "conditioning/upscale_diffusion",
    output_node: false,
  },
  PhotoMakerLoader: {
    input: { required: { photomaker_model_name: [[]] } },
    input_order: { required: ["photomaker_model_name"] },
    output: ["PHOTOMAKER"],
    output_is_list: [false],
    output_name: ["PHOTOMAKER"],
    name: "PhotoMakerLoader",
    display_name: "PhotoMakerLoader",
    description: "",
    python_module: "comfy_extras.nodes_photomaker",
    category: "_for_testing/photomaker",
    output_node: false,
  },
  PhotoMakerEncode: {
    input: {
      required: {
        photomaker: ["PHOTOMAKER"],
        image: ["IMAGE"],
        clip: ["CLIP"],
        text: [
          "STRING",
          {
            multiline: true,
            dynamicPrompts: true,
            default: "photograph of photomaker",
          },
        ],
      },
    },
    input_order: { required: ["photomaker", "image", "clip", "text"] },
    output: ["CONDITIONING"],
    output_is_list: [false],
    output_name: ["CONDITIONING"],
    name: "PhotoMakerEncode",
    display_name: "PhotoMakerEncode",
    description: "",
    python_module: "comfy_extras.nodes_photomaker",
    category: "_for_testing/photomaker",
    output_node: false,
  },
  CLIPTextEncodeControlnet: {
    input: {
      required: {
        clip: ["CLIP"],
        conditioning: ["CONDITIONING"],
        text: ["STRING", { multiline: true, dynamicPrompts: true }],
      },
    },
    input_order: { required: ["clip", "conditioning", "text"] },
    output: ["CONDITIONING"],
    output_is_list: [false],
    output_name: ["CONDITIONING"],
    name: "CLIPTextEncodeControlnet",
    display_name: "CLIPTextEncodeControlnet",
    description: "",
    python_module: "comfy_extras.nodes_cond",
    category: "_for_testing/conditioning",
    output_node: false,
  },
  Morphology: {
    input: {
      required: {
        image: ["IMAGE"],
        operation: [
          [
            "erode",
            "dilate",
            "open",
            "close",
            "gradient",
            "bottom_hat",
            "top_hat",
          ],
        ],
        kernel_size: ["INT", { default: 3, min: 3, max: 999, step: 1 }],
      },
    },
    input_order: { required: ["image", "operation", "kernel_size"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "Morphology",
    display_name: "ImageMorphology",
    description: "",
    python_module: "comfy_extras.nodes_morphology",
    category: "image/postprocessing",
    output_node: false,
  },
  StableCascade_EmptyLatentImage: {
    input: {
      required: {
        width: ["INT", { default: 1024, min: 256, max: 16384, step: 8 }],
        height: ["INT", { default: 1024, min: 256, max: 16384, step: 8 }],
        compression: ["INT", { default: 42, min: 4, max: 128, step: 1 }],
        batch_size: ["INT", { default: 1, min: 1, max: 4096 }],
      },
    },
    input_order: { required: ["width", "height", "compression", "batch_size"] },
    output: ["LATENT", "LATENT"],
    output_is_list: [false, false],
    output_name: ["stage_c", "stage_b"],
    name: "StableCascade_EmptyLatentImage",
    display_name: "StableCascade_EmptyLatentImage",
    description: "",
    python_module: "comfy_extras.nodes_stable_cascade",
    category: "latent/stable_cascade",
    output_node: false,
  },
  StableCascade_StageB_Conditioning: {
    input: {
      required: { conditioning: ["CONDITIONING"], stage_c: ["LATENT"] },
    },
    input_order: { required: ["conditioning", "stage_c"] },
    output: ["CONDITIONING"],
    output_is_list: [false],
    output_name: ["CONDITIONING"],
    name: "StableCascade_StageB_Conditioning",
    display_name: "StableCascade_StageB_Conditioning",
    description: "",
    python_module: "comfy_extras.nodes_stable_cascade",
    category: "conditioning/stable_cascade",
    output_node: false,
  },
  StableCascade_StageC_VAEEncode: {
    input: {
      required: {
        image: ["IMAGE"],
        vae: ["VAE"],
        compression: ["INT", { default: 42, min: 4, max: 128, step: 1 }],
      },
    },
    input_order: { required: ["image", "vae", "compression"] },
    output: ["LATENT", "LATENT"],
    output_is_list: [false, false],
    output_name: ["stage_c", "stage_b"],
    name: "StableCascade_StageC_VAEEncode",
    display_name: "StableCascade_StageC_VAEEncode",
    description: "",
    python_module: "comfy_extras.nodes_stable_cascade",
    category: "latent/stable_cascade",
    output_node: false,
  },
  StableCascade_SuperResolutionControlnet: {
    input: { required: { image: ["IMAGE"], vae: ["VAE"] } },
    input_order: { required: ["image", "vae"] },
    output: ["IMAGE", "LATENT", "LATENT"],
    output_is_list: [false, false, false],
    output_name: ["controlnet_input", "stage_c", "stage_b"],
    name: "StableCascade_SuperResolutionControlnet",
    display_name: "StableCascade_SuperResolutionControlnet",
    description: "",
    python_module: "comfy_extras.nodes_stable_cascade",
    category: "_for_testing/stable_cascade",
    output_node: false,
    experimental: true,
  },
  DifferentialDiffusion: {
    input: { required: { model: ["MODEL"] } },
    input_order: { required: ["model"] },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "DifferentialDiffusion",
    display_name: "Differential Diffusion",
    description: "",
    python_module: "comfy_extras.nodes_differential_diffusion",
    category: "_for_testing",
    output_node: false,
  },
  InstructPixToPixConditioning: {
    input: {
      required: {
        positive: ["CONDITIONING"],
        negative: ["CONDITIONING"],
        vae: ["VAE"],
        pixels: ["IMAGE"],
      },
    },
    input_order: { required: ["positive", "negative", "vae", "pixels"] },
    output: ["CONDITIONING", "CONDITIONING", "LATENT"],
    output_is_list: [false, false, false],
    output_name: ["positive", "negative", "latent"],
    name: "InstructPixToPixConditioning",
    display_name: "InstructPixToPixConditioning",
    description: "",
    python_module: "comfy_extras.nodes_ip2p",
    category: "conditioning/instructpix2pix",
    output_node: false,
  },
  ModelMergeSD1: {
    input: {
      required: {
        model1: ["MODEL"],
        model2: ["MODEL"],
        "time_embed.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "label_emb.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.0.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.1.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.2.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.3.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.4.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.5.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.6.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.7.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.8.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.9.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.10.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.11.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "middle_block.0.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "middle_block.1.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "middle_block.2.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.0.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.1.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.2.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.3.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.4.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.5.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.6.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.7.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.8.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.9.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.10.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.11.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "out.": ["FLOAT", { default: 1.0, min: 0.0, max: 1.0, step: 0.01 }],
      },
    },
    input_order: {
      required: [
        "model1",
        "model2",
        "time_embed.",
        "label_emb.",
        "input_blocks.0.",
        "input_blocks.1.",
        "input_blocks.2.",
        "input_blocks.3.",
        "input_blocks.4.",
        "input_blocks.5.",
        "input_blocks.6.",
        "input_blocks.7.",
        "input_blocks.8.",
        "input_blocks.9.",
        "input_blocks.10.",
        "input_blocks.11.",
        "middle_block.0.",
        "middle_block.1.",
        "middle_block.2.",
        "output_blocks.0.",
        "output_blocks.1.",
        "output_blocks.2.",
        "output_blocks.3.",
        "output_blocks.4.",
        "output_blocks.5.",
        "output_blocks.6.",
        "output_blocks.7.",
        "output_blocks.8.",
        "output_blocks.9.",
        "output_blocks.10.",
        "output_blocks.11.",
        "out.",
      ],
    },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "ModelMergeSD1",
    display_name: "ModelMergeSD1",
    description: "",
    python_module: "comfy_extras.nodes_model_merging_model_specific",
    category: "advanced/model_merging/model_specific",
    output_node: false,
  },
  ModelMergeSD2: {
    input: {
      required: {
        model1: ["MODEL"],
        model2: ["MODEL"],
        "time_embed.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "label_emb.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.0.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.1.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.2.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.3.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.4.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.5.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.6.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.7.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.8.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.9.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.10.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.11.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "middle_block.0.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "middle_block.1.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "middle_block.2.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.0.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.1.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.2.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.3.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.4.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.5.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.6.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.7.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.8.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.9.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.10.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.11.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "out.": ["FLOAT", { default: 1.0, min: 0.0, max: 1.0, step: 0.01 }],
      },
    },
    input_order: {
      required: [
        "model1",
        "model2",
        "time_embed.",
        "label_emb.",
        "input_blocks.0.",
        "input_blocks.1.",
        "input_blocks.2.",
        "input_blocks.3.",
        "input_blocks.4.",
        "input_blocks.5.",
        "input_blocks.6.",
        "input_blocks.7.",
        "input_blocks.8.",
        "input_blocks.9.",
        "input_blocks.10.",
        "input_blocks.11.",
        "middle_block.0.",
        "middle_block.1.",
        "middle_block.2.",
        "output_blocks.0.",
        "output_blocks.1.",
        "output_blocks.2.",
        "output_blocks.3.",
        "output_blocks.4.",
        "output_blocks.5.",
        "output_blocks.6.",
        "output_blocks.7.",
        "output_blocks.8.",
        "output_blocks.9.",
        "output_blocks.10.",
        "output_blocks.11.",
        "out.",
      ],
    },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "ModelMergeSD2",
    display_name: "ModelMergeSD2",
    description: "",
    python_module: "comfy_extras.nodes_model_merging_model_specific",
    category: "advanced/model_merging/model_specific",
    output_node: false,
  },
  ModelMergeSDXL: {
    input: {
      required: {
        model1: ["MODEL"],
        model2: ["MODEL"],
        "time_embed.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "label_emb.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.0": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.1": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.2": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.3": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.4": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.5": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.6": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.7": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "input_blocks.8": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "middle_block.0": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "middle_block.1": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "middle_block.2": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.0": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.1": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.2": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.3": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.4": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.5": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.6": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.7": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "output_blocks.8": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "out.": ["FLOAT", { default: 1.0, min: 0.0, max: 1.0, step: 0.01 }],
      },
    },
    input_order: {
      required: [
        "model1",
        "model2",
        "time_embed.",
        "label_emb.",
        "input_blocks.0",
        "input_blocks.1",
        "input_blocks.2",
        "input_blocks.3",
        "input_blocks.4",
        "input_blocks.5",
        "input_blocks.6",
        "input_blocks.7",
        "input_blocks.8",
        "middle_block.0",
        "middle_block.1",
        "middle_block.2",
        "output_blocks.0",
        "output_blocks.1",
        "output_blocks.2",
        "output_blocks.3",
        "output_blocks.4",
        "output_blocks.5",
        "output_blocks.6",
        "output_blocks.7",
        "output_blocks.8",
        "out.",
      ],
    },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "ModelMergeSDXL",
    display_name: "ModelMergeSDXL",
    description: "",
    python_module: "comfy_extras.nodes_model_merging_model_specific",
    category: "advanced/model_merging/model_specific",
    output_node: false,
  },
  ModelMergeSD3_2B: {
    input: {
      required: {
        model1: ["MODEL"],
        model2: ["MODEL"],
        "pos_embed.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "x_embedder.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "context_embedder.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "y_embedder.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "t_embedder.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "joint_blocks.0.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "joint_blocks.1.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "joint_blocks.2.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "joint_blocks.3.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "joint_blocks.4.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "joint_blocks.5.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "joint_blocks.6.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "joint_blocks.7.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "joint_blocks.8.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "joint_blocks.9.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "joint_blocks.10.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "joint_blocks.11.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "joint_blocks.12.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "joint_blocks.13.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "joint_blocks.14.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "joint_blocks.15.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "joint_blocks.16.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "joint_blocks.17.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "joint_blocks.18.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "joint_blocks.19.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "joint_blocks.20.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "joint_blocks.21.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "joint_blocks.22.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "joint_blocks.23.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "final_layer.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
      },
    },
    input_order: {
      required: [
        "model1",
        "model2",
        "pos_embed.",
        "x_embedder.",
        "context_embedder.",
        "y_embedder.",
        "t_embedder.",
        "joint_blocks.0.",
        "joint_blocks.1.",
        "joint_blocks.2.",
        "joint_blocks.3.",
        "joint_blocks.4.",
        "joint_blocks.5.",
        "joint_blocks.6.",
        "joint_blocks.7.",
        "joint_blocks.8.",
        "joint_blocks.9.",
        "joint_blocks.10.",
        "joint_blocks.11.",
        "joint_blocks.12.",
        "joint_blocks.13.",
        "joint_blocks.14.",
        "joint_blocks.15.",
        "joint_blocks.16.",
        "joint_blocks.17.",
        "joint_blocks.18.",
        "joint_blocks.19.",
        "joint_blocks.20.",
        "joint_blocks.21.",
        "joint_blocks.22.",
        "joint_blocks.23.",
        "final_layer.",
      ],
    },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "ModelMergeSD3_2B",
    display_name: "ModelMergeSD3_2B",
    description: "",
    python_module: "comfy_extras.nodes_model_merging_model_specific",
    category: "advanced/model_merging/model_specific",
    output_node: false,
  },
  ModelMergeFlux1: {
    input: {
      required: {
        model1: ["MODEL"],
        model2: ["MODEL"],
        "img_in.": ["FLOAT", { default: 1.0, min: 0.0, max: 1.0, step: 0.01 }],
        "time_in.": ["FLOAT", { default: 1.0, min: 0.0, max: 1.0, step: 0.01 }],
        guidance_in: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "vector_in.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "txt_in.": ["FLOAT", { default: 1.0, min: 0.0, max: 1.0, step: 0.01 }],
        "double_blocks.0.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "double_blocks.1.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "double_blocks.2.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "double_blocks.3.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "double_blocks.4.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "double_blocks.5.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "double_blocks.6.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "double_blocks.7.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "double_blocks.8.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "double_blocks.9.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "double_blocks.10.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "double_blocks.11.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "double_blocks.12.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "double_blocks.13.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "double_blocks.14.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "double_blocks.15.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "double_blocks.16.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "double_blocks.17.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "double_blocks.18.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.0.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.1.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.2.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.3.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.4.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.5.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.6.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.7.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.8.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.9.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.10.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.11.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.12.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.13.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.14.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.15.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.16.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.17.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.18.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.19.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.20.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.21.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.22.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.23.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.24.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.25.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.26.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.27.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.28.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.29.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.30.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.31.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.32.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.33.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.34.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.35.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.36.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "single_blocks.37.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        "final_layer.": [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
      },
    },
    input_order: {
      required: [
        "model1",
        "model2",
        "img_in.",
        "time_in.",
        "guidance_in",
        "vector_in.",
        "txt_in.",
        "double_blocks.0.",
        "double_blocks.1.",
        "double_blocks.2.",
        "double_blocks.3.",
        "double_blocks.4.",
        "double_blocks.5.",
        "double_blocks.6.",
        "double_blocks.7.",
        "double_blocks.8.",
        "double_blocks.9.",
        "double_blocks.10.",
        "double_blocks.11.",
        "double_blocks.12.",
        "double_blocks.13.",
        "double_blocks.14.",
        "double_blocks.15.",
        "double_blocks.16.",
        "double_blocks.17.",
        "double_blocks.18.",
        "single_blocks.0.",
        "single_blocks.1.",
        "single_blocks.2.",
        "single_blocks.3.",
        "single_blocks.4.",
        "single_blocks.5.",
        "single_blocks.6.",
        "single_blocks.7.",
        "single_blocks.8.",
        "single_blocks.9.",
        "single_blocks.10.",
        "single_blocks.11.",
        "single_blocks.12.",
        "single_blocks.13.",
        "single_blocks.14.",
        "single_blocks.15.",
        "single_blocks.16.",
        "single_blocks.17.",
        "single_blocks.18.",
        "single_blocks.19.",
        "single_blocks.20.",
        "single_blocks.21.",
        "single_blocks.22.",
        "single_blocks.23.",
        "single_blocks.24.",
        "single_blocks.25.",
        "single_blocks.26.",
        "single_blocks.27.",
        "single_blocks.28.",
        "single_blocks.29.",
        "single_blocks.30.",
        "single_blocks.31.",
        "single_blocks.32.",
        "single_blocks.33.",
        "single_blocks.34.",
        "single_blocks.35.",
        "single_blocks.36.",
        "single_blocks.37.",
        "final_layer.",
      ],
    },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "ModelMergeFlux1",
    display_name: "ModelMergeFlux1",
    description: "",
    python_module: "comfy_extras.nodes_model_merging_model_specific",
    category: "advanced/model_merging/model_specific",
    output_node: false,
  },
  PerturbedAttentionGuidance: {
    input: {
      required: {
        model: ["MODEL"],
        scale: [
          "FLOAT",
          { default: 3.0, min: 0.0, max: 100.0, step: 0.01, round: 0.01 },
        ],
      },
    },
    input_order: { required: ["model", "scale"] },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "PerturbedAttentionGuidance",
    display_name: "PerturbedAttentionGuidance",
    description: "",
    python_module: "comfy_extras.nodes_pag",
    category: "model_patches/unet",
    output_node: false,
  },
  AlignYourStepsScheduler: {
    input: {
      required: {
        model_type: [["SD1", "SDXL", "SVD"]],
        steps: ["INT", { default: 10, min: 10, max: 10000 }],
        denoise: ["FLOAT", { default: 1.0, min: 0.0, max: 1.0, step: 0.01 }],
      },
    },
    input_order: { required: ["model_type", "steps", "denoise"] },
    output: ["SIGMAS"],
    output_is_list: [false],
    output_name: ["SIGMAS"],
    name: "AlignYourStepsScheduler",
    display_name: "AlignYourStepsScheduler",
    description: "",
    python_module: "comfy_extras.nodes_align_your_steps",
    category: "sampling/custom_sampling/schedulers",
    output_node: false,
  },
  UNetSelfAttentionMultiply: {
    input: {
      required: {
        model: ["MODEL"],
        q: ["FLOAT", { default: 1.0, min: 0.0, max: 10.0, step: 0.01 }],
        k: ["FLOAT", { default: 1.0, min: 0.0, max: 10.0, step: 0.01 }],
        v: ["FLOAT", { default: 1.0, min: 0.0, max: 10.0, step: 0.01 }],
        out: ["FLOAT", { default: 1.0, min: 0.0, max: 10.0, step: 0.01 }],
      },
    },
    input_order: { required: ["model", "q", "k", "v", "out"] },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "UNetSelfAttentionMultiply",
    display_name: "UNetSelfAttentionMultiply",
    description: "",
    python_module: "comfy_extras.nodes_attention_multiply",
    category: "_for_testing/attention_experiments",
    output_node: false,
  },
  UNetCrossAttentionMultiply: {
    input: {
      required: {
        model: ["MODEL"],
        q: ["FLOAT", { default: 1.0, min: 0.0, max: 10.0, step: 0.01 }],
        k: ["FLOAT", { default: 1.0, min: 0.0, max: 10.0, step: 0.01 }],
        v: ["FLOAT", { default: 1.0, min: 0.0, max: 10.0, step: 0.01 }],
        out: ["FLOAT", { default: 1.0, min: 0.0, max: 10.0, step: 0.01 }],
      },
    },
    input_order: { required: ["model", "q", "k", "v", "out"] },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "UNetCrossAttentionMultiply",
    display_name: "UNetCrossAttentionMultiply",
    description: "",
    python_module: "comfy_extras.nodes_attention_multiply",
    category: "_for_testing/attention_experiments",
    output_node: false,
  },
  CLIPAttentionMultiply: {
    input: {
      required: {
        clip: ["CLIP"],
        q: ["FLOAT", { default: 1.0, min: 0.0, max: 10.0, step: 0.01 }],
        k: ["FLOAT", { default: 1.0, min: 0.0, max: 10.0, step: 0.01 }],
        v: ["FLOAT", { default: 1.0, min: 0.0, max: 10.0, step: 0.01 }],
        out: ["FLOAT", { default: 1.0, min: 0.0, max: 10.0, step: 0.01 }],
      },
    },
    input_order: { required: ["clip", "q", "k", "v", "out"] },
    output: ["CLIP"],
    output_is_list: [false],
    output_name: ["CLIP"],
    name: "CLIPAttentionMultiply",
    display_name: "CLIPAttentionMultiply",
    description: "",
    python_module: "comfy_extras.nodes_attention_multiply",
    category: "_for_testing/attention_experiments",
    output_node: false,
  },
  UNetTemporalAttentionMultiply: {
    input: {
      required: {
        model: ["MODEL"],
        self_structural: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 10.0, step: 0.01 },
        ],
        self_temporal: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 10.0, step: 0.01 },
        ],
        cross_structural: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 10.0, step: 0.01 },
        ],
        cross_temporal: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 10.0, step: 0.01 },
        ],
      },
    },
    input_order: {
      required: [
        "model",
        "self_structural",
        "self_temporal",
        "cross_structural",
        "cross_temporal",
      ],
    },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "UNetTemporalAttentionMultiply",
    display_name: "UNetTemporalAttentionMultiply",
    description: "",
    python_module: "comfy_extras.nodes_attention_multiply",
    category: "_for_testing/attention_experiments",
    output_node: false,
  },
  SamplerLCMUpscale: {
    input: {
      required: {
        scale_ratio: [
          "FLOAT",
          { default: 1.0, min: 0.1, max: 20.0, step: 0.01 },
        ],
        scale_steps: ["INT", { default: -1, min: -1, max: 1000, step: 1 }],
        upscale_method: [
          ["bislerp", "nearest-exact", "bilinear", "area", "bicubic"],
        ],
      },
    },
    input_order: { required: ["scale_ratio", "scale_steps", "upscale_method"] },
    output: ["SAMPLER"],
    output_is_list: [false],
    output_name: ["SAMPLER"],
    name: "SamplerLCMUpscale",
    display_name: "SamplerLCMUpscale",
    description: "",
    python_module: "comfy_extras.nodes_advanced_samplers",
    category: "sampling/custom_sampling/samplers",
    output_node: false,
  },
  SamplerEulerCFGpp: {
    input: { required: { version: [["regular", "alternative"]] } },
    input_order: { required: ["version"] },
    output: ["SAMPLER"],
    output_is_list: [false],
    output_name: ["SAMPLER"],
    name: "SamplerEulerCFGpp",
    display_name: "SamplerEulerCFG++",
    description: "",
    python_module: "comfy_extras.nodes_advanced_samplers",
    category: "_for_testing",
    output_node: false,
  },
  WebcamCapture: {
    input: {
      required: {
        image: ["WEBCAM", {}],
        width: ["INT", { default: 0, min: 0, max: 16384, step: 1 }],
        height: ["INT", { default: 0, min: 0, max: 16384, step: 1 }],
        capture_on_queue: ["BOOLEAN", { default: true }],
      },
    },
    input_order: { required: ["image", "width", "height", "capture_on_queue"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "WebcamCapture",
    display_name: "Webcam Capture",
    description: "",
    python_module: "comfy_extras.nodes_webcam",
    category: "image",
    output_node: false,
  },
  EmptyLatentAudio: {
    input: {
      required: {
        seconds: ["FLOAT", { default: 47.6, min: 1.0, max: 1000.0, step: 0.1 }],
        batch_size: [
          "INT",
          {
            default: 1,
            min: 1,
            max: 4096,
            tooltip: "The number of latent images in the batch.",
          },
        ],
      },
    },
    input_order: { required: ["seconds", "batch_size"] },
    output: ["LATENT"],
    output_is_list: [false],
    output_name: ["LATENT"],
    name: "EmptyLatentAudio",
    display_name: "EmptyLatentAudio",
    description: "",
    python_module: "comfy_extras.nodes_audio",
    category: "latent/audio",
    output_node: false,
  },
  VAEEncodeAudio: {
    input: { required: { audio: ["AUDIO"], vae: ["VAE"] } },
    input_order: { required: ["audio", "vae"] },
    output: ["LATENT"],
    output_is_list: [false],
    output_name: ["LATENT"],
    name: "VAEEncodeAudio",
    display_name: "VAEEncodeAudio",
    description: "",
    python_module: "comfy_extras.nodes_audio",
    category: "latent/audio",
    output_node: false,
  },
  VAEDecodeAudio: {
    input: { required: { samples: ["LATENT"], vae: ["VAE"] } },
    input_order: { required: ["samples", "vae"] },
    output: ["AUDIO"],
    output_is_list: [false],
    output_name: ["AUDIO"],
    name: "VAEDecodeAudio",
    display_name: "VAEDecodeAudio",
    description: "",
    python_module: "comfy_extras.nodes_audio",
    category: "latent/audio",
    output_node: false,
  },
  SaveAudio: {
    input: {
      required: {
        audio: ["AUDIO"],
        filename_prefix: ["STRING", { default: "audio/ComfyUI" }],
      },
      hidden: { prompt: "PROMPT", extra_pnginfo: "EXTRA_PNGINFO" },
    },
    input_order: {
      required: ["audio", "filename_prefix"],
      hidden: ["prompt", "extra_pnginfo"],
    },
    output: [],
    output_is_list: [],
    output_name: [],
    name: "SaveAudio",
    display_name: "SaveAudio",
    description: "",
    python_module: "comfy_extras.nodes_audio",
    category: "audio",
    output_node: true,
  },
  LoadAudio: {
    input: { required: { audio: [[], { audio_upload: true }] } },
    input_order: { required: ["audio"] },
    output: ["AUDIO"],
    output_is_list: [false],
    output_name: ["AUDIO"],
    name: "LoadAudio",
    display_name: "LoadAudio",
    description: "",
    python_module: "comfy_extras.nodes_audio",
    category: "audio",
    output_node: false,
  },
  PreviewAudio: {
    input: {
      required: { audio: ["AUDIO"] },
      hidden: { prompt: "PROMPT", extra_pnginfo: "EXTRA_PNGINFO" },
    },
    input_order: { required: ["audio"], hidden: ["prompt", "extra_pnginfo"] },
    output: [],
    output_is_list: [],
    output_name: [],
    name: "PreviewAudio",
    display_name: "PreviewAudio",
    description: "",
    python_module: "comfy_extras.nodes_audio",
    category: "audio",
    output_node: true,
  },
  TripleCLIPLoader: {
    input: {
      required: {
        clip_name1: [
          [
            "ViT-L-14_openai_artists.safetensors",
            "ViT-L-14_openai_flavors.safetensors",
            "ViT-L-14_openai_mediums.safetensors",
            "ViT-L-14_openai_movements.safetensors",
            "ViT-L-14_openai_negative.safetensors",
            "ViT-L-14_openai_trendings.safetensors",
          ],
        ],
        clip_name2: [
          [
            "ViT-L-14_openai_artists.safetensors",
            "ViT-L-14_openai_flavors.safetensors",
            "ViT-L-14_openai_mediums.safetensors",
            "ViT-L-14_openai_movements.safetensors",
            "ViT-L-14_openai_negative.safetensors",
            "ViT-L-14_openai_trendings.safetensors",
          ],
        ],
        clip_name3: [
          [
            "ViT-L-14_openai_artists.safetensors",
            "ViT-L-14_openai_flavors.safetensors",
            "ViT-L-14_openai_mediums.safetensors",
            "ViT-L-14_openai_movements.safetensors",
            "ViT-L-14_openai_negative.safetensors",
            "ViT-L-14_openai_trendings.safetensors",
          ],
        ],
      },
    },
    input_order: { required: ["clip_name1", "clip_name2", "clip_name3"] },
    output: ["CLIP"],
    output_is_list: [false],
    output_name: ["CLIP"],
    name: "TripleCLIPLoader",
    display_name: "TripleCLIPLoader",
    description: "",
    python_module: "comfy_extras.nodes_sd3",
    category: "advanced/loaders",
    output_node: false,
  },
  EmptySD3LatentImage: {
    input: {
      required: {
        width: ["INT", { default: 1024, min: 16, max: 16384, step: 16 }],
        height: ["INT", { default: 1024, min: 16, max: 16384, step: 16 }],
        batch_size: ["INT", { default: 1, min: 1, max: 4096 }],
      },
    },
    input_order: { required: ["width", "height", "batch_size"] },
    output: ["LATENT"],
    output_is_list: [false],
    output_name: ["LATENT"],
    name: "EmptySD3LatentImage",
    display_name: "EmptySD3LatentImage",
    description: "",
    python_module: "comfy_extras.nodes_sd3",
    category: "latent/sd3",
    output_node: false,
  },
  CLIPTextEncodeSD3: {
    input: {
      required: {
        clip: ["CLIP"],
        clip_l: ["STRING", { multiline: true, dynamicPrompts: true }],
        clip_g: ["STRING", { multiline: true, dynamicPrompts: true }],
        t5xxl: ["STRING", { multiline: true, dynamicPrompts: true }],
        empty_padding: [["none", "empty_prompt"]],
      },
    },
    input_order: {
      required: ["clip", "clip_l", "clip_g", "t5xxl", "empty_padding"],
    },
    output: ["CONDITIONING"],
    output_is_list: [false],
    output_name: ["CONDITIONING"],
    name: "CLIPTextEncodeSD3",
    display_name: "CLIPTextEncodeSD3",
    description: "",
    python_module: "comfy_extras.nodes_sd3",
    category: "advanced/conditioning",
    output_node: false,
  },
  ControlNetApplySD3: {
    input: {
      required: {
        positive: ["CONDITIONING"],
        negative: ["CONDITIONING"],
        control_net: ["CONTROL_NET"],
        vae: ["VAE"],
        image: ["IMAGE"],
        strength: ["FLOAT", { default: 1.0, min: 0.0, max: 10.0, step: 0.01 }],
        start_percent: [
          "FLOAT",
          { default: 0.0, min: 0.0, max: 1.0, step: 0.001 },
        ],
        end_percent: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.001 },
        ],
      },
    },
    input_order: {
      required: [
        "positive",
        "negative",
        "control_net",
        "vae",
        "image",
        "strength",
        "start_percent",
        "end_percent",
      ],
    },
    output: ["CONDITIONING", "CONDITIONING"],
    output_is_list: [false, false],
    output_name: ["positive", "negative"],
    name: "ControlNetApplySD3",
    display_name: "Apply Controlnet with VAE",
    description: "",
    python_module: "comfy_extras.nodes_sd3",
    category: "conditioning/controlnet",
    output_node: false,
    deprecated: true,
  },
  GITSScheduler: {
    input: {
      required: {
        coeff: ["FLOAT", { default: 1.2, min: 0.8, max: 1.5, step: 0.05 }],
        steps: ["INT", { default: 10, min: 2, max: 1000 }],
        denoise: ["FLOAT", { default: 1.0, min: 0.0, max: 1.0, step: 0.01 }],
      },
    },
    input_order: { required: ["coeff", "steps", "denoise"] },
    output: ["SIGMAS"],
    output_is_list: [false],
    output_name: ["SIGMAS"],
    name: "GITSScheduler",
    display_name: "GITSScheduler",
    description: "",
    python_module: "comfy_extras.nodes_gits",
    category: "sampling/custom_sampling/schedulers",
    output_node: false,
  },
  SetUnionControlNetType: {
    input: {
      required: {
        control_net: ["CONTROL_NET"],
        type: [
          [
            "auto",
            "openpose",
            "depth",
            "hed/pidi/scribble/ted",
            "canny/lineart/anime_lineart/mlsd",
            "normal",
            "segment",
            "tile",
            "repaint",
          ],
        ],
      },
    },
    input_order: { required: ["control_net", "type"] },
    output: ["CONTROL_NET"],
    output_is_list: [false],
    output_name: ["CONTROL_NET"],
    name: "SetUnionControlNetType",
    display_name: "SetUnionControlNetType",
    description: "",
    python_module: "comfy_extras.nodes_controlnet",
    category: "conditioning/controlnet",
    output_node: false,
  },
  ControlNetInpaintingAliMamaApply: {
    input: {
      required: {
        positive: ["CONDITIONING"],
        negative: ["CONDITIONING"],
        control_net: ["CONTROL_NET"],
        vae: ["VAE"],
        image: ["IMAGE"],
        mask: ["MASK"],
        strength: ["FLOAT", { default: 1.0, min: 0.0, max: 10.0, step: 0.01 }],
        start_percent: [
          "FLOAT",
          { default: 0.0, min: 0.0, max: 1.0, step: 0.001 },
        ],
        end_percent: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.001 },
        ],
      },
    },
    input_order: {
      required: [
        "positive",
        "negative",
        "control_net",
        "vae",
        "image",
        "mask",
        "strength",
        "start_percent",
        "end_percent",
      ],
    },
    output: ["CONDITIONING", "CONDITIONING"],
    output_is_list: [false, false],
    output_name: ["positive", "negative"],
    name: "ControlNetInpaintingAliMamaApply",
    display_name: "ControlNetInpaintingAliMamaApply",
    description: "",
    python_module: "comfy_extras.nodes_controlnet",
    category: "conditioning/controlnet",
    output_node: false,
  },
  CLIPTextEncodeHunyuanDiT: {
    input: {
      required: {
        clip: ["CLIP"],
        bert: ["STRING", { multiline: true, dynamicPrompts: true }],
        mt5xl: ["STRING", { multiline: true, dynamicPrompts: true }],
      },
    },
    input_order: { required: ["clip", "bert", "mt5xl"] },
    output: ["CONDITIONING"],
    output_is_list: [false],
    output_name: ["CONDITIONING"],
    name: "CLIPTextEncodeHunyuanDiT",
    display_name: "CLIPTextEncodeHunyuanDiT",
    description: "",
    python_module: "comfy_extras.nodes_hunyuan",
    category: "advanced/conditioning",
    output_node: false,
  },
  CLIPTextEncodeFlux: {
    input: {
      required: {
        clip: ["CLIP"],
        clip_l: ["STRING", { multiline: true, dynamicPrompts: true }],
        t5xxl: ["STRING", { multiline: true, dynamicPrompts: true }],
        guidance: ["FLOAT", { default: 3.5, min: 0.0, max: 100.0, step: 0.1 }],
      },
    },
    input_order: { required: ["clip", "clip_l", "t5xxl", "guidance"] },
    output: ["CONDITIONING"],
    output_is_list: [false],
    output_name: ["CONDITIONING"],
    name: "CLIPTextEncodeFlux",
    display_name: "CLIPTextEncodeFlux",
    description: "",
    python_module: "comfy_extras.nodes_flux",
    category: "advanced/conditioning/flux",
    output_node: false,
  },
  FluxGuidance: {
    input: {
      required: {
        conditioning: ["CONDITIONING"],
        guidance: ["FLOAT", { default: 3.5, min: 0.0, max: 100.0, step: 0.1 }],
      },
    },
    input_order: { required: ["conditioning", "guidance"] },
    output: ["CONDITIONING"],
    output_is_list: [false],
    output_name: ["CONDITIONING"],
    name: "FluxGuidance",
    display_name: "FluxGuidance",
    description: "",
    python_module: "comfy_extras.nodes_flux",
    category: "advanced/conditioning/flux",
    output_node: false,
  },
  LoraSave: {
    input: {
      required: {
        filename_prefix: [
          "STRING",
          { default: "loras/ComfyUI_extracted_lora" },
        ],
        rank: ["INT", { default: 8, min: 1, max: 4096, step: 1 }],
        lora_type: [["standard", "full_diff"]],
        bias_diff: ["BOOLEAN", { default: true }],
      },
      optional: { model_diff: ["MODEL"], text_encoder_diff: ["CLIP"] },
    },
    input_order: {
      required: ["filename_prefix", "rank", "lora_type", "bias_diff"],
      optional: ["model_diff", "text_encoder_diff"],
    },
    output: [],
    output_is_list: [],
    output_name: [],
    name: "LoraSave",
    display_name: "LoraSave",
    description: "",
    python_module: "comfy_extras.nodes_lora_extract",
    category: "_for_testing",
    output_node: true,
  },
  TorchCompileModel: {
    input: {
      required: { model: ["MODEL"], backend: [["inductor", "cudagraphs"]] },
    },
    input_order: { required: ["model", "backend"] },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "TorchCompileModel",
    display_name: "TorchCompileModel",
    description: "",
    python_module: "comfy_extras.nodes_torch_compile",
    category: "_for_testing",
    output_node: false,
    experimental: true,
  },
  "Remove Image Background (abg)": {
    input: { required: { image: ["IMAGE"] } },
    input_order: { required: ["image"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "Remove Image Background (abg)",
    display_name: "Remove Image Background (abg)",
    description: "",
    python_module: "custom_nodes.abg-comfyui",
    category: "image",
    output_node: false,
  },
  BRIA_RMBG_ModelLoader_Zho: {
    input: { required: {} },
    input_order: { required: [] },
    output: ["RMBGMODEL"],
    output_is_list: [false],
    output_name: ["rmbgmodel"],
    name: "BRIA_RMBG_ModelLoader_Zho",
    display_name: "\ud83e\uddf9BRIA_RMBG Model Loader",
    description: "",
    python_module: "custom_nodes.ComfyUI-BRIA_AI-RMBG",
    category: "\ud83e\uddf9BRIA RMBG",
    output_node: false,
  },
  BRIA_RMBG_Zho: {
    input: { required: { rmbgmodel: ["RMBGMODEL"], image: ["IMAGE"] } },
    input_order: { required: ["rmbgmodel", "image"] },
    output: ["IMAGE", "MASK"],
    output_is_list: [false, false],
    output_name: ["image", "mask"],
    name: "BRIA_RMBG_Zho",
    display_name: "\ud83e\uddf9BRIA RMBG",
    description: "",
    python_module: "custom_nodes.ComfyUI-BRIA_AI-RMBG",
    category: "\ud83e\uddf9BRIA RMBG",
    output_node: false,
  },
  DownloadAndLoadFlorence2Model: {
    input: {
      required: {
        model: [
          [
            "microsoft/Florence-2-base",
            "microsoft/Florence-2-base-ft",
            "microsoft/Florence-2-large",
            "microsoft/Florence-2-large-ft",
            "HuggingFaceM4/Florence-2-DocVQA",
            "thwri/CogFlorence-2.1-Large",
            "gokaygokay/Florence-2-SD3-Captioner",
            "MiaoshouAI/Florence-2-base-PromptGen",
          ],
          { default: "microsoft/Florence-2-base" },
        ],
        precision: [["fp16", "bf16", "fp32"], { default: "fp16" }],
        attention: [
          ["flash_attention_2", "sdpa", "eager"],
          { default: "sdpa" },
        ],
      },
      optional: { lora: ["PEFTLORA"] },
    },
    input_order: {
      required: ["model", "precision", "attention"],
      optional: ["lora"],
    },
    output: ["FL2MODEL"],
    output_is_list: [false],
    output_name: ["florence2_model"],
    name: "DownloadAndLoadFlorence2Model",
    display_name: "DownloadAndLoadFlorence2Model",
    description: "",
    python_module: "custom_nodes.ComfyUI-Florence2",
    category: "Florence2",
    output_node: false,
  },
  DownloadAndLoadFlorence2Lora: {
    input: { required: { model: [["NikshepShetty/Florence-2-pixelprose"]] } },
    input_order: { required: ["model"] },
    output: ["PEFTLORA"],
    output_is_list: [false],
    output_name: ["lora"],
    name: "DownloadAndLoadFlorence2Lora",
    display_name: "DownloadAndLoadFlorence2Lora",
    description: "",
    python_module: "custom_nodes.ComfyUI-Florence2",
    category: "Florence2",
    output_node: false,
  },
  Florence2ModelLoader: {
    input: {
      required: {
        model: [["Florence-2-base"]],
        precision: [["fp16", "bf16", "fp32"]],
        attention: [
          ["flash_attention_2", "sdpa", "eager"],
          { default: "sdpa" },
        ],
      },
      optional: { lora: ["PEFTLORA"] },
    },
    input_order: {
      required: ["model", "precision", "attention"],
      optional: ["lora"],
    },
    output: ["FL2MODEL"],
    output_is_list: [false],
    output_name: ["florence2_model"],
    name: "Florence2ModelLoader",
    display_name: "Florence2ModelLoader",
    description: "",
    python_module: "custom_nodes.ComfyUI-Florence2",
    category: "Florence2",
    output_node: false,
  },
  Florence2Run: {
    input: {
      required: {
        image: ["IMAGE"],
        florence2_model: ["FL2MODEL"],
        text_input: ["STRING", { default: "", multiline: true }],
        task: [
          [
            "region_caption",
            "dense_region_caption",
            "region_proposal",
            "caption",
            "detailed_caption",
            "more_detailed_caption",
            "caption_to_phrase_grounding",
            "referring_expression_segmentation",
            "ocr",
            "ocr_with_region",
            "docvqa",
            "prompt_gen",
          ],
        ],
        fill_mask: ["BOOLEAN", { default: true }],
      },
      optional: {
        keep_model_loaded: ["BOOLEAN", { default: false }],
        max_new_tokens: ["INT", { default: 1024, min: 1, max: 4096 }],
        num_beams: ["INT", { default: 3, min: 1, max: 64 }],
        do_sample: ["BOOLEAN", { default: true }],
        output_mask_select: ["STRING", { default: "" }],
        seed: ["INT", { default: 1, min: 1, max: 18446744073709551615 }],
      },
    },
    input_order: {
      required: ["image", "florence2_model", "text_input", "task", "fill_mask"],
      optional: [
        "keep_model_loaded",
        "max_new_tokens",
        "num_beams",
        "do_sample",
        "output_mask_select",
        "seed",
      ],
    },
    output: ["IMAGE", "MASK", "STRING", "JSON"],
    output_is_list: [false, false, false, false],
    output_name: ["image", "mask", "caption", "data"],
    name: "Florence2Run",
    display_name: "Florence2Run",
    description: "",
    python_module: "custom_nodes.ComfyUI-Florence2",
    category: "Florence2",
    output_node: false,
  },
  INTConstant: {
    input: {
      required: {
        value: ["INT", { default: 0, min: 0, max: 18446744073709551615 }],
      },
    },
    input_order: { required: ["value"] },
    output: ["INT"],
    output_is_list: [false],
    output_name: ["value"],
    name: "INTConstant",
    display_name: "INT Constant",
    description: "",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/constants",
    output_node: false,
  },
  FloatConstant: {
    input: {
      required: {
        value: [
          "FLOAT",
          {
            default: 0.0,
            min: -18446744073709551615,
            max: 18446744073709551615,
            step: 0.001,
          },
        ],
      },
    },
    input_order: { required: ["value"] },
    output: ["FLOAT"],
    output_is_list: [false],
    output_name: ["value"],
    name: "FloatConstant",
    display_name: "Float Constant",
    description: "",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/constants",
    output_node: false,
  },
  StringConstant: {
    input: {
      required: { string: ["STRING", { default: "", multiline: false }] },
    },
    input_order: { required: ["string"] },
    output: ["STRING"],
    output_is_list: [false],
    output_name: ["STRING"],
    name: "StringConstant",
    display_name: "String Constant",
    description: "",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/constants",
    output_node: false,
  },
  StringConstantMultiline: {
    input: {
      required: {
        string: ["STRING", { default: "", multiline: true }],
        strip_newlines: ["BOOLEAN", { default: true }],
      },
    },
    input_order: { required: ["string", "strip_newlines"] },
    output: ["STRING"],
    output_is_list: [false],
    output_name: ["STRING"],
    name: "StringConstantMultiline",
    display_name: "String Constant Multiline",
    description: "",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/constants",
    output_node: false,
  },
  ConditioningMultiCombine: {
    input: {
      required: {
        inputcount: ["INT", { default: 2, min: 2, max: 20, step: 1 }],
        conditioning_1: ["CONDITIONING"],
        conditioning_2: ["CONDITIONING"],
      },
    },
    input_order: {
      required: ["inputcount", "conditioning_1", "conditioning_2"],
    },
    output: ["CONDITIONING", "INT"],
    output_is_list: [false, false],
    output_name: ["combined", "inputcount"],
    name: "ConditioningMultiCombine",
    display_name: "Conditioning Multi Combine",
    description: "\nCombines multiple conditioning nodes into one\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking/conditioning",
    output_node: false,
  },
  ConditioningSetMaskAndCombine: {
    input: {
      required: {
        positive_1: ["CONDITIONING"],
        negative_1: ["CONDITIONING"],
        positive_2: ["CONDITIONING"],
        negative_2: ["CONDITIONING"],
        mask_1: ["MASK"],
        mask_2: ["MASK"],
        mask_1_strength: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 10.0, step: 0.01 },
        ],
        mask_2_strength: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 10.0, step: 0.01 },
        ],
        set_cond_area: [["default", "mask bounds"]],
      },
    },
    input_order: {
      required: [
        "positive_1",
        "negative_1",
        "positive_2",
        "negative_2",
        "mask_1",
        "mask_2",
        "mask_1_strength",
        "mask_2_strength",
        "set_cond_area",
      ],
    },
    output: ["CONDITIONING", "CONDITIONING"],
    output_is_list: [false, false],
    output_name: ["combined_positive", "combined_negative"],
    name: "ConditioningSetMaskAndCombine",
    display_name: "ConditioningSetMaskAndCombine",
    description:
      "\nBundles multiple conditioning mask and combine nodes into one,functionality is identical to ComfyUI native nodes\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking/conditioning",
    output_node: false,
  },
  ConditioningSetMaskAndCombine3: {
    input: {
      required: {
        positive_1: ["CONDITIONING"],
        negative_1: ["CONDITIONING"],
        positive_2: ["CONDITIONING"],
        negative_2: ["CONDITIONING"],
        positive_3: ["CONDITIONING"],
        negative_3: ["CONDITIONING"],
        mask_1: ["MASK"],
        mask_2: ["MASK"],
        mask_3: ["MASK"],
        mask_1_strength: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 10.0, step: 0.01 },
        ],
        mask_2_strength: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 10.0, step: 0.01 },
        ],
        mask_3_strength: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 10.0, step: 0.01 },
        ],
        set_cond_area: [["default", "mask bounds"]],
      },
    },
    input_order: {
      required: [
        "positive_1",
        "negative_1",
        "positive_2",
        "negative_2",
        "positive_3",
        "negative_3",
        "mask_1",
        "mask_2",
        "mask_3",
        "mask_1_strength",
        "mask_2_strength",
        "mask_3_strength",
        "set_cond_area",
      ],
    },
    output: ["CONDITIONING", "CONDITIONING"],
    output_is_list: [false, false],
    output_name: ["combined_positive", "combined_negative"],
    name: "ConditioningSetMaskAndCombine3",
    display_name: "ConditioningSetMaskAndCombine3",
    description:
      "\nBundles multiple conditioning mask and combine nodes into one,functionality is identical to ComfyUI native nodes\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking/conditioning",
    output_node: false,
  },
  ConditioningSetMaskAndCombine4: {
    input: {
      required: {
        positive_1: ["CONDITIONING"],
        negative_1: ["CONDITIONING"],
        positive_2: ["CONDITIONING"],
        negative_2: ["CONDITIONING"],
        positive_3: ["CONDITIONING"],
        negative_3: ["CONDITIONING"],
        positive_4: ["CONDITIONING"],
        negative_4: ["CONDITIONING"],
        mask_1: ["MASK"],
        mask_2: ["MASK"],
        mask_3: ["MASK"],
        mask_4: ["MASK"],
        mask_1_strength: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 10.0, step: 0.01 },
        ],
        mask_2_strength: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 10.0, step: 0.01 },
        ],
        mask_3_strength: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 10.0, step: 0.01 },
        ],
        mask_4_strength: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 10.0, step: 0.01 },
        ],
        set_cond_area: [["default", "mask bounds"]],
      },
    },
    input_order: {
      required: [
        "positive_1",
        "negative_1",
        "positive_2",
        "negative_2",
        "positive_3",
        "negative_3",
        "positive_4",
        "negative_4",
        "mask_1",
        "mask_2",
        "mask_3",
        "mask_4",
        "mask_1_strength",
        "mask_2_strength",
        "mask_3_strength",
        "mask_4_strength",
        "set_cond_area",
      ],
    },
    output: ["CONDITIONING", "CONDITIONING"],
    output_is_list: [false, false],
    output_name: ["combined_positive", "combined_negative"],
    name: "ConditioningSetMaskAndCombine4",
    display_name: "ConditioningSetMaskAndCombine4",
    description:
      "\nBundles multiple conditioning mask and combine nodes into one,functionality is identical to ComfyUI native nodes\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking/conditioning",
    output_node: false,
  },
  ConditioningSetMaskAndCombine5: {
    input: {
      required: {
        positive_1: ["CONDITIONING"],
        negative_1: ["CONDITIONING"],
        positive_2: ["CONDITIONING"],
        negative_2: ["CONDITIONING"],
        positive_3: ["CONDITIONING"],
        negative_3: ["CONDITIONING"],
        positive_4: ["CONDITIONING"],
        negative_4: ["CONDITIONING"],
        positive_5: ["CONDITIONING"],
        negative_5: ["CONDITIONING"],
        mask_1: ["MASK"],
        mask_2: ["MASK"],
        mask_3: ["MASK"],
        mask_4: ["MASK"],
        mask_5: ["MASK"],
        mask_1_strength: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 10.0, step: 0.01 },
        ],
        mask_2_strength: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 10.0, step: 0.01 },
        ],
        mask_3_strength: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 10.0, step: 0.01 },
        ],
        mask_4_strength: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 10.0, step: 0.01 },
        ],
        mask_5_strength: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 10.0, step: 0.01 },
        ],
        set_cond_area: [["default", "mask bounds"]],
      },
    },
    input_order: {
      required: [
        "positive_1",
        "negative_1",
        "positive_2",
        "negative_2",
        "positive_3",
        "negative_3",
        "positive_4",
        "negative_4",
        "positive_5",
        "negative_5",
        "mask_1",
        "mask_2",
        "mask_3",
        "mask_4",
        "mask_5",
        "mask_1_strength",
        "mask_2_strength",
        "mask_3_strength",
        "mask_4_strength",
        "mask_5_strength",
        "set_cond_area",
      ],
    },
    output: ["CONDITIONING", "CONDITIONING"],
    output_is_list: [false, false],
    output_name: ["combined_positive", "combined_negative"],
    name: "ConditioningSetMaskAndCombine5",
    display_name: "ConditioningSetMaskAndCombine5",
    description:
      "\nBundles multiple conditioning mask and combine nodes into one,functionality is identical to ComfyUI native nodes\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking/conditioning",
    output_node: false,
  },
  CondPassThrough: {
    input: {
      required: {},
      optional: { positive: ["CONDITIONING"], negative: ["CONDITIONING"] },
    },
    input_order: { required: [], optional: ["positive", "negative"] },
    output: ["CONDITIONING", "CONDITIONING"],
    output_is_list: [false, false],
    output_name: ["positive", "negative"],
    name: "CondPassThrough",
    display_name: "CondPassThrough",
    description:
      "\nSimply passes through the positive and negative conditioning,\nworkaround for Set node not allowing bypassed inputs.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/misc",
    output_node: false,
  },
  DownloadAndLoadCLIPSeg: {
    input: {
      required: {
        model: [
          ["Kijai/clipseg-rd64-refined-fp16", "CIDAS/clipseg-rd64-refined"],
        ],
      },
    },
    input_order: { required: ["model"] },
    output: ["CLIPSEGMODEL"],
    output_is_list: [false],
    output_name: ["clipseg_model"],
    name: "DownloadAndLoadCLIPSeg",
    display_name: "(Down)load CLIPSeg",
    description:
      "\nDownloads and loads CLIPSeg model with huggingface_hub,\nto ComfyUI/models/clip_seg\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking",
    output_node: false,
  },
  BatchCLIPSeg: {
    input: {
      required: {
        images: ["IMAGE"],
        text: ["STRING", { multiline: false }],
        threshold: [
          "FLOAT",
          { default: 0.5, min: 0.0, max: 10.0, step: 0.001 },
        ],
        binary_mask: ["BOOLEAN", { default: true }],
        combine_mask: ["BOOLEAN", { default: false }],
        use_cuda: ["BOOLEAN", { default: true }],
      },
      optional: {
        blur_sigma: [
          "FLOAT",
          { default: 0.0, min: 0.0, max: 100.0, step: 0.1 },
        ],
        opt_model: ["CLIPSEGMODEL"],
        prev_mask: ["MASK", { default: null }],
        image_bg_level: [
          "FLOAT",
          { default: 0.5, min: 0.0, max: 1.0, step: 0.01 },
        ],
        invert: ["BOOLEAN", { default: false }],
      },
    },
    input_order: {
      required: [
        "images",
        "text",
        "threshold",
        "binary_mask",
        "combine_mask",
        "use_cuda",
      ],
      optional: [
        "blur_sigma",
        "opt_model",
        "prev_mask",
        "image_bg_level",
        "invert",
      ],
    },
    output: ["MASK", "IMAGE"],
    output_is_list: [false, false],
    output_name: ["Mask", "Image"],
    name: "BatchCLIPSeg",
    display_name: "Batch CLIPSeg",
    description: "\nSegments an image or batch of images using CLIPSeg.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking",
    output_node: false,
  },
  ColorToMask: {
    input: {
      required: {
        images: ["IMAGE"],
        invert: ["BOOLEAN", { default: false }],
        red: ["INT", { default: 0, min: 0, max: 255, step: 1 }],
        green: ["INT", { default: 0, min: 0, max: 255, step: 1 }],
        blue: ["INT", { default: 0, min: 0, max: 255, step: 1 }],
        threshold: ["INT", { default: 10, min: 0, max: 255, step: 1 }],
        per_batch: ["INT", { default: 16, min: 1, max: 4096, step: 1 }],
      },
    },
    input_order: {
      required: [
        "images",
        "invert",
        "red",
        "green",
        "blue",
        "threshold",
        "per_batch",
      ],
    },
    output: ["MASK"],
    output_is_list: [false],
    output_name: ["MASK"],
    name: "ColorToMask",
    display_name: "Color To Mask",
    description:
      "\nConverts chosen RGB value to a mask.\nWith batch inputs, the **per_batch**\ncontrols the number of images processed at once.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking",
    output_node: false,
  },
  CreateGradientMask: {
    input: {
      required: {
        invert: ["BOOLEAN", { default: false }],
        frames: ["INT", { default: 0, min: 0, max: 255, step: 1 }],
        width: ["INT", { default: 256, min: 16, max: 4096, step: 1 }],
        height: ["INT", { default: 256, min: 16, max: 4096, step: 1 }],
      },
    },
    input_order: { required: ["invert", "frames", "width", "height"] },
    output: ["MASK"],
    output_is_list: [false],
    output_name: ["MASK"],
    name: "CreateGradientMask",
    display_name: "Create Gradient Mask",
    description: "",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking/generate",
    output_node: false,
  },
  CreateTextMask: {
    input: {
      required: {
        invert: ["BOOLEAN", { default: false }],
        frames: ["INT", { default: 1, min: 1, max: 4096, step: 1 }],
        text_x: ["INT", { default: 0, min: 0, max: 4096, step: 1 }],
        text_y: ["INT", { default: 0, min: 0, max: 4096, step: 1 }],
        font_size: ["INT", { default: 32, min: 8, max: 4096, step: 1 }],
        font_color: ["STRING", { default: "white" }],
        text: ["STRING", { default: "HELLO!", multiline: true }],
        font: [
          ["FreeMono.ttf", "FreeMonoBoldOblique.otf", "TTNorms-Black.otf"],
        ],
        width: ["INT", { default: 512, min: 16, max: 4096, step: 1 }],
        height: ["INT", { default: 512, min: 16, max: 4096, step: 1 }],
        start_rotation: ["INT", { default: 0, min: 0, max: 359, step: 1 }],
        end_rotation: ["INT", { default: 0, min: -359, max: 359, step: 1 }],
      },
    },
    input_order: {
      required: [
        "invert",
        "frames",
        "text_x",
        "text_y",
        "font_size",
        "font_color",
        "text",
        "font",
        "width",
        "height",
        "start_rotation",
        "end_rotation",
      ],
    },
    output: ["IMAGE", "MASK"],
    output_is_list: [false, false],
    output_name: ["IMAGE", "MASK"],
    name: "CreateTextMask",
    display_name: "Create Text Mask",
    description:
      "\nCreates a text image and mask.\nLooks for fonts from this folder:\nComfyUI/custom_nodes/ComfyUI-KJNodes/fonts\n\nIf start_rotation and/or end_rotation are different values,\ncreates animation between them.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/text",
    output_node: false,
  },
  CreateAudioMask: {
    input: {
      required: {
        invert: ["BOOLEAN", { default: false }],
        frames: ["INT", { default: 16, min: 1, max: 255, step: 1 }],
        scale: ["FLOAT", { default: 0.5, min: 0.0, max: 2.0, step: 0.01 }],
        audio_path: ["STRING", { default: "audio.wav" }],
        width: ["INT", { default: 256, min: 16, max: 4096, step: 1 }],
        height: ["INT", { default: 256, min: 16, max: 4096, step: 1 }],
      },
    },
    input_order: {
      required: ["invert", "frames", "scale", "audio_path", "width", "height"],
    },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "CreateAudioMask",
    display_name: "Create Audio Mask",
    description: "",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/deprecated",
    output_node: false,
  },
  CreateFadeMask: {
    input: {
      required: {
        invert: ["BOOLEAN", { default: false }],
        frames: ["INT", { default: 2, min: 2, max: 255, step: 1 }],
        width: ["INT", { default: 256, min: 16, max: 4096, step: 1 }],
        height: ["INT", { default: 256, min: 16, max: 4096, step: 1 }],
        interpolation: [["linear", "ease_in", "ease_out", "ease_in_out"]],
        start_level: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        midpoint_level: [
          "FLOAT",
          { default: 0.5, min: 0.0, max: 1.0, step: 0.01 },
        ],
        end_level: ["FLOAT", { default: 0.0, min: 0.0, max: 1.0, step: 0.01 }],
        midpoint_frame: ["INT", { default: 0, min: 0, max: 4096, step: 1 }],
      },
    },
    input_order: {
      required: [
        "invert",
        "frames",
        "width",
        "height",
        "interpolation",
        "start_level",
        "midpoint_level",
        "end_level",
        "midpoint_frame",
      ],
    },
    output: ["MASK"],
    output_is_list: [false],
    output_name: ["MASK"],
    name: "CreateFadeMask",
    display_name: "Create Fade Mask",
    description: "",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/deprecated",
    output_node: false,
  },
  CreateFadeMaskAdvanced: {
    input: {
      required: {
        points_string: [
          "STRING",
          { default: "0:(0.0),\n7:(1.0),\n15:(0.0)\n", multiline: true },
        ],
        invert: ["BOOLEAN", { default: false }],
        frames: ["INT", { default: 16, min: 2, max: 255, step: 1 }],
        width: ["INT", { default: 512, min: 1, max: 4096, step: 1 }],
        height: ["INT", { default: 512, min: 1, max: 4096, step: 1 }],
        interpolation: [["linear", "ease_in", "ease_out", "ease_in_out"]],
      },
    },
    input_order: {
      required: [
        "points_string",
        "invert",
        "frames",
        "width",
        "height",
        "interpolation",
      ],
    },
    output: ["MASK"],
    output_is_list: [false],
    output_name: ["MASK"],
    name: "CreateFadeMaskAdvanced",
    display_name: "Create Fade Mask Advanced",
    description:
      "\nCreate a batch of masks interpolated between given frames and values. \nUses same syntax as Fizz' BatchValueSchedule.\nFirst value is the frame index (not that this starts from 0, not 1) \nand the second value inside the brackets is the float value of the mask in range 0.0 - 1.0\n\nFor example the default values:\n0:(0.0)\n7:(1.0)\n15:(0.0)\n\nWould create a mask batch fo 16 frames, starting from black, \ninterpolating with the chosen curve to fully white at the 8th frame, \nand interpolating from that to fully black at the 16th frame.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking/generate",
    output_node: false,
  },
  CreateFluidMask: {
    input: {
      required: {
        invert: ["BOOLEAN", { default: false }],
        frames: ["INT", { default: 1, min: 1, max: 4096, step: 1 }],
        width: ["INT", { default: 256, min: 16, max: 4096, step: 1 }],
        height: ["INT", { default: 256, min: 16, max: 4096, step: 1 }],
        inflow_count: ["INT", { default: 3, min: 0, max: 255, step: 1 }],
        inflow_velocity: ["INT", { default: 1, min: 0, max: 255, step: 1 }],
        inflow_radius: ["INT", { default: 8, min: 0, max: 255, step: 1 }],
        inflow_padding: ["INT", { default: 50, min: 0, max: 255, step: 1 }],
        inflow_duration: ["INT", { default: 60, min: 0, max: 255, step: 1 }],
      },
    },
    input_order: {
      required: [
        "invert",
        "frames",
        "width",
        "height",
        "inflow_count",
        "inflow_velocity",
        "inflow_radius",
        "inflow_padding",
        "inflow_duration",
      ],
    },
    output: ["IMAGE", "MASK"],
    output_is_list: [false, false],
    output_name: ["IMAGE", "MASK"],
    name: "CreateFluidMask",
    display_name: "Create Fluid Mask",
    description: "",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking/generate",
    output_node: false,
  },
  CreateShapeMask: {
    input: {
      required: {
        shape: [["circle", "square", "triangle"], { default: "circle" }],
        frames: ["INT", { default: 1, min: 1, max: 4096, step: 1 }],
        location_x: ["INT", { default: 256, min: 0, max: 4096, step: 1 }],
        location_y: ["INT", { default: 256, min: 0, max: 4096, step: 1 }],
        grow: ["INT", { default: 0, min: -512, max: 512, step: 1 }],
        frame_width: ["INT", { default: 512, min: 16, max: 4096, step: 1 }],
        frame_height: ["INT", { default: 512, min: 16, max: 4096, step: 1 }],
        shape_width: ["INT", { default: 128, min: 8, max: 4096, step: 1 }],
        shape_height: ["INT", { default: 128, min: 8, max: 4096, step: 1 }],
      },
    },
    input_order: {
      required: [
        "shape",
        "frames",
        "location_x",
        "location_y",
        "grow",
        "frame_width",
        "frame_height",
        "shape_width",
        "shape_height",
      ],
    },
    output: ["MASK", "MASK"],
    output_is_list: [false, false],
    output_name: ["mask", "mask_inverted"],
    name: "CreateShapeMask",
    display_name: "Create Shape Mask",
    description:
      "\nCreates a mask or batch of masks with the specified shape.\nLocations are center locations.\nGrow value is the amount to grow the shape on each frame, creating animated masks.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking/generate",
    output_node: false,
  },
  CreateVoronoiMask: {
    input: {
      required: {
        frames: ["INT", { default: 16, min: 2, max: 4096, step: 1 }],
        num_points: ["INT", { default: 15, min: 1, max: 4096, step: 1 }],
        line_width: ["INT", { default: 4, min: 1, max: 4096, step: 1 }],
        speed: ["FLOAT", { default: 0.5, min: 0.0, max: 1.0, step: 0.01 }],
        frame_width: ["INT", { default: 512, min: 16, max: 4096, step: 1 }],
        frame_height: ["INT", { default: 512, min: 16, max: 4096, step: 1 }],
      },
    },
    input_order: {
      required: [
        "frames",
        "num_points",
        "line_width",
        "speed",
        "frame_width",
        "frame_height",
      ],
    },
    output: ["MASK", "MASK"],
    output_is_list: [false, false],
    output_name: ["mask", "mask_inverted"],
    name: "CreateVoronoiMask",
    display_name: "Create Voronoi Mask",
    description: "",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking/generate",
    output_node: false,
  },
  CreateMagicMask: {
    input: {
      required: {
        frames: ["INT", { default: 16, min: 2, max: 4096, step: 1 }],
        depth: ["INT", { default: 12, min: 1, max: 500, step: 1 }],
        distortion: [
          "FLOAT",
          { default: 1.5, min: 0.0, max: 100.0, step: 0.01 },
        ],
        seed: ["INT", { default: 123, min: 0, max: 99999999, step: 1 }],
        transitions: ["INT", { default: 1, min: 1, max: 20, step: 1 }],
        frame_width: ["INT", { default: 512, min: 16, max: 4096, step: 1 }],
        frame_height: ["INT", { default: 512, min: 16, max: 4096, step: 1 }],
      },
    },
    input_order: {
      required: [
        "frames",
        "depth",
        "distortion",
        "seed",
        "transitions",
        "frame_width",
        "frame_height",
      ],
    },
    output: ["MASK", "MASK"],
    output_is_list: [false, false],
    output_name: ["mask", "mask_inverted"],
    name: "CreateMagicMask",
    display_name: "Create Magic Mask",
    description: "",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking/generate",
    output_node: false,
  },
  GetMaskSizeAndCount: {
    input: { required: { mask: ["MASK"] } },
    input_order: { required: ["mask"] },
    output: ["MASK", "INT", "INT", "INT"],
    output_is_list: [false, false, false, false],
    output_name: ["mask", "width", "height", "count"],
    name: "GetMaskSizeAndCount",
    display_name: "Get Mask Size & Count",
    description:
      "\nReturns the width, height and batch size of the mask,\nand passes it through unchanged.\n\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking",
    output_node: false,
  },
  GrowMaskWithBlur: {
    input: {
      required: {
        mask: ["MASK"],
        expand: ["INT", { default: 0, min: -16384, max: 16384, step: 1 }],
        incremental_expandrate: [
          "FLOAT",
          { default: 0.0, min: 0.0, max: 100.0, step: 0.1 },
        ],
        tapered_corners: ["BOOLEAN", { default: true }],
        flip_input: ["BOOLEAN", { default: false }],
        blur_radius: ["FLOAT", { default: 0.0, min: 0.0, max: 100, step: 0.1 }],
        lerp_alpha: ["FLOAT", { default: 1.0, min: 0.0, max: 1.0, step: 0.01 }],
        decay_factor: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
      },
      optional: { fill_holes: ["BOOLEAN", { default: false }] },
    },
    input_order: {
      required: [
        "mask",
        "expand",
        "incremental_expandrate",
        "tapered_corners",
        "flip_input",
        "blur_radius",
        "lerp_alpha",
        "decay_factor",
      ],
      optional: ["fill_holes"],
    },
    output: ["MASK", "MASK"],
    output_is_list: [false, false],
    output_name: ["mask", "mask_inverted"],
    name: "GrowMaskWithBlur",
    display_name: "Grow Mask With Blur",
    description:
      "\n# GrowMaskWithBlur\n- mask: Input mask or mask batch\n- expand: Expand or contract mask or mask batch by a given amount\n- incremental_expandrate: increase expand rate by a given amount per frame\n- tapered_corners: use tapered corners\n- flip_input: flip input mask\n- blur_radius: value higher than 0 will blur the mask\n- lerp_alpha: alpha value for interpolation between frames\n- decay_factor: decay value for interpolation between frames\n- fill_holes: fill holes in the mask (slow)",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking",
    output_node: false,
  },
  MaskBatchMulti: {
    input: {
      required: {
        inputcount: ["INT", { default: 2, min: 2, max: 1000, step: 1 }],
        mask_1: ["MASK"],
        mask_2: ["MASK"],
      },
    },
    input_order: { required: ["inputcount", "mask_1", "mask_2"] },
    output: ["MASK"],
    output_is_list: [false],
    output_name: ["masks"],
    name: "MaskBatchMulti",
    display_name: "Mask Batch Multi",
    description:
      "\nCreates an image batch from multiple masks.\nYou can set how many inputs the node has,\nwith the **inputcount** and clicking update.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking",
    output_node: false,
  },
  OffsetMask: {
    input: {
      required: {
        mask: ["MASK"],
        x: [
          "INT",
          { default: 0, min: -4096, max: 16384, step: 1, display: "number" },
        ],
        y: [
          "INT",
          { default: 0, min: -4096, max: 16384, step: 1, display: "number" },
        ],
        angle: [
          "INT",
          { default: 0, min: -360, max: 360, step: 1, display: "number" },
        ],
        duplication_factor: [
          "INT",
          { default: 1, min: 1, max: 1000, step: 1, display: "number" },
        ],
        roll: ["BOOLEAN", { default: false }],
        incremental: ["BOOLEAN", { default: false }],
        padding_mode: [["empty", "border", "reflection"], { default: "empty" }],
      },
    },
    input_order: {
      required: [
        "mask",
        "x",
        "y",
        "angle",
        "duplication_factor",
        "roll",
        "incremental",
        "padding_mode",
      ],
    },
    output: ["MASK"],
    output_is_list: [false],
    output_name: ["mask"],
    name: "OffsetMask",
    display_name: "Offset Mask",
    description:
      "\nOffsets the mask by the specified amount.\n - mask: Input mask or mask batch\n - x: Horizontal offset\n - y: Vertical offset\n - angle: Angle in degrees\n - roll: roll edge wrapping\n - duplication_factor: Number of times to duplicate the mask to form a batch\n - border padding_mode: Padding mode for the mask\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking",
    output_node: false,
  },
  RemapMaskRange: {
    input: {
      required: {
        mask: ["MASK"],
        min: ["FLOAT", { default: 0.0, min: -10.0, max: 1.0, step: 0.01 }],
        max: ["FLOAT", { default: 1.0, min: 0.0, max: 10.0, step: 0.01 }],
      },
    },
    input_order: { required: ["mask", "min", "max"] },
    output: ["MASK"],
    output_is_list: [false],
    output_name: ["mask"],
    name: "RemapMaskRange",
    display_name: "Remap Mask Range",
    description: "\nSets new min and max values for the mask.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking",
    output_node: false,
  },
  ResizeMask: {
    input: {
      required: {
        mask: ["MASK"],
        width: [
          "INT",
          { default: 512, min: 0, max: 16384, step: 8, display: "number" },
        ],
        height: [
          "INT",
          { default: 512, min: 0, max: 16384, step: 8, display: "number" },
        ],
        keep_proportions: ["BOOLEAN", { default: false }],
      },
    },
    input_order: { required: ["mask", "width", "height", "keep_proportions"] },
    output: ["MASK", "INT", "INT"],
    output_is_list: [false, false, false],
    output_name: ["mask", "width", "height"],
    name: "ResizeMask",
    display_name: "Resize Mask",
    description:
      "\nResizes the mask or batch of masks to the specified width and height.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking",
    output_node: false,
  },
  RoundMask: {
    input: { required: { mask: ["MASK"] } },
    input_order: { required: ["mask"] },
    output: ["MASK"],
    output_is_list: [false],
    output_name: ["MASK"],
    name: "RoundMask",
    display_name: "Round Mask",
    description:
      '\nRounds the mask or batch of masks to a binary mask.\n<img src="https://github.com/kijai/ComfyUI-KJNodes/assets/40791699/52c85202-f74e-4b96-9dac-c8bda5ddcc40" width="300" height="250" alt="RoundMask example">\n\n',
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking",
    output_node: false,
  },
  AddLabel: {
    input: {
      required: {
        image: ["IMAGE"],
        text_x: ["INT", { default: 10, min: 0, max: 4096, step: 1 }],
        text_y: ["INT", { default: 2, min: 0, max: 4096, step: 1 }],
        height: ["INT", { default: 48, min: 0, max: 4096, step: 1 }],
        font_size: ["INT", { default: 32, min: 0, max: 4096, step: 1 }],
        font_color: ["STRING", { default: "white" }],
        label_color: ["STRING", { default: "black" }],
        font: [
          ["FreeMono.ttf", "FreeMonoBoldOblique.otf", "TTNorms-Black.otf"],
        ],
        text: ["STRING", { default: "Text" }],
        direction: [
          ["up", "down", "left", "right", "overlay"],
          { default: "up" },
        ],
      },
      optional: { caption: ["STRING", { default: "", forceInput: true }] },
    },
    input_order: {
      required: [
        "image",
        "text_x",
        "text_y",
        "height",
        "font_size",
        "font_color",
        "label_color",
        "font",
        "text",
        "direction",
      ],
      optional: ["caption"],
    },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "AddLabel",
    display_name: "Add Label",
    description:
      "\nCreates a new with the given text, and concatenates it to\neither above or below the input image.\nNote that this changes the input image's height!\nFonts are loaded from this folder:\nComfyUI/custom_nodes/ComfyUI-KJNodes/fonts\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/text",
    output_node: false,
  },
  ColorMatch: {
    input: {
      required: {
        image_ref: ["IMAGE"],
        image_target: ["IMAGE"],
        method: [
          ["mkl", "hm", "reinhard", "mvgd", "hm-mvgd-hm", "hm-mkl-hm"],
          { default: "mkl" },
        ],
      },
      optional: {
        strength: ["FLOAT", { default: 1.0, min: 0.0, max: 10.0, step: 0.01 }],
      },
    },
    input_order: {
      required: ["image_ref", "image_target", "method"],
      optional: ["strength"],
    },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["image"],
    name: "ColorMatch",
    display_name: "Color Match",
    description:
      "\ncolor-matcher enables color transfer across images which comes in handy for automatic\ncolor-grading of photographs, paintings and film sequences as well as light-field\nand stopmotion corrections.\n\nThe methods behind the mappings are based on the approach from Reinhard et al.,\nthe Monge-Kantorovich Linearization (MKL) as proposed by Pitie et al. and our analytical solution\nto a Multi-Variate Gaussian Distribution (MVGD) transfer in conjunction with classical histogram \nmatching. As shown below our HM-MVGD-HM compound outperforms existing methods. \nhttps://github.com/hahnec/color-matcher/\n\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/image",
    output_node: false,
  },
  CrossFadeImages: {
    input: {
      required: {
        images_1: ["IMAGE"],
        images_2: ["IMAGE"],
        interpolation: [
          [
            "linear",
            "ease_in",
            "ease_out",
            "ease_in_out",
            "bounce",
            "elastic",
            "glitchy",
            "exponential_ease_out",
          ],
        ],
        transition_start_index: [
          "INT",
          { default: 1, min: 0, max: 4096, step: 1 },
        ],
        transitioning_frames: [
          "INT",
          { default: 1, min: 0, max: 4096, step: 1 },
        ],
        start_level: [
          "FLOAT",
          { default: 0.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        end_level: ["FLOAT", { default: 1.0, min: 0.0, max: 1.0, step: 0.01 }],
      },
    },
    input_order: {
      required: [
        "images_1",
        "images_2",
        "interpolation",
        "transition_start_index",
        "transitioning_frames",
        "start_level",
        "end_level",
      ],
    },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "CrossFadeImages",
    display_name: "Cross Fade Images",
    description: "",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/image",
    output_node: false,
  },
  GetImagesFromBatchIndexed: {
    input: {
      required: {
        images: ["IMAGE"],
        indexes: ["STRING", { default: "0, 1, 2", multiline: true }],
      },
    },
    input_order: { required: ["images", "indexes"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "GetImagesFromBatchIndexed",
    display_name: "Get Images From Batch Indexed",
    description:
      "\nSelects and returns the images at the specified indices as an image batch.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/image",
    output_node: false,
  },
  GetImageRangeFromBatch: {
    input: {
      required: {
        start_index: ["INT", { default: 0, min: -1, max: 4096, step: 1 }],
        num_frames: ["INT", { default: 1, min: 1, max: 4096, step: 1 }],
      },
      optional: { images: ["IMAGE"], masks: ["MASK"] },
    },
    input_order: {
      required: ["start_index", "num_frames"],
      optional: ["images", "masks"],
    },
    output: ["IMAGE", "MASK"],
    output_is_list: [false, false],
    output_name: ["IMAGE", "MASK"],
    name: "GetImageRangeFromBatch",
    display_name: "Get Image or Mask Range From Batch",
    description:
      "\nCreates a new batch using images from the input,\nbatch, starting from start_index.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/image",
    output_node: false,
  },
  GetImageSizeAndCount: {
    input: { required: { image: ["IMAGE"] } },
    input_order: { required: ["image"] },
    output: ["IMAGE", "INT", "INT", "INT"],
    output_is_list: [false, false, false, false],
    output_name: ["image", "width", "height", "count"],
    name: "GetImageSizeAndCount",
    display_name: "Get Image Size & Count",
    description:
      "\nReturns width, height and batch size of the image,\nand passes it through unchanged.\n\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/image",
    output_node: false,
  },
  ImageAndMaskPreview: {
    input: {
      required: {
        mask_opacity: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        mask_color: ["STRING", { default: "255, 255, 255" }],
        pass_through: ["BOOLEAN", { default: false }],
      },
      optional: { image: ["IMAGE"], mask: ["MASK"] },
      hidden: { prompt: "PROMPT", extra_pnginfo: "EXTRA_PNGINFO" },
    },
    input_order: {
      required: ["mask_opacity", "mask_color", "pass_through"],
      optional: ["image", "mask"],
      hidden: ["prompt", "extra_pnginfo"],
    },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["composite"],
    name: "ImageAndMaskPreview",
    display_name: "ImageAndMaskPreview",
    description:
      "\nPreview an image or a mask, when both inputs are used\ncomposites the mask on top of the image.\nwith pass_through on the preview is disabled and the\ncomposite is returned from the composite slot instead,\nthis allows for the preview to be passed for video combine\nnodes for example.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes",
    output_node: true,
  },
  ImageAddMulti: {
    input: {
      required: {
        inputcount: ["INT", { default: 2, min: 2, max: 1000, step: 1 }],
        image_1: ["IMAGE"],
        image_2: ["IMAGE"],
        blending: [
          ["add", "subtract", "multiply", "difference"],
          { default: "add" },
        ],
      },
    },
    input_order: { required: ["inputcount", "image_1", "image_2", "blending"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["images"],
    name: "ImageAddMulti",
    display_name: "Image Add Multi",
    description:
      "\nAdd blends multiple images together.\nYou can set how many inputs the node has,\nwith the **inputcount** and clicking update.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/image",
    output_node: false,
  },
  ImageBatchMulti: {
    input: {
      required: {
        inputcount: ["INT", { default: 2, min: 2, max: 1000, step: 1 }],
        image_1: ["IMAGE"],
        image_2: ["IMAGE"],
      },
    },
    input_order: { required: ["inputcount", "image_1", "image_2"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["images"],
    name: "ImageBatchMulti",
    display_name: "Image Batch Multi",
    description:
      "\nCreates an image batch from multiple images.\nYou can set how many inputs the node has,\nwith the **inputcount** and clicking update.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/image",
    output_node: false,
  },
  ImageBatchRepeatInterleaving: {
    input: {
      required: {
        images: ["IMAGE"],
        repeats: ["INT", { default: 1, min: 1, max: 4096 }],
      },
    },
    input_order: { required: ["images", "repeats"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "ImageBatchRepeatInterleaving",
    display_name: "ImageBatchRepeatInterleaving",
    description:
      "\nRepeats each image in a batch by the specified number of times.\nExample batch of 5 images: 0, 1 ,2, 3, 4\nwith repeats 2 becomes batch of 10 images: 0, 0, 1, 1, 2, 2, 3, 3, 4, 4\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/image",
    output_node: false,
  },
  ImageBatchTestPattern: {
    input: {
      required: {
        batch_size: ["INT", { default: 1, min: 1, max: 255, step: 1 }],
        start_from: ["INT", { default: 0, min: 0, max: 255, step: 1 }],
        text_x: ["INT", { default: 256, min: 0, max: 4096, step: 1 }],
        text_y: ["INT", { default: 256, min: 0, max: 4096, step: 1 }],
        width: ["INT", { default: 512, min: 16, max: 4096, step: 1 }],
        height: ["INT", { default: 512, min: 16, max: 4096, step: 1 }],
        font: [
          ["FreeMono.ttf", "FreeMonoBoldOblique.otf", "TTNorms-Black.otf"],
        ],
        font_size: ["INT", { default: 255, min: 8, max: 4096, step: 1 }],
      },
    },
    input_order: {
      required: [
        "batch_size",
        "start_from",
        "text_x",
        "text_y",
        "width",
        "height",
        "font",
        "font_size",
      ],
    },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "ImageBatchTestPattern",
    display_name: "Image Batch Test Pattern",
    description: "",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/text",
    output_node: false,
  },
  ImageConcanate: {
    input: {
      required: {
        image1: ["IMAGE"],
        image2: ["IMAGE"],
        direction: [["right", "down", "left", "up"], { default: "right" }],
        match_image_size: ["BOOLEAN", { default: false }],
      },
    },
    input_order: {
      required: ["image1", "image2", "direction", "match_image_size"],
    },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "ImageConcanate",
    display_name: "Image Concatenate",
    description:
      "\nConcatenates the image2 to image1 in the specified direction.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/image",
    output_node: false,
  },
  ImageConcatMulti: {
    input: {
      required: {
        inputcount: ["INT", { default: 2, min: 2, max: 1000, step: 1 }],
        image_1: ["IMAGE"],
        image_2: ["IMAGE"],
        direction: [["right", "down", "left", "up"], { default: "right" }],
        match_image_size: ["BOOLEAN", { default: false }],
      },
    },
    input_order: {
      required: [
        "inputcount",
        "image_1",
        "image_2",
        "direction",
        "match_image_size",
      ],
    },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["images"],
    name: "ImageConcatMulti",
    display_name: "Image Concatenate Multi",
    description:
      "\nCreates an image from multiple images.\nYou can set how many inputs the node has,\nwith the **inputcount** and clicking update.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/image",
    output_node: false,
  },
  ImageGrabPIL: {
    input: {
      required: {
        x: ["INT", { default: 0, min: 0, max: 4096, step: 1 }],
        y: ["INT", { default: 0, min: 0, max: 4096, step: 1 }],
        width: ["INT", { default: 512, min: 0, max: 4096, step: 1 }],
        height: ["INT", { default: 512, min: 0, max: 4096, step: 1 }],
        num_frames: ["INT", { default: 1, min: 1, max: 255, step: 1 }],
        delay: ["FLOAT", { default: 0.1, min: 0.0, max: 10.0, step: 0.01 }],
      },
    },
    input_order: {
      required: ["x", "y", "width", "height", "num_frames", "delay"],
    },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["image"],
    name: "ImageGrabPIL",
    display_name: "Image Grab PIL",
    description:
      "\nCaptures an area specified by screen coordinates.\nCan be used for realtime diffusion with autoqueue.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/experimental",
    output_node: false,
  },
  ImageGridComposite2x2: {
    input: {
      required: {
        image1: ["IMAGE"],
        image2: ["IMAGE"],
        image3: ["IMAGE"],
        image4: ["IMAGE"],
      },
    },
    input_order: { required: ["image1", "image2", "image3", "image4"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "ImageGridComposite2x2",
    display_name: "Image Grid Composite 2x2",
    description: "\nConcatenates the 4 input images into a 2x2 grid. \n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/image",
    output_node: false,
  },
  ImageGridComposite3x3: {
    input: {
      required: {
        image1: ["IMAGE"],
        image2: ["IMAGE"],
        image3: ["IMAGE"],
        image4: ["IMAGE"],
        image5: ["IMAGE"],
        image6: ["IMAGE"],
        image7: ["IMAGE"],
        image8: ["IMAGE"],
        image9: ["IMAGE"],
      },
    },
    input_order: {
      required: [
        "image1",
        "image2",
        "image3",
        "image4",
        "image5",
        "image6",
        "image7",
        "image8",
        "image9",
      ],
    },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "ImageGridComposite3x3",
    display_name: "Image Grid Composite 3x3",
    description: "\nConcatenates the 9 input images into a 3x3 grid. \n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/image",
    output_node: false,
  },
  ImageNormalize_Neg1_To_1: {
    input: { required: { images: ["IMAGE"] } },
    input_order: { required: ["images"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "ImageNormalize_Neg1_To_1",
    display_name: "Image Normalize -1 to 1",
    description: "\nNormalize the images to be in the range [-1, 1]\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/image",
    output_node: false,
  },
  ImagePass: {
    input: { required: {}, optional: { image: ["IMAGE"] } },
    input_order: { required: [], optional: ["image"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "ImagePass",
    display_name: "ImagePass",
    description: "\nPasses the image through without modifying it.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/image",
    output_node: false,
  },
  ImagePadForOutpaintMasked: {
    input: {
      required: {
        image: ["IMAGE"],
        left: ["INT", { default: 0, min: 0, max: 16384, step: 8 }],
        top: ["INT", { default: 0, min: 0, max: 16384, step: 8 }],
        right: ["INT", { default: 0, min: 0, max: 16384, step: 8 }],
        bottom: ["INT", { default: 0, min: 0, max: 16384, step: 8 }],
        feathering: ["INT", { default: 0, min: 0, max: 16384, step: 1 }],
      },
      optional: { mask: ["MASK"] },
    },
    input_order: {
      required: ["image", "left", "top", "right", "bottom", "feathering"],
      optional: ["mask"],
    },
    output: ["IMAGE", "MASK"],
    output_is_list: [false, false],
    output_name: ["IMAGE", "MASK"],
    name: "ImagePadForOutpaintMasked",
    display_name: "Image Pad For Outpaint Masked",
    description: "",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "image",
    output_node: false,
  },
  ImagePadForOutpaintTargetSize: {
    input: {
      required: {
        image: ["IMAGE"],
        target_width: ["INT", { default: 0, min: 0, max: 16384, step: 8 }],
        target_height: ["INT", { default: 0, min: 0, max: 16384, step: 8 }],
        feathering: ["INT", { default: 0, min: 0, max: 16384, step: 1 }],
        upscale_method: [
          ["nearest-exact", "bilinear", "area", "bicubic", "lanczos"],
        ],
      },
      optional: { mask: ["MASK"] },
    },
    input_order: {
      required: [
        "image",
        "target_width",
        "target_height",
        "feathering",
        "upscale_method",
      ],
      optional: ["mask"],
    },
    output: ["IMAGE", "MASK"],
    output_is_list: [false, false],
    output_name: ["IMAGE", "MASK"],
    name: "ImagePadForOutpaintTargetSize",
    display_name: "Image Pad For Outpaint Target Size",
    description: "",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "image",
    output_node: false,
  },
  ImageResizeKJ: {
    input: {
      required: {
        image: ["IMAGE"],
        width: ["INT", { default: 512, min: 0, max: 16384, step: 8 }],
        height: ["INT", { default: 512, min: 0, max: 16384, step: 8 }],
        upscale_method: [
          ["nearest-exact", "bilinear", "area", "bicubic", "lanczos"],
        ],
        keep_proportion: ["BOOLEAN", { default: false }],
        divisible_by: ["INT", { default: 2, min: 0, max: 512, step: 1 }],
      },
      optional: {
        width_input: ["INT", { forceInput: true }],
        height_input: ["INT", { forceInput: true }],
        get_image_size: ["IMAGE"],
        crop: [["disabled", "center"]],
      },
    },
    input_order: {
      required: [
        "image",
        "width",
        "height",
        "upscale_method",
        "keep_proportion",
        "divisible_by",
      ],
      optional: ["width_input", "height_input", "get_image_size", "crop"],
    },
    output: ["IMAGE", "INT", "INT"],
    output_is_list: [false, false, false],
    output_name: ["IMAGE", "width", "height"],
    name: "ImageResizeKJ",
    display_name: "Resize Image",
    description:
      "\nResizes the image to the specified width and height.\nSize can be retrieved from the inputs, and the final scale\nisdetermined in this order of importance:\n- get_image_size\n- width_input and height_input\n- width and height widgets\n\nKeep proportions keeps the aspect ratio of the image, by\nhighest dimension.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/image",
    output_node: false,
  },
  ImageUpscaleWithModelBatched: {
    input: {
      required: {
        upscale_model: ["UPSCALE_MODEL"],
        images: ["IMAGE"],
        per_batch: ["INT", { default: 16, min: 1, max: 4096, step: 1 }],
      },
    },
    input_order: { required: ["upscale_model", "images", "per_batch"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "ImageUpscaleWithModelBatched",
    display_name: "Image Upscale With Model Batched",
    description:
      "\nSame as ComfyUI native model upscaling node,\nbut allows setting sub-batches for reduced VRAM usage.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/image",
    output_node: false,
  },
  InsertImagesToBatchIndexed: {
    input: {
      required: {
        original_images: ["IMAGE"],
        images_to_insert: ["IMAGE"],
        indexes: ["STRING", { default: "0, 1, 2", multiline: true }],
      },
    },
    input_order: {
      required: ["original_images", "images_to_insert", "indexes"],
    },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "InsertImagesToBatchIndexed",
    display_name: "Insert Images To Batch Indexed",
    description:
      "\nInserts images at the specified indices into the original image batch.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/image",
    output_node: false,
  },
  LoadAndResizeImage: {
    input: {
      required: {
        image: [
          [
            "00000-2766569857.png",
            "00016-2678844265.png",
            "00017-749375916.png",
            "00051-493598238.png",
            "005.jpg",
            "010.jpg",
            "20240819_001358_873_SP-MangaEditor.png",
            "20240819_002252_983_SP-MangaEditor.png",
            "dark-skin.webp",
            "example.png",
            "p02.jpg",
            "police-station.webp",
            "tan-skin.webp",
          ],
          { image_upload: true },
        ],
        resize: ["BOOLEAN", { default: false }],
        width: ["INT", { default: 512, min: 0, max: 16384, step: 8 }],
        height: ["INT", { default: 512, min: 0, max: 16384, step: 8 }],
        repeat: ["INT", { default: 1, min: 1, max: 4096, step: 1 }],
        keep_proportion: ["BOOLEAN", { default: false }],
        divisible_by: ["INT", { default: 2, min: 0, max: 512, step: 1 }],
        mask_channel: [["alpha", "red", "green", "blue"]],
      },
    },
    input_order: {
      required: [
        "image",
        "resize",
        "width",
        "height",
        "repeat",
        "keep_proportion",
        "divisible_by",
        "mask_channel",
      ],
    },
    output: ["IMAGE", "MASK", "INT", "INT", "STRING"],
    output_is_list: [false, false, false, false, false],
    output_name: ["image", "mask", "width", "height", "image_path"],
    name: "LoadAndResizeImage",
    display_name: "Load & Resize Image",
    description: "",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/image",
    output_node: false,
  },
  LoadImagesFromFolderKJ: {
    input: {
      required: { folder: ["STRING", { default: "" }] },
      optional: {
        image_load_cap: ["INT", { default: 0, min: 0, step: 1 }],
        start_index: ["INT", { default: 0, min: 0, step: 1 }],
      },
    },
    input_order: {
      required: ["folder"],
      optional: ["image_load_cap", "start_index"],
    },
    output: ["IMAGE", "MASK", "INT", "STRING"],
    output_is_list: [false, false, false, false],
    output_name: ["image", "mask", "count", "image_path"],
    name: "LoadImagesFromFolderKJ",
    display_name: "Load Images From Folder (KJ)",
    description: "",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "image",
    output_node: false,
  },
  MergeImageChannels: {
    input: {
      required: { red: ["IMAGE"], green: ["IMAGE"], blue: ["IMAGE"] },
      optional: { alpha: ["MASK", { default: null }] },
    },
    input_order: { required: ["red", "green", "blue"], optional: ["alpha"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["image"],
    name: "MergeImageChannels",
    display_name: "Merge Image Channels",
    description: "\nMerges channel data into an image.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/image",
    output_node: false,
  },
  PreviewAnimation: {
    input: {
      required: {
        fps: ["FLOAT", { default: 8.0, min: 0.01, max: 1000.0, step: 0.01 }],
      },
      optional: { images: ["IMAGE"], masks: ["MASK"] },
    },
    input_order: { required: ["fps"], optional: ["images", "masks"] },
    output: [],
    output_is_list: [],
    output_name: [],
    name: "PreviewAnimation",
    display_name: "Preview Animation",
    description: "",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/image",
    output_node: true,
  },
  RemapImageRange: {
    input: {
      required: {
        image: ["IMAGE"],
        min: ["FLOAT", { default: 0.0, min: -10.0, max: 1.0, step: 0.01 }],
        max: ["FLOAT", { default: 1.0, min: 0.0, max: 10.0, step: 0.01 }],
        clamp: ["BOOLEAN", { default: true }],
      },
    },
    input_order: { required: ["image", "min", "max", "clamp"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "RemapImageRange",
    display_name: "Remap Image Range",
    description: "\nRemaps the image values to the specified range. \n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/image",
    output_node: false,
  },
  ReverseImageBatch: {
    input: { required: { images: ["IMAGE"] } },
    input_order: { required: ["images"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "ReverseImageBatch",
    display_name: "Reverse Image Batch",
    description: "\nReverses the order of the images in a batch.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/image",
    output_node: false,
  },
  ReplaceImagesInBatch: {
    input: {
      required: {
        original_images: ["IMAGE"],
        replacement_images: ["IMAGE"],
        start_index: ["INT", { default: 1, min: 0, max: 4096, step: 1 }],
      },
    },
    input_order: {
      required: ["original_images", "replacement_images", "start_index"],
    },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "ReplaceImagesInBatch",
    display_name: "Replace Images In Batch",
    description:
      "\nReplaces the images in a batch, starting from the specified start index,\nwith the replacement images.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/image",
    output_node: false,
  },
  SaveImageWithAlpha: {
    input: {
      required: {
        images: ["IMAGE"],
        mask: ["MASK"],
        filename_prefix: ["STRING", { default: "ComfyUI" }],
      },
      hidden: { prompt: "PROMPT", extra_pnginfo: "EXTRA_PNGINFO" },
    },
    input_order: {
      required: ["images", "mask", "filename_prefix"],
      hidden: ["prompt", "extra_pnginfo"],
    },
    output: [],
    output_is_list: [],
    output_name: [],
    name: "SaveImageWithAlpha",
    display_name: "Save Image With Alpha",
    description:
      "\nSaves an image and mask as .PNG with the mask as the alpha channel. \n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/image",
    output_node: true,
  },
  SplitImageChannels: {
    input: { required: { image: ["IMAGE"] } },
    input_order: { required: ["image"] },
    output: ["IMAGE", "IMAGE", "IMAGE", "MASK"],
    output_is_list: [false, false, false, false],
    output_name: ["red", "green", "blue", "mask"],
    name: "SplitImageChannels",
    display_name: "Split Image Channels",
    description:
      "\nSplits image channels into images where the selected channel\nis repeated for all channels, and the alpha as a mask. \n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/image",
    output_node: false,
  },
  BatchCropFromMask: {
    input: {
      required: {
        original_images: ["IMAGE"],
        masks: ["MASK"],
        crop_size_mult: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 10.0, step: 0.001 },
        ],
        bbox_smooth_alpha: [
          "FLOAT",
          { default: 0.5, min: 0.0, max: 1.0, step: 0.01 },
        ],
      },
    },
    input_order: {
      required: [
        "original_images",
        "masks",
        "crop_size_mult",
        "bbox_smooth_alpha",
      ],
    },
    output: ["IMAGE", "IMAGE", "BBOX", "INT", "INT"],
    output_is_list: [false, false, false, false, false],
    output_name: [
      "original_images",
      "cropped_images",
      "bboxes",
      "width",
      "height",
    ],
    name: "BatchCropFromMask",
    display_name: "Batch Crop From Mask",
    description: "",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking",
    output_node: false,
  },
  BatchCropFromMaskAdvanced: {
    input: {
      required: {
        original_images: ["IMAGE"],
        masks: ["MASK"],
        crop_size_mult: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 10.0, step: 0.01 },
        ],
        bbox_smooth_alpha: [
          "FLOAT",
          { default: 0.5, min: 0.0, max: 1.0, step: 0.01 },
        ],
      },
    },
    input_order: {
      required: [
        "original_images",
        "masks",
        "crop_size_mult",
        "bbox_smooth_alpha",
      ],
    },
    output: [
      "IMAGE",
      "IMAGE",
      "MASK",
      "IMAGE",
      "MASK",
      "BBOX",
      "BBOX",
      "INT",
      "INT",
    ],
    output_is_list: [
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
    ],
    output_name: [
      "original_images",
      "cropped_images",
      "cropped_masks",
      "combined_crop_image",
      "combined_crop_masks",
      "bboxes",
      "combined_bounding_box",
      "bbox_width",
      "bbox_height",
    ],
    name: "BatchCropFromMaskAdvanced",
    display_name: "Batch Crop From Mask Advanced",
    description: "",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking",
    output_node: false,
  },
  FilterZeroMasksAndCorrespondingImages: {
    input: {
      required: { masks: ["MASK"] },
      optional: { original_images: ["IMAGE"] },
    },
    input_order: { required: ["masks"], optional: ["original_images"] },
    output: ["MASK", "IMAGE", "IMAGE", "INDEXES"],
    output_is_list: [false, false, false, false],
    output_name: [
      "non_zero_masks_out",
      "non_zero_mask_images_out",
      "zero_mask_images_out",
      "zero_mask_images_out_indexes",
    ],
    name: "FilterZeroMasksAndCorrespondingImages",
    display_name: "FilterZeroMasksAndCorrespondingImages",
    description:
      "\nFilter out all the empty (i.e. all zero) mask in masks\nAlso filter out all the corresponding images in original_images by indexes if provide\n\noriginal_images (optional): If provided, need have same length as masks.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking",
    output_node: false,
  },
  InsertImageBatchByIndexes: {
    input: {
      required: {
        images: ["IMAGE"],
        images_to_insert: ["IMAGE"],
        insert_indexes: ["INDEXES"],
      },
    },
    input_order: { required: ["images", "images_to_insert", "insert_indexes"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["images_after_insert"],
    name: "InsertImageBatchByIndexes",
    display_name: "Insert Image Batch By Indexes",
    description:
      "\nThis node is designed to be use with node FilterZeroMasksAndCorrespondingImages\nIt inserts the images_to_insert into images according to insert_indexes\n\nReturns:\nimages_after_insert: updated original images with origonal sequence order\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/image",
    output_node: false,
  },
  BatchUncrop: {
    input: {
      required: {
        original_images: ["IMAGE"],
        cropped_images: ["IMAGE"],
        bboxes: ["BBOX"],
        border_blending: [
          "FLOAT",
          { default: 0.25, min: 0.0, max: 1.0, step: 0.01 },
        ],
        crop_rescale: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 10.0, step: 0.01 },
        ],
        border_top: ["BOOLEAN", { default: true }],
        border_bottom: ["BOOLEAN", { default: true }],
        border_left: ["BOOLEAN", { default: true }],
        border_right: ["BOOLEAN", { default: true }],
      },
    },
    input_order: {
      required: [
        "original_images",
        "cropped_images",
        "bboxes",
        "border_blending",
        "crop_rescale",
        "border_top",
        "border_bottom",
        "border_left",
        "border_right",
      ],
    },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "BatchUncrop",
    display_name: "Batch Uncrop",
    description: "",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking",
    output_node: false,
  },
  BatchUncropAdvanced: {
    input: {
      required: {
        original_images: ["IMAGE"],
        cropped_images: ["IMAGE"],
        cropped_masks: ["MASK"],
        combined_crop_mask: ["MASK"],
        bboxes: ["BBOX"],
        border_blending: [
          "FLOAT",
          { default: 0.25, min: 0.0, max: 1.0, step: 0.01 },
        ],
        crop_rescale: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 10.0, step: 0.01 },
        ],
        use_combined_mask: ["BOOLEAN", { default: false }],
        use_square_mask: ["BOOLEAN", { default: true }],
      },
      optional: { combined_bounding_box: ["BBOX", { default: null }] },
    },
    input_order: {
      required: [
        "original_images",
        "cropped_images",
        "cropped_masks",
        "combined_crop_mask",
        "bboxes",
        "border_blending",
        "crop_rescale",
        "use_combined_mask",
        "use_square_mask",
      ],
      optional: ["combined_bounding_box"],
    },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "BatchUncropAdvanced",
    display_name: "Batch Uncrop Advanced",
    description: "",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking",
    output_node: false,
  },
  SplitBboxes: {
    input: {
      required: {
        bboxes: ["BBOX"],
        index: ["INT", { default: 0, min: 0, max: 99999999, step: 1 }],
      },
    },
    input_order: { required: ["bboxes", "index"] },
    output: ["BBOX", "BBOX"],
    output_is_list: [false, false],
    output_name: ["bboxes_a", "bboxes_b"],
    name: "SplitBboxes",
    display_name: "Split Bboxes",
    description:
      "\nSplits the specified bbox list at the given index into two lists.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking",
    output_node: false,
  },
  BboxToInt: {
    input: {
      required: {
        bboxes: ["BBOX"],
        index: ["INT", { default: 0, min: 0, max: 99999999, step: 1 }],
      },
    },
    input_order: { required: ["bboxes", "index"] },
    output: ["INT", "INT", "INT", "INT", "INT", "INT"],
    output_is_list: [false, false, false, false, false, false],
    output_name: ["x_min", "y_min", "width", "height", "center_x", "center_y"],
    name: "BboxToInt",
    display_name: "Bbox To Int",
    description:
      "\nReturns selected index from bounding box list as integers.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking",
    output_node: false,
  },
  BboxVisualize: {
    input: {
      required: {
        images: ["IMAGE"],
        bboxes: ["BBOX"],
        line_width: ["INT", { default: 1, min: 1, max: 10, step: 1 }],
      },
    },
    input_order: { required: ["images", "bboxes", "line_width"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["images"],
    name: "BboxVisualize",
    display_name: "Bbox Visualize",
    description: "\nVisualizes the specified bbox on the image.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking",
    output_node: false,
  },
  GenerateNoise: {
    input: {
      required: {
        width: ["INT", { default: 512, min: 16, max: 4096, step: 1 }],
        height: ["INT", { default: 512, min: 16, max: 4096, step: 1 }],
        batch_size: ["INT", { default: 1, min: 1, max: 4096 }],
        seed: [
          "INT",
          { default: 123, min: 0, max: 18446744073709551615, step: 1 },
        ],
        multiplier: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 4096, step: 0.01 },
        ],
        constant_batch_noise: ["BOOLEAN", { default: false }],
        normalize: ["BOOLEAN", { default: false }],
      },
      optional: {
        model: ["MODEL"],
        sigmas: ["SIGMAS"],
        latent_channels: [["4", "16"]],
      },
    },
    input_order: {
      required: [
        "width",
        "height",
        "batch_size",
        "seed",
        "multiplier",
        "constant_batch_noise",
        "normalize",
      ],
      optional: ["model", "sigmas", "latent_channels"],
    },
    output: ["LATENT"],
    output_is_list: [false],
    output_name: ["LATENT"],
    name: "GenerateNoise",
    display_name: "Generate Noise",
    description:
      "\nGenerates noise for injection or to be used as empty latents on samplers with add_noise off.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/noise",
    output_node: false,
  },
  FlipSigmasAdjusted: {
    input: {
      required: {
        sigmas: ["SIGMAS"],
        divide_by_last_sigma: ["BOOLEAN", { default: false }],
        divide_by: ["FLOAT", { default: 1, min: 1, max: 255, step: 0.01 }],
        offset_by: ["INT", { default: 1, min: -100, max: 100, step: 1 }],
      },
    },
    input_order: {
      required: ["sigmas", "divide_by_last_sigma", "divide_by", "offset_by"],
    },
    output: ["SIGMAS", "STRING"],
    output_is_list: [false, false],
    output_name: ["SIGMAS", "sigmas_string"],
    name: "FlipSigmasAdjusted",
    display_name: "Flip Sigmas Adjusted",
    description: "",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/noise",
    output_node: false,
  },
  InjectNoiseToLatent: {
    input: {
      required: {
        latents: ["LATENT"],
        strength: [
          "FLOAT",
          { default: 0.1, min: 0.0, max: 200.0, step: 0.0001 },
        ],
        noise: ["LATENT"],
        normalize: ["BOOLEAN", { default: false }],
        average: ["BOOLEAN", { default: false }],
      },
      optional: {
        mask: ["MASK"],
        mix_randn_amount: [
          "FLOAT",
          { default: 0.0, min: 0.0, max: 1000.0, step: 0.001 },
        ],
        seed: [
          "INT",
          { default: 123, min: 0, max: 18446744073709551615, step: 1 },
        ],
      },
    },
    input_order: {
      required: ["latents", "strength", "noise", "normalize", "average"],
      optional: ["mask", "mix_randn_amount", "seed"],
    },
    output: ["LATENT"],
    output_is_list: [false],
    output_name: ["LATENT"],
    name: "InjectNoiseToLatent",
    display_name: "Inject Noise To Latent",
    description: "",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/noise",
    output_node: false,
  },
  CustomSigmas: {
    input: {
      required: {
        sigmas_string: [
          "STRING",
          {
            default:
              "14.615, 6.475, 3.861, 2.697, 1.886, 1.396, 0.963, 0.652, 0.399, 0.152, 0.029",
            multiline: true,
          },
        ],
        interpolate_to_steps: [
          "INT",
          { default: 10, min: 0, max: 255, step: 1 },
        ],
      },
    },
    input_order: { required: ["sigmas_string", "interpolate_to_steps"] },
    output: ["SIGMAS"],
    output_is_list: [false],
    output_name: ["SIGMAS"],
    name: "CustomSigmas",
    display_name: "Custom Sigmas",
    description:
      "\nCreates a sigmas tensor from a string of comma separated values.\nExamples: \n \nNvidia's optimized AYS 10 step schedule for SD 1.5:\n14.615, 6.475, 3.861, 2.697, 1.886, 1.396, 0.963, 0.652, 0.399, 0.152, 0.029\nSDXL: \n14.615, 6.315, 3.771, 2.181, 1.342, 0.862, 0.555, 0.380, 0.234, 0.113, 0.029\nSVD:\n700.00, 54.5, 15.886, 7.977, 4.248, 1.789, 0.981, 0.403, 0.173, 0.034, 0.002\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/noise",
    output_node: false,
  },
  WidgetToString: {
    input: {
      required: {
        id: ["INT", { default: 0 }],
        widget_name: ["STRING", { multiline: false }],
        return_all: ["BOOLEAN", { default: false }],
      },
      optional: {
        any_input: ["*", {}],
        node_title: ["STRING", { multiline: false }],
      },
      hidden: {
        extra_pnginfo: "EXTRA_PNGINFO",
        prompt: "PROMPT",
        unique_id: "UNIQUE_ID",
      },
    },
    input_order: {
      required: ["id", "widget_name", "return_all"],
      optional: ["any_input", "node_title"],
      hidden: ["extra_pnginfo", "prompt", "unique_id"],
    },
    output: ["STRING"],
    output_is_list: [false],
    output_name: ["STRING"],
    name: "WidgetToString",
    display_name: "Widget To String",
    description:
      "\nSelects a node and it's specified widget and outputs the value as a string.\nIf no node id or title is provided it will use the 'any_input' link and use that node.\nTo see node id's, enable node id display from Manager badge menu.\nAlternatively you can search with the node title. Node titles ONLY exist if they\nare manually edited!\nThe 'any_input' is required for making sure the node you want the value from exists in the workflow.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/text",
    output_node: false,
  },
  DummyOut: {
    input: { required: { any_input: ["*", {}] } },
    input_order: { required: ["any_input"] },
    output: ["*"],
    output_is_list: [false],
    output_name: ["*"],
    name: "DummyOut",
    display_name: "Dummy Out",
    description:
      "\nDoes nothing, used to trigger generic workflow output.\nA way to get previews in the UI without saving anything to disk.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/misc",
    output_node: true,
  },
  GetLatentsFromBatchIndexed: {
    input: {
      required: {
        latents: ["LATENT"],
        indexes: ["STRING", { default: "0, 1, 2", multiline: true }],
      },
    },
    input_order: { required: ["latents", "indexes"] },
    output: ["LATENT"],
    output_is_list: [false],
    output_name: ["LATENT"],
    name: "GetLatentsFromBatchIndexed",
    display_name: "Get Latents From Batch Indexed",
    description:
      "\nSelects and returns the latents at the specified indices as an latent batch.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes",
    output_node: false,
  },
  ScaleBatchPromptSchedule: {
    input: {
      required: {
        input_str: [
          "STRING",
          { forceInput: true, default: "0:(0.0),\n7:(1.0),\n15:(0.0)\n" },
        ],
        old_frame_count: [
          "INT",
          { forceInput: true, default: 1, min: 1, max: 4096, step: 1 },
        ],
        new_frame_count: [
          "INT",
          { forceInput: true, default: 1, min: 1, max: 4096, step: 1 },
        ],
      },
    },
    input_order: {
      required: ["input_str", "old_frame_count", "new_frame_count"],
    },
    output: ["STRING"],
    output_is_list: [false],
    output_name: ["STRING"],
    name: "ScaleBatchPromptSchedule",
    display_name: "Scale Batch Prompt Schedule",
    description:
      "\nScales a batch schedule from Fizz' nodes BatchPromptSchedule\nto a different frame count.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes",
    output_node: false,
  },
  CameraPoseVisualizer: {
    input: {
      required: {
        pose_file_path: ["STRING", { default: "", multiline: false }],
        base_xval: ["FLOAT", { default: 0.2, min: 0, max: 100, step: 0.01 }],
        zval: ["FLOAT", { default: 0.3, min: 0, max: 100, step: 0.01 }],
        scale: ["FLOAT", { default: 1.0, min: 0.01, max: 10.0, step: 0.01 }],
        use_exact_fx: ["BOOLEAN", { default: false }],
        relative_c2w: ["BOOLEAN", { default: true }],
        use_viewer: ["BOOLEAN", { default: false }],
      },
      optional: { cameractrl_poses: ["CAMERACTRL_POSES", { default: null }] },
    },
    input_order: {
      required: [
        "pose_file_path",
        "base_xval",
        "zval",
        "scale",
        "use_exact_fx",
        "relative_c2w",
        "use_viewer",
      ],
      optional: ["cameractrl_poses"],
    },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "CameraPoseVisualizer",
    display_name: "Camera Pose Visualizer",
    description:
      "\nVisualizes the camera poses, from Animatediff-Evolved CameraCtrl Pose\nor a .txt file with RealEstate camera intrinsics and coordinates, in a 3D plot. \n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/misc",
    output_node: false,
  },
  JoinStrings: {
    input: {
      required: {
        string1: ["STRING", { default: "", forceInput: true }],
        string2: ["STRING", { default: "", forceInput: true }],
        delimiter: ["STRING", { default: " ", multiline: false }],
      },
    },
    input_order: { required: ["string1", "string2", "delimiter"] },
    output: ["STRING"],
    output_is_list: [false],
    output_name: ["STRING"],
    name: "JoinStrings",
    display_name: "Join Strings",
    description: "",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/constants",
    output_node: false,
  },
  JoinStringMulti: {
    input: {
      required: {
        inputcount: ["INT", { default: 2, min: 2, max: 1000, step: 1 }],
        string_1: ["STRING", { default: "", forceInput: true }],
        string_2: ["STRING", { default: "", forceInput: true }],
        delimiter: ["STRING", { default: " ", multiline: false }],
        return_list: ["BOOLEAN", { default: false }],
      },
    },
    input_order: {
      required: [
        "inputcount",
        "string_1",
        "string_2",
        "delimiter",
        "return_list",
      ],
    },
    output: ["STRING"],
    output_is_list: [false],
    output_name: ["string"],
    name: "JoinStringMulti",
    display_name: "Join String Multi",
    description:
      "\nCreates single string, or a list of strings, from\nmultiple input strings.\nYou can set how many inputs the node has,\nwith the **inputcount** and clicking update.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes",
    output_node: false,
  },
  SomethingToString: {
    input: {
      required: { input: ["*", {}] },
      optional: {
        prefix: ["STRING", { default: "" }],
        suffix: ["STRING", { default: "" }],
      },
    },
    input_order: { required: ["input"], optional: ["prefix", "suffix"] },
    output: ["STRING"],
    output_is_list: [false],
    output_name: ["STRING"],
    name: "SomethingToString",
    display_name: "Something To String",
    description: "\nConverts any type to a string.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/text",
    output_node: false,
  },
  Sleep: {
    input: {
      required: {
        input: ["*", {}],
        minutes: ["INT", { default: 0, min: 0, max: 1439 }],
        seconds: ["FLOAT", { default: 0.0, min: 0.0, max: 59.99, step: 0.01 }],
      },
    },
    input_order: { required: ["input", "minutes", "seconds"] },
    output: ["*"],
    output_is_list: [false],
    output_name: ["*"],
    name: "Sleep",
    display_name: "Sleep",
    description: "\nDelays the execution for the input amount of time.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/misc",
    output_node: false,
  },
  VRAM_Debug: {
    input: {
      required: {
        empty_cache: ["BOOLEAN", { default: true }],
        gc_collect: ["BOOLEAN", { default: true }],
        unload_all_models: ["BOOLEAN", { default: false }],
      },
      optional: {
        any_input: ["*", {}],
        image_pass: ["IMAGE"],
        model_pass: ["MODEL"],
      },
    },
    input_order: {
      required: ["empty_cache", "gc_collect", "unload_all_models"],
      optional: ["any_input", "image_pass", "model_pass"],
    },
    output: ["*", "IMAGE", "MODEL", "INT", "INT"],
    output_is_list: [false, false, false, false, false],
    output_name: [
      "any_output",
      "image_pass",
      "model_pass",
      "freemem_before",
      "freemem_after",
    ],
    name: "VRAM_Debug",
    display_name: "VRAM Debug",
    description:
      "\nReturns the inputs unchanged, they are only used as triggers,\nand performs comfy model management functions and garbage collection,\nreports free VRAM before and after the operations.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/misc",
    output_node: false,
  },
  EmptyLatentImagePresets: {
    input: {
      required: {
        dimensions: [
          [
            "512 x 512",
            "768 x 512",
            "960 x 512",
            "1024 x 512",
            "1536 x 640",
            "1344 x 768",
            "1216 x 832",
            "1152 x 896",
            "1024 x 1024",
          ],
          { default: "512 x 512" },
        ],
        invert: ["BOOLEAN", { default: false }],
        batch_size: ["INT", { default: 1, min: 1, max: 4096 }],
      },
    },
    input_order: { required: ["dimensions", "invert", "batch_size"] },
    output: ["LATENT", "INT", "INT"],
    output_is_list: [false, false, false],
    output_name: ["Latent", "Width", "Height"],
    name: "EmptyLatentImagePresets",
    display_name: "Empty Latent Image Presets",
    description: "",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes",
    output_node: false,
  },
  ModelPassThrough: {
    input: { required: {}, optional: { model: ["MODEL"] } },
    input_order: { required: [], optional: ["model"] },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["model"],
    name: "ModelPassThrough",
    display_name: "ModelPass",
    description:
      "\nSimply passes through the model,\nworkaround for Set node not allowing bypassed inputs.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/misc",
    output_node: false,
  },
  NormalizedAmplitudeToMask: {
    input: {
      required: {
        normalized_amp: ["NORMALIZED_AMPLITUDE"],
        width: ["INT", { default: 512, min: 16, max: 4096, step: 1 }],
        height: ["INT", { default: 512, min: 16, max: 4096, step: 1 }],
        frame_offset: ["INT", { default: 0, min: -255, max: 255, step: 1 }],
        location_x: ["INT", { default: 256, min: 0, max: 4096, step: 1 }],
        location_y: ["INT", { default: 256, min: 0, max: 4096, step: 1 }],
        size: ["INT", { default: 128, min: 8, max: 4096, step: 1 }],
        shape: [["none", "circle", "square", "triangle"], { default: "none" }],
        color: [["white", "amplitude"], { default: "amplitude" }],
      },
    },
    input_order: {
      required: [
        "normalized_amp",
        "width",
        "height",
        "frame_offset",
        "location_x",
        "location_y",
        "size",
        "shape",
        "color",
      ],
    },
    output: ["MASK"],
    output_is_list: [false],
    output_name: ["MASK"],
    name: "NormalizedAmplitudeToMask",
    display_name: "NormalizedAmplitudeToMask",
    description:
      "\nWorks as a bridge to the AudioScheduler -nodes:\nhttps://github.com/a1lazydog/ComfyUI-AudioScheduler\nCreates masks based on the normalized amplitude.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/audio",
    output_node: false,
  },
  NormalizedAmplitudeToFloatList: {
    input: { required: { normalized_amp: ["NORMALIZED_AMPLITUDE"] } },
    input_order: { required: ["normalized_amp"] },
    output: ["FLOAT"],
    output_is_list: [false],
    output_name: ["FLOAT"],
    name: "NormalizedAmplitudeToFloatList",
    display_name: "NormalizedAmplitudeToFloatList",
    description:
      "\nWorks as a bridge to the AudioScheduler -nodes:\nhttps://github.com/a1lazydog/ComfyUI-AudioScheduler\nCreates a list of floats from the normalized amplitude.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/audio",
    output_node: false,
  },
  OffsetMaskByNormalizedAmplitude: {
    input: {
      required: {
        normalized_amp: ["NORMALIZED_AMPLITUDE"],
        mask: ["MASK"],
        x: [
          "INT",
          { default: 0, min: -4096, max: 16384, step: 1, display: "number" },
        ],
        y: [
          "INT",
          { default: 0, min: -4096, max: 16384, step: 1, display: "number" },
        ],
        rotate: ["BOOLEAN", { default: false }],
        angle_multiplier: [
          "FLOAT",
          { default: 0.0, min: -1.0, max: 1.0, step: 0.001, display: "number" },
        ],
      },
    },
    input_order: {
      required: [
        "normalized_amp",
        "mask",
        "x",
        "y",
        "rotate",
        "angle_multiplier",
      ],
    },
    output: ["MASK"],
    output_is_list: [false],
    output_name: ["mask"],
    name: "OffsetMaskByNormalizedAmplitude",
    display_name: "OffsetMaskByNormalizedAmplitude",
    description:
      "\nWorks as a bridge to the AudioScheduler -nodes:\nhttps://github.com/a1lazydog/ComfyUI-AudioScheduler\nOffsets masks based on the normalized amplitude.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/audio",
    output_node: false,
  },
  ImageTransformByNormalizedAmplitude: {
    input: {
      required: {
        normalized_amp: ["NORMALIZED_AMPLITUDE"],
        zoom_scale: [
          "FLOAT",
          { default: 0.0, min: -1.0, max: 1.0, step: 0.001, display: "number" },
        ],
        x_offset: [
          "INT",
          { default: 0, min: -16383, max: 16384, step: 1, display: "number" },
        ],
        y_offset: [
          "INT",
          { default: 0, min: -16383, max: 16384, step: 1, display: "number" },
        ],
        cumulative: ["BOOLEAN", { default: false }],
        image: ["IMAGE"],
      },
    },
    input_order: {
      required: [
        "normalized_amp",
        "zoom_scale",
        "x_offset",
        "y_offset",
        "cumulative",
        "image",
      ],
    },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "ImageTransformByNormalizedAmplitude",
    display_name: "ImageTransformByNormalizedAmplitude",
    description:
      "\nWorks as a bridge to the AudioScheduler -nodes:\nhttps://github.com/a1lazydog/ComfyUI-AudioScheduler\nTransforms image based on the normalized amplitude.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/audio",
    output_node: false,
  },
  SplineEditor: {
    input: {
      required: {
        points_store: ["STRING", { multiline: false }],
        coordinates: ["STRING", { multiline: false }],
        mask_width: ["INT", { default: 512, min: 8, max: 4096, step: 8 }],
        mask_height: ["INT", { default: 512, min: 8, max: 4096, step: 8 }],
        points_to_sample: ["INT", { default: 16, min: 2, max: 1000, step: 1 }],
        sampling_method: [
          ["path", "time", "controlpoints"],
          { default: "time" },
        ],
        interpolation: [
          [
            "cardinal",
            "monotone",
            "basis",
            "linear",
            "step-before",
            "step-after",
            "polar",
            "polar-reverse",
          ],
          { default: "cardinal" },
        ],
        tension: ["FLOAT", { default: 0.5, min: 0.0, max: 1.0, step: 0.01 }],
        repeat_output: ["INT", { default: 1, min: 1, max: 4096, step: 1 }],
        float_output_type: [
          ["list", "pandas series", "tensor"],
          { default: "list" },
        ],
      },
      optional: {
        min_value: [
          "FLOAT",
          { default: 0.0, min: -10000.0, max: 10000.0, step: 0.01 },
        ],
        max_value: [
          "FLOAT",
          { default: 1.0, min: -10000.0, max: 10000.0, step: 0.01 },
        ],
      },
    },
    input_order: {
      required: [
        "points_store",
        "coordinates",
        "mask_width",
        "mask_height",
        "points_to_sample",
        "sampling_method",
        "interpolation",
        "tension",
        "repeat_output",
        "float_output_type",
      ],
      optional: ["min_value", "max_value"],
    },
    output: ["MASK", "STRING", "FLOAT", "INT", "STRING"],
    output_is_list: [false, false, false, false, false],
    output_name: ["mask", "coord_str", "float", "count", "normalized_str"],
    name: "SplineEditor",
    display_name: "Spline Editor",
    description:
      "\n# WORK IN PROGRESS\nDo not count on this as part of your workflow yet,\nprobably contains lots of bugs and stability is not\nguaranteed!!\n\n## Graphical editor to create values for various \n## schedules and/or mask batches.\n\n**Shift + click** to add control point at end.\n**Ctrl + click** to add control point (subdivide) between two points.\n**Right click on a point** to delete it.\nNote that you can't delete from start/end.\n\nRight click on canvas for context menu:\nThese are purely visual options, doesn't affect the output:\n - Toggle handles visibility\n - Display sample points: display the points to be returned.\n\n**points_to_sample** value sets the number of samples\nreturned from the **drawn spline itself**, this is independent from the\nactual control points, so the interpolation type matters.\nsampling_method: \n - time: samples along the time axis, used for schedules\n - path: samples along the path itself, useful for coordinates\n\noutput types:\n - mask batch\nexample compatible nodes: anything that takes masks\n - list of floats\nexample compatible nodes: IPAdapter weights\n - pandas series\nexample compatible nodes: anything that takes Fizz'\nnodes Batch Value Schedule\n - torch tensor\nexample compatible nodes: unknown\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/weights",
    output_node: false,
  },
  CreateShapeImageOnPath: {
    input: {
      required: {
        shape: [["circle", "square", "triangle"], { default: "circle" }],
        coordinates: ["STRING", { forceInput: true }],
        frame_width: ["INT", { default: 512, min: 16, max: 4096, step: 1 }],
        frame_height: ["INT", { default: 512, min: 16, max: 4096, step: 1 }],
        shape_width: ["INT", { default: 128, min: 8, max: 4096, step: 1 }],
        shape_height: ["INT", { default: 128, min: 8, max: 4096, step: 1 }],
        shape_color: ["STRING", { default: "white" }],
        bg_color: ["STRING", { default: "black" }],
        blur_radius: ["FLOAT", { default: 0.0, min: 0.0, max: 100, step: 0.1 }],
        intensity: [
          "FLOAT",
          { default: 1.0, min: 0.01, max: 100.0, step: 0.01 },
        ],
      },
      optional: {
        size_multiplier: ["FLOAT", { default: [1.0], forceInput: true }],
      },
    },
    input_order: {
      required: [
        "shape",
        "coordinates",
        "frame_width",
        "frame_height",
        "shape_width",
        "shape_height",
        "shape_color",
        "bg_color",
        "blur_radius",
        "intensity",
      ],
      optional: ["size_multiplier"],
    },
    output: ["IMAGE", "MASK"],
    output_is_list: [false, false],
    output_name: ["image", "mask"],
    name: "CreateShapeImageOnPath",
    display_name: "Create Shape Image On Path",
    description:
      "\nCreates an image or batch of images with the specified shape.\nLocations are center locations.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/image",
    output_node: false,
  },
  CreateShapeMaskOnPath: {
    input: {
      required: {
        shape: [["circle", "square", "triangle"], { default: "circle" }],
        coordinates: ["STRING", { forceInput: true }],
        frame_width: ["INT", { default: 512, min: 16, max: 4096, step: 1 }],
        frame_height: ["INT", { default: 512, min: 16, max: 4096, step: 1 }],
        shape_width: ["INT", { default: 128, min: 8, max: 4096, step: 1 }],
        shape_height: ["INT", { default: 128, min: 8, max: 4096, step: 1 }],
      },
      optional: {
        size_multiplier: ["FLOAT", { default: [1.0], forceInput: true }],
      },
    },
    input_order: {
      required: [
        "shape",
        "coordinates",
        "frame_width",
        "frame_height",
        "shape_width",
        "shape_height",
      ],
      optional: ["size_multiplier"],
    },
    output: ["MASK", "MASK"],
    output_is_list: [false, false],
    output_name: ["mask", "mask_inverted"],
    name: "CreateShapeMaskOnPath",
    display_name: "Create Shape Mask On Path",
    description:
      "\nCreates a mask or batch of masks with the specified shape.\nLocations are center locations.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking/generate",
    output_node: false,
  },
  CreateTextOnPath: {
    input: {
      required: {
        coordinates: ["STRING", { forceInput: true }],
        text: ["STRING", { default: "text", multiline: true }],
        frame_width: ["INT", { default: 512, min: 16, max: 4096, step: 1 }],
        frame_height: ["INT", { default: 512, min: 16, max: 4096, step: 1 }],
        font: [
          ["FreeMono.ttf", "FreeMonoBoldOblique.otf", "TTNorms-Black.otf"],
        ],
        font_size: ["INT", { default: 42 }],
        alignment: [["left", "center", "right"], { default: "center" }],
        text_color: ["STRING", { default: "white" }],
      },
      optional: {
        size_multiplier: ["FLOAT", { default: [1.0], forceInput: true }],
      },
    },
    input_order: {
      required: [
        "coordinates",
        "text",
        "frame_width",
        "frame_height",
        "font",
        "font_size",
        "alignment",
        "text_color",
      ],
      optional: ["size_multiplier"],
    },
    output: ["IMAGE", "MASK", "MASK"],
    output_is_list: [false, false, false],
    output_name: ["image", "mask", "mask_inverted"],
    name: "CreateTextOnPath",
    display_name: "Create Text On Path",
    description:
      "\nCreates a mask or batch of masks with the specified text.\nLocations are center locations.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking/generate",
    output_node: false,
  },
  CreateGradientFromCoords: {
    input: {
      required: {
        coordinates: ["STRING", { forceInput: true }],
        frame_width: ["INT", { default: 512, min: 16, max: 4096, step: 1 }],
        frame_height: ["INT", { default: 512, min: 16, max: 4096, step: 1 }],
        start_color: ["STRING", { default: "white" }],
        end_color: ["STRING", { default: "black" }],
        multiplier: [
          "FLOAT",
          { default: 1.0, min: 0.01, max: 100.0, step: 0.01 },
        ],
      },
    },
    input_order: {
      required: [
        "coordinates",
        "frame_width",
        "frame_height",
        "start_color",
        "end_color",
        "multiplier",
      ],
    },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["image"],
    name: "CreateGradientFromCoords",
    display_name: "Create Gradient From Coords",
    description: "\nCreates a gradient image from coordinates.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/image",
    output_node: false,
  },
  GradientToFloat: {
    input: {
      required: {
        image: ["IMAGE"],
        steps: ["INT", { default: 10, min: 2, max: 10000, step: 1 }],
      },
    },
    input_order: { required: ["image", "steps"] },
    output: ["FLOAT", "FLOAT"],
    output_is_list: [false, false],
    output_name: ["float_x", "float_y"],
    name: "GradientToFloat",
    display_name: "Gradient To Float",
    description: "\nCalculates list of floats from image.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/image",
    output_node: false,
  },
  WeightScheduleExtend: {
    input: {
      required: {
        input_values_1: ["FLOAT", { default: 0.0, forceInput: true }],
        input_values_2: ["FLOAT", { default: 0.0, forceInput: true }],
        output_type: [
          ["match_input", "list", "pandas series", "tensor"],
          { default: "match_input" },
        ],
      },
    },
    input_order: {
      required: ["input_values_1", "input_values_2", "output_type"],
    },
    output: ["FLOAT"],
    output_is_list: [false],
    output_name: ["FLOAT"],
    name: "WeightScheduleExtend",
    display_name: "Weight Schedule Extend",
    description:
      "\nExtends, and converts if needed, different value lists/series\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/weights",
    output_node: false,
  },
  MaskOrImageToWeight: {
    input: {
      required: {
        output_type: [
          ["list", "pandas series", "tensor", "string"],
          { default: "list" },
        ],
      },
      optional: { images: ["IMAGE"], masks: ["MASK"] },
    },
    input_order: { required: ["output_type"], optional: ["images", "masks"] },
    output: ["FLOAT", "STRING"],
    output_is_list: [false, false],
    output_name: ["FLOAT", "STRING"],
    name: "MaskOrImageToWeight",
    display_name: "Mask Or Image To Weight",
    description:
      "\nGets the mean values from mask or image batch\nand returns that as the selected output type. \n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/weights",
    output_node: false,
  },
  WeightScheduleConvert: {
    input: {
      required: {
        input_values: ["FLOAT", { default: 0.0, forceInput: true }],
        output_type: [
          ["match_input", "list", "pandas series", "tensor"],
          { default: "list" },
        ],
        invert: ["BOOLEAN", { default: false }],
        repeat: ["INT", { default: 1, min: 1, max: 255, step: 1 }],
      },
      optional: {
        remap_to_frames: ["INT", { default: 0 }],
        interpolation_curve: ["FLOAT", { forceInput: true }],
        remap_values: ["BOOLEAN", { default: false }],
        remap_min: [
          "FLOAT",
          { default: 0.0, min: -100000, max: 100000.0, step: 0.01 },
        ],
        remap_max: [
          "FLOAT",
          { default: 1.0, min: -100000, max: 100000.0, step: 0.01 },
        ],
      },
    },
    input_order: {
      required: ["input_values", "output_type", "invert", "repeat"],
      optional: [
        "remap_to_frames",
        "interpolation_curve",
        "remap_values",
        "remap_min",
        "remap_max",
      ],
    },
    output: ["FLOAT", "STRING", "INT"],
    output_is_list: [false, false, false],
    output_name: ["FLOAT", "STRING", "INT"],
    name: "WeightScheduleConvert",
    display_name: "Weight Schedule Convert",
    description: "\nConverts different value lists/series to another type.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/weights",
    output_node: false,
  },
  FloatToMask: {
    input: {
      required: {
        input_values: ["FLOAT", { forceInput: true, default: 0 }],
        width: ["INT", { default: 100, min: 1 }],
        height: ["INT", { default: 100, min: 1 }],
      },
    },
    input_order: { required: ["input_values", "width", "height"] },
    output: ["MASK"],
    output_is_list: [false],
    output_name: ["MASK"],
    name: "FloatToMask",
    display_name: "Float To Mask",
    description:
      "\nGenerates a batch of masks based on the input float values.\nThe batch size is determined by the length of the input float values.\nEach mask is generated with the specified width and height.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/masking/generate",
    output_node: false,
  },
  FloatToSigmas: {
    input: {
      required: { float_list: ["FLOAT", { default: 0.0, forceInput: true }] },
    },
    input_order: { required: ["float_list"] },
    output: ["SIGMAS"],
    output_is_list: [false],
    output_name: ["SIGMAS"],
    name: "FloatToSigmas",
    display_name: "Float To Sigmas",
    description: "\nCreates a sigmas tensor from list of float values.\n\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/noise",
    output_node: false,
  },
  PlotCoordinates: {
    input: {
      required: {
        coordinates: ["STRING", { forceInput: true }],
        text: ["STRING", { default: "title", multiline: false }],
        width: ["INT", { default: 512, min: 8, max: 4096, step: 8 }],
        height: ["INT", { default: 512, min: 8, max: 4096, step: 8 }],
        bbox_width: ["INT", { default: 128, min: 8, max: 4096, step: 8 }],
        bbox_height: ["INT", { default: 128, min: 8, max: 4096, step: 8 }],
      },
      optional: {
        size_multiplier: ["FLOAT", { default: [1.0], forceInput: true }],
      },
    },
    input_order: {
      required: [
        "coordinates",
        "text",
        "width",
        "height",
        "bbox_width",
        "bbox_height",
      ],
      optional: ["size_multiplier"],
    },
    output: ["IMAGE", "INT", "INT", "INT", "INT"],
    output_is_list: [false, false, false, false, false],
    output_name: ["images", "width", "height", "bbox_width", "bbox_height"],
    name: "PlotCoordinates",
    display_name: "Plot Coordinates",
    description:
      "\nPlots coordinates to sequence of images using Matplotlib.\n\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/experimental",
    output_node: false,
  },
  InterpolateCoords: {
    input: {
      required: {
        coordinates: ["STRING", { forceInput: true }],
        interpolation_curve: ["FLOAT", { forceInput: true }],
      },
    },
    input_order: { required: ["coordinates", "interpolation_curve"] },
    output: ["STRING"],
    output_is_list: [false],
    output_name: ["coordinates"],
    name: "InterpolateCoords",
    display_name: "Interpolate Coords",
    description: "\nInterpolates coordinates based on a curve. \n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/experimental",
    output_node: false,
  },
  PointsEditor: {
    input: {
      required: {
        points_store: ["STRING", { multiline: false }],
        coordinates: ["STRING", { multiline: false }],
        neg_coordinates: ["STRING", { multiline: false }],
        bbox_store: ["STRING", { multiline: false }],
        bboxes: ["STRING", { multiline: false }],
        bbox_format: [["xyxy", "xywh"]],
        width: ["INT", { default: 512, min: 8, max: 4096, step: 8 }],
        height: ["INT", { default: 512, min: 8, max: 4096, step: 8 }],
        normalize: ["BOOLEAN", { default: false }],
      },
      optional: { bg_image: ["IMAGE"] },
    },
    input_order: {
      required: [
        "points_store",
        "coordinates",
        "neg_coordinates",
        "bbox_store",
        "bboxes",
        "bbox_format",
        "width",
        "height",
        "normalize",
      ],
      optional: ["bg_image"],
    },
    output: ["STRING", "STRING", "BBOX", "MASK", "IMAGE"],
    output_is_list: [false, false, false, false, false],
    output_name: [
      "positive_coords",
      "negative_coords",
      "bbox",
      "bbox_mask",
      "cropped_image",
    ],
    name: "PointsEditor",
    display_name: "Points Editor",
    description:
      "\n# WORK IN PROGRESS\nDo not count on this as part of your workflow yet,\nprobably contains lots of bugs and stability is not\nguaranteed!!\n\n## Graphical editor to create coordinates\n\n**Shift + click** to add a positive (green) point.\n**Shift + right click** to add a negative (red) point.\n**Ctrl + click** to draw a box.\n**Right click on a point** to delete it.\nNote that you can't delete from start/end of the points array.\n\nTo add an image select the node and copy/paste or drag in the image.\nOr from the bg_image input on queue (first frame of the batch).\n\n**THE IMAGE IS SAVED TO THE NODE AND WORKFLOW METADATA**\nyou can clear the image from the context menu by right clicking on the canvas\n\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/experimental",
    output_node: false,
  },
  StabilityAPI_SD3: {
    input: {
      required: {
        prompt: ["STRING", { multiline: true }],
        n_prompt: ["STRING", { multiline: true }],
        seed: ["INT", { default: 123, min: 0, max: 4294967294, step: 1 }],
        model: [["sd3", "sd3-turbo"], { default: "sd3" }],
        aspect_ratio: [
          ["1:1", "16:9", "21:9", "2:3", "3:2", "4:5", "5:4", "9:16", "9:21"],
          { default: "1:1" },
        ],
        output_format: [["png", "jpeg"], { default: "jpeg" }],
      },
      optional: {
        api_key: ["STRING", { multiline: true }],
        image: ["IMAGE"],
        img2img_strength: [
          "FLOAT",
          { default: 0.5, min: 0.0, max: 1.0, step: 0.01 },
        ],
        disable_metadata: ["BOOLEAN", { default: true }],
      },
    },
    input_order: {
      required: [
        "prompt",
        "n_prompt",
        "seed",
        "model",
        "aspect_ratio",
        "output_format",
      ],
      optional: ["api_key", "image", "img2img_strength", "disable_metadata"],
    },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "StabilityAPI_SD3",
    display_name: "Stability API SD3",
    description:
      '\n## Calls StabilityAI API\n \nAlthough you may have multiple keys in your account,\nyou should use the same key for all requests to this API.\n\nGet your API key here: https://platform.stability.ai/account/keys\nRecommended to set the key in the config.json -file under this\nnode packs folder.\n# WARNING:\nOtherwise the API key may get saved in the image metadata even\nwith "disable_metadata" on if the workflow includes save nodes\nseparate from this node.\n \nsd3 requires 6.5 credits per generation\nsd3-turbo requires 4 credits per generation\n\nIf no image is provided, mode is set to text-to-image\n\n',
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/experimental",
    output_node: false,
  },
  SoundReactive: {
    input: {
      required: {
        sound_level: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 99999, step: 0.01 },
        ],
        start_range_hz: ["INT", { default: 150, min: 0, max: 9999, step: 1 }],
        end_range_hz: ["INT", { default: 2000, min: 0, max: 9999, step: 1 }],
        multiplier: [
          "FLOAT",
          { default: 1.0, min: 0.01, max: 99999, step: 0.01 },
        ],
        smoothing_factor: [
          "FLOAT",
          { default: 0.5, min: 0.0, max: 1.0, step: 0.01 },
        ],
        normalize: ["BOOLEAN", { default: false }],
      },
    },
    input_order: {
      required: [
        "sound_level",
        "start_range_hz",
        "end_range_hz",
        "multiplier",
        "smoothing_factor",
        "normalize",
      ],
    },
    output: ["FLOAT", "INT"],
    output_is_list: [false, false],
    output_name: ["sound_level", "sound_level_int"],
    name: "SoundReactive",
    display_name: "Sound Reactive",
    description:
      "\nReacts to the sound level of the input.\nUses your browsers sound input options and requires.\nMeant to be used with realtime diffusion with autoqueue.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/audio",
    output_node: false,
  },
  StableZero123_BatchSchedule: {
    input: {
      required: {
        clip_vision: ["CLIP_VISION"],
        init_image: ["IMAGE"],
        vae: ["VAE"],
        width: ["INT", { default: 256, min: 16, max: 16384, step: 8 }],
        height: ["INT", { default: 256, min: 16, max: 16384, step: 8 }],
        batch_size: ["INT", { default: 1, min: 1, max: 4096 }],
        interpolation: [["linear", "ease_in", "ease_out", "ease_in_out"]],
        azimuth_points_string: [
          "STRING",
          { default: "0:(0.0),\n7:(1.0),\n15:(0.0)\n", multiline: true },
        ],
        elevation_points_string: [
          "STRING",
          { default: "0:(0.0),\n7:(0.0),\n15:(0.0)\n", multiline: true },
        ],
      },
    },
    input_order: {
      required: [
        "clip_vision",
        "init_image",
        "vae",
        "width",
        "height",
        "batch_size",
        "interpolation",
        "azimuth_points_string",
        "elevation_points_string",
      ],
    },
    output: ["CONDITIONING", "CONDITIONING", "LATENT"],
    output_is_list: [false, false, false],
    output_name: ["positive", "negative", "latent"],
    name: "StableZero123_BatchSchedule",
    display_name: "Stable Zero123 Batch Schedule",
    description: "",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/experimental",
    output_node: false,
  },
  SV3D_BatchSchedule: {
    input: {
      required: {
        clip_vision: ["CLIP_VISION"],
        init_image: ["IMAGE"],
        vae: ["VAE"],
        width: ["INT", { default: 576, min: 16, max: 16384, step: 8 }],
        height: ["INT", { default: 576, min: 16, max: 16384, step: 8 }],
        batch_size: ["INT", { default: 21, min: 1, max: 4096 }],
        interpolation: [["linear", "ease_in", "ease_out", "ease_in_out"]],
        azimuth_points_string: [
          "STRING",
          { default: "0:(0.0),\n9:(180.0),\n20:(360.0)\n", multiline: true },
        ],
        elevation_points_string: [
          "STRING",
          { default: "0:(0.0),\n9:(0.0),\n20:(0.0)\n", multiline: true },
        ],
      },
    },
    input_order: {
      required: [
        "clip_vision",
        "init_image",
        "vae",
        "width",
        "height",
        "batch_size",
        "interpolation",
        "azimuth_points_string",
        "elevation_points_string",
      ],
    },
    output: ["CONDITIONING", "CONDITIONING", "LATENT"],
    output_is_list: [false, false, false],
    output_name: ["positive", "negative", "latent"],
    name: "SV3D_BatchSchedule",
    display_name: "SV3D Batch Schedule",
    description:
      "\nAllow scheduling of the azimuth and elevation conditions for SV3D.\nNote that SV3D is still a video model and the schedule needs to always go forward\nhttps://huggingface.co/stabilityai/sv3d\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/experimental",
    output_node: false,
  },
  LoadResAdapterNormalization: {
    input: {
      required: {
        model: ["MODEL"],
        resadapter_path: [
          [
            "Flux\\blue_pencil-flux1-v0.1.0-nf4.safetensors",
            "Flux\\carnivalUnchained_v10.safetensors",
            "Flux\\flux1-dev-bnb-nf4-v2.safetensors",
            "Flux\\fluximation_v1NF4.safetensors",
            "Flux\\lemonmixFLUX_protoFP8.safetensors",
            "Flux\\xeHentaiAnimeFlux_04.safetensors",
            "Pony\\boleromixPony_v141VAE.safetensors",
            "Pony\\boleromixSDXL_v13.safetensors",
            "SD1.0\\anime\\RealBackground_v12.safetensors",
            "SD1.0\\anime\\akinamixBE.safetensors",
            "SD1.0\\anime\\ambientgrapemixForAnime2D_v11.ckpt",
            "SD1.0\\anime\\animeScreencapStyle_assV13.safetensors",
            "SD1.0\\anime\\coffeensfw_v10.safetensors",
            "SD1.0\\anime\\colorfulAnimeXLXL_v20.safetensors",
            "SD1.0\\anime\\yden_v20.safetensors",
            "SD1.0\\other\\chosenIrisesMix_chosenIrisesMixV10.safetensors",
            "SD1.0\\other\\fantasyBackground_v10PrunedFp16.safetensors",
            "SD1.0\\other\\idkwimixNSFW_deformedV2.safetensors",
            "SD1.0\\other\\orientalPunkMix_orientalPunkFlower.ckpt",
            "SD1.0\\other\\threeDelicacyWonton_sanxianwontonmixv1.safetensors",
            "SD1.0\\real\\Guofengrealmix_v10.safetensors",
            "SD1.0\\real\\chilledReGenericV3_v10.safetensors",
            "SD1.0\\real\\chilloutmix_NiPrunedFp32Fix.ckpt",
            "SD1.0\\real\\fantasticmix_v40.safetensors",
            "SD1.0\\real\\snapdd00_v1.safetensors",
            "SD1.0\\real\\xxmix9realistic_v25.safetensors",
            "SD1.0\\semi_real\\comiNoirClassicV2.safetensors",
            "XL\\9527DetailRealistic_v50Bakedvae.safetensors",
            "XL\\NSFWAnimexl_10.safetensors",
            "XL\\anime2.5_animeArtDiffusionXL_alpha3.safetensors",
            "XL\\anime2.5_bluePencilXL_v401.safetensors",
            "XL\\anime2.5_breakdomainxl_V06d.safetensors",
            "XL\\anime2.5_counterfeitxl_v25.safetensors",
            "XL\\anime2.5_deepblueXL_v060.safetensors",
            "XL\\anime2.5_explicitFreedomNSFW_alpha.safetensors",
            "XL\\anime2.5_himawarimix_xlV2.safetensors",
            "XL\\anime2.5_kohakuXLBeta_beta7.safetensors",
            "XL\\anime2.5_reproductionSDXL_2v12.safetensors",
            "XL\\anime2.5_yesmixXL_v10.safetensors",
            "XL\\anime_aamXLAnimeMix_v10.civitai.safetensors",
            "XL\\anime_animagineXLV3_v30.safetensors",
            "XL\\anime_hassakuXLSfwNsfwBeta_betaV04.safetensors",
            "XL\\anime_notAnimefullFinalXL_v10.safetensors",
            "XL\\anime_sdxlYamersAnimeUltra_yamersAnimeV2.safetensors",
            "XL\\baxlBlueArchiveFlatCelluloidStyleFineTune_xlv3.safetensors",
            "XL\\real_4Guofeng4XL_v10Beta.safetensors",
            "XL\\real_cherrypickerXL_v27.safetensors",
            "XL\\real_realvisxlV40_v40LightningBakedvae.safetensors",
            "XL\\real_sdvn6Realxl_detailface.safetensors",
            "XL\\real_sdxl10ArienmixxlAsian_v40Pruned.safetensors",
            "XL\\real_xxmix9realisticsdxl_v10.safetensors",
            "animatBackgroundV1_03.safetensors",
            "sd_xl_base_1.0_0.9vae.safetensors",
          ],
        ],
      },
    },
    input_order: { required: ["model", "resadapter_path"] },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "LoadResAdapterNormalization",
    display_name: "LoadResAdapterNormalization",
    description: "",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/experimental",
    output_node: false,
  },
  Superprompt: {
    input: {
      required: {
        instruction_prompt: [
          "STRING",
          {
            default: "Expand the following prompt to add more detail",
            multiline: true,
          },
        ],
        prompt: ["STRING", { default: "", multiline: true, forceInput: true }],
        max_new_tokens: ["INT", { default: 128, min: 1, max: 4096, step: 1 }],
      },
    },
    input_order: {
      required: ["instruction_prompt", "prompt", "max_new_tokens"],
    },
    output: ["STRING"],
    output_is_list: [false],
    output_name: ["STRING"],
    name: "Superprompt",
    display_name: "Superprompt",
    description:
      "\n# SuperPrompt\nA T5 model fine-tuned on the SuperPrompt dataset for\nupsampling text prompts to more detailed descriptions.\nMeant to be used as a pre-generation step for text-to-image\nmodels that benefit from more detailed prompts.\nhttps://huggingface.co/roborovski/superprompt-v1\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/text",
    output_node: false,
  },
  GLIGENTextBoxApplyBatchCoords: {
    input: {
      required: {
        conditioning_to: ["CONDITIONING"],
        latents: ["LATENT"],
        clip: ["CLIP"],
        gligen_textbox_model: ["GLIGEN"],
        coordinates: ["STRING", { forceInput: true }],
        text: ["STRING", { multiline: true }],
        width: ["INT", { default: 128, min: 8, max: 4096, step: 8 }],
        height: ["INT", { default: 128, min: 8, max: 4096, step: 8 }],
      },
      optional: {
        size_multiplier: ["FLOAT", { default: [1.0], forceInput: true }],
      },
    },
    input_order: {
      required: [
        "conditioning_to",
        "latents",
        "clip",
        "gligen_textbox_model",
        "coordinates",
        "text",
        "width",
        "height",
      ],
      optional: ["size_multiplier"],
    },
    output: ["CONDITIONING", "IMAGE"],
    output_is_list: [false, false],
    output_name: ["conditioning", "coord_preview"],
    name: "GLIGENTextBoxApplyBatchCoords",
    display_name: "GLIGENTextBoxApplyBatchCoords",
    description:
      '\nThis node allows scheduling GLIGEN text box positions in a batch,\nto be used with AnimateDiff-Evolved. Intended to pair with the\nSpline Editor -node.\n\nGLIGEN model can be downloaded through the Manage\'s "Install Models" menu.\nOr directly from here:\nhttps://huggingface.co/comfyanonymous/GLIGEN_pruned_safetensors/tree/main\n\nInputs:\n- **latents** input is used to calculate batch size\n- **clip** is your standard text encoder, use same as for the main prompt\n- **gligen_textbox_model** connects to GLIGEN Loader\n- **coordinates** takes a json string of points, directly compatible\nwith the spline editor node.\n- **text** is the part of the prompt to set position for\n- **width** and **height** are the size of the GLIGEN bounding box\n\nOutputs:\n- **conditioning** goes between to clip text encode and the sampler\n- **coord_preview** is an optional preview of the coordinates and\nbounding boxes.\n\n',
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/experimental",
    output_node: false,
  },
  Intrinsic_lora_sampling: {
    input: {
      required: {
        model: ["MODEL"],
        lora_name: [
          [
            "intrinsic_lora_sd15_albedo.safetensors",
            "intrinsic_lora_sd15_depth.safetensors",
            "intrinsic_lora_sd15_normal.safetensors",
            "intrinsic_lora_sd15_shading.safetensors",
            "intrinsic_loras.txt",
          ],
        ],
        task: [
          ["depth map", "surface normals", "albedo", "shading"],
          { default: "depth map" },
        ],
        text: ["STRING", { multiline: true, default: "" }],
        clip: ["CLIP"],
        vae: ["VAE"],
        per_batch: ["INT", { default: 16, min: 1, max: 4096, step: 1 }],
      },
      optional: { image: ["IMAGE"], optional_latent: ["LATENT"] },
    },
    input_order: {
      required: [
        "model",
        "lora_name",
        "task",
        "text",
        "clip",
        "vae",
        "per_batch",
      ],
      optional: ["image", "optional_latent"],
    },
    output: ["IMAGE", "LATENT"],
    output_is_list: [false, false],
    output_name: ["IMAGE", "LATENT"],
    name: "Intrinsic_lora_sampling",
    display_name: "Intrinsic Lora Sampling",
    description:
      "\nSampler to use the intrinsic loras:\nhttps://github.com/duxiaodan/intrinsic-lora\nThese LoRAs are tiny and thus included\nwith this node pack.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes",
    output_node: false,
  },
  CheckpointPerturbWeights: {
    input: {
      required: {
        model: ["MODEL"],
        joint_blocks: [
          "FLOAT",
          { default: 0.02, min: 0.001, max: 10.0, step: 0.001 },
        ],
        final_layer: [
          "FLOAT",
          { default: 0.02, min: 0.001, max: 10.0, step: 0.001 },
        ],
        rest_of_the_blocks: [
          "FLOAT",
          { default: 0.02, min: 0.001, max: 10.0, step: 0.001 },
        ],
        seed: [
          "INT",
          { default: 123, min: 0, max: 18446744073709551615, step: 1 },
        ],
      },
    },
    input_order: {
      required: [
        "model",
        "joint_blocks",
        "final_layer",
        "rest_of_the_blocks",
        "seed",
      ],
    },
    output: ["MODEL"],
    output_is_list: [false],
    output_name: ["MODEL"],
    name: "CheckpointPerturbWeights",
    display_name: "CheckpointPerturbWeights",
    description: "",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/experimental",
    output_node: true,
  },
  Screencap_mss: {
    input: {
      required: {
        x: ["INT", { default: 0, min: 0, max: 4096, step: 1 }],
        y: ["INT", { default: 0, min: 0, max: 4096, step: 1 }],
        width: ["INT", { default: 512, min: 0, max: 4096, step: 1 }],
        height: ["INT", { default: 512, min: 0, max: 4096, step: 1 }],
        num_frames: ["INT", { default: 1, min: 1, max: 255, step: 1 }],
        delay: ["FLOAT", { default: 0.1, min: 0.0, max: 10.0, step: 0.01 }],
      },
    },
    input_order: {
      required: ["x", "y", "width", "height", "num_frames", "delay"],
    },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["image"],
    name: "Screencap_mss",
    display_name: "Screencap mss",
    description:
      "\nCaptures an area specified by screen coordinates.\nCan be used for realtime diffusion with autoqueue.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/experimental",
    output_node: false,
  },
  WebcamCaptureCV2: {
    input: {
      required: {
        x: ["INT", { default: 0, min: 0, max: 4096, step: 1 }],
        y: ["INT", { default: 0, min: 0, max: 4096, step: 1 }],
        width: ["INT", { default: 512, min: 0, max: 4096, step: 1 }],
        height: ["INT", { default: 512, min: 0, max: 4096, step: 1 }],
        cam_index: ["INT", { default: 0, min: 0, max: 255, step: 1 }],
        release: ["BOOLEAN", { default: false }],
      },
    },
    input_order: {
      required: ["x", "y", "width", "height", "cam_index", "release"],
    },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["image"],
    name: "WebcamCaptureCV2",
    display_name: "Webcam Capture CV2",
    description:
      "\nCaptures a frame from a webcam using CV2.\nCan be used for realtime diffusion with autoqueue.\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/experimental",
    output_node: false,
  },
  CreateInstanceDiffusionTracking: {
    input: {
      required: {
        coordinates: ["STRING", { forceInput: true }],
        width: ["INT", { default: 512, min: 16, max: 4096, step: 1 }],
        height: ["INT", { default: 512, min: 16, max: 4096, step: 1 }],
        bbox_width: ["INT", { default: 512, min: 16, max: 4096, step: 1 }],
        bbox_height: ["INT", { default: 512, min: 16, max: 4096, step: 1 }],
        class_name: ["STRING", { default: "class_name" }],
        class_id: ["INT", { default: 0, min: 0, max: 255, step: 1 }],
        prompt: ["STRING", { default: "prompt", multiline: true }],
      },
      optional: {
        size_multiplier: ["FLOAT", { default: [1.0], forceInput: true }],
        fit_in_frame: ["BOOLEAN", { default: true }],
      },
    },
    input_order: {
      required: [
        "coordinates",
        "width",
        "height",
        "bbox_width",
        "bbox_height",
        "class_name",
        "class_id",
        "prompt",
      ],
      optional: ["size_multiplier", "fit_in_frame"],
    },
    output: ["TRACKING", "STRING", "INT", "INT", "INT", "INT"],
    output_is_list: [false, false, false, false, false, false],
    output_name: [
      "tracking",
      "prompt",
      "width",
      "height",
      "bbox_width",
      "bbox_height",
    ],
    name: "CreateInstanceDiffusionTracking",
    display_name: "CreateInstanceDiffusionTracking",
    description:
      '\nCreates tracking data to be used with InstanceDiffusion:\nhttps://github.com/logtd/ComfyUI-InstanceDiffusion\n\nInstanceDiffusion prompt format:\n"class_id.class_name": "prompt",\nfor example:\n"1.head": "((head))",\n',
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/InstanceDiffusion",
    output_node: false,
  },
  AppendInstanceDiffusionTracking: {
    input: {
      required: {
        tracking_1: ["TRACKING", { forceInput: true }],
        tracking_2: ["TRACKING", { forceInput: true }],
      },
      optional: {
        prompt_1: ["STRING", { default: "", forceInput: true }],
        prompt_2: ["STRING", { default: "", forceInput: true }],
      },
    },
    input_order: {
      required: ["tracking_1", "tracking_2"],
      optional: ["prompt_1", "prompt_2"],
    },
    output: ["TRACKING", "STRING"],
    output_is_list: [false, false],
    output_name: ["tracking", "prompt"],
    name: "AppendInstanceDiffusionTracking",
    display_name: "AppendInstanceDiffusionTracking",
    description:
      "\nAppends tracking data to be used with InstanceDiffusion:\nhttps://github.com/logtd/ComfyUI-InstanceDiffusion\n\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/InstanceDiffusion",
    output_node: false,
  },
  DrawInstanceDiffusionTracking: {
    input: {
      required: {
        image: ["IMAGE"],
        tracking: ["TRACKING", { forceInput: true }],
        box_line_width: ["INT", { default: 2, min: 1, max: 10, step: 1 }],
        draw_text: ["BOOLEAN", { default: true }],
        font: [
          ["FreeMono.ttf", "FreeMonoBoldOblique.otf", "TTNorms-Black.otf"],
        ],
        font_size: ["INT", { default: 20 }],
      },
    },
    input_order: {
      required: [
        "image",
        "tracking",
        "box_line_width",
        "draw_text",
        "font",
        "font_size",
      ],
    },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["image"],
    name: "DrawInstanceDiffusionTracking",
    display_name: "DrawInstanceDiffusionTracking",
    description:
      "\nDraws the tracking data from\nCreateInstanceDiffusionTracking -node.\n\n",
    python_module: "custom_nodes.ComfyUI-KJNodes",
    category: "KJNodes/InstanceDiffusion",
    output_node: false,
  },
  DownloadAndLoadSAM2Model: {
    input: {
      required: {
        model: [
          [
            "sam2_hiera_base_plus.safetensors",
            "sam2_hiera_large.safetensors",
            "sam2_hiera_small.safetensors",
            "sam2_hiera_tiny.safetensors",
          ],
        ],
        segmentor: [["single_image", "video", "automaskgenerator"]],
        device: [["cuda", "cpu", "mps"]],
        precision: [["fp16", "bf16", "fp32"], { default: "bf16" }],
      },
    },
    input_order: { required: ["model", "segmentor", "device", "precision"] },
    output: ["SAM2MODEL"],
    output_is_list: [false],
    output_name: ["sam2_model"],
    name: "DownloadAndLoadSAM2Model",
    display_name: "(Down)Load SAM2Model",
    description: "",
    python_module: "custom_nodes.ComfyUI-segment-anything-2",
    category: "SAM2",
    output_node: false,
  },
  Sam2Segmentation: {
    input: {
      required: {
        sam2_model: ["SAM2MODEL"],
        image: ["IMAGE"],
        keep_model_loaded: ["BOOLEAN", { default: true }],
      },
      optional: {
        coordinates_positive: ["STRING", { forceInput: true }],
        coordinates_negative: ["STRING", { forceInput: true }],
        bboxes: ["BBOX"],
        individual_objects: ["BOOLEAN", { default: false }],
        mask: ["MASK"],
      },
    },
    input_order: {
      required: ["sam2_model", "image", "keep_model_loaded"],
      optional: [
        "coordinates_positive",
        "coordinates_negative",
        "bboxes",
        "individual_objects",
        "mask",
      ],
    },
    output: ["MASK"],
    output_is_list: [false],
    output_name: ["mask"],
    name: "Sam2Segmentation",
    display_name: "Sam2Segmentation",
    description: "",
    python_module: "custom_nodes.ComfyUI-segment-anything-2",
    category: "SAM2",
    output_node: false,
  },
  Florence2toCoordinates: {
    input: {
      required: {
        data: ["JSON"],
        index: ["STRING", { default: "0" }],
        batch: ["BOOLEAN", { default: false }],
      },
    },
    input_order: { required: ["data", "index", "batch"] },
    output: ["STRING", "BBOX"],
    output_is_list: [false, false],
    output_name: ["center_coordinates", "bboxes"],
    name: "Florence2toCoordinates",
    display_name: "Florence2 Coordinates",
    description: "",
    python_module: "custom_nodes.ComfyUI-segment-anything-2",
    category: "SAM2",
    output_node: false,
  },
  Sam2AutoSegmentation: {
    input: {
      required: {
        sam2_model: ["SAM2MODEL"],
        image: ["IMAGE"],
        points_per_side: ["INT", { default: 32 }],
        points_per_batch: ["INT", { default: 64 }],
        pred_iou_thresh: [
          "FLOAT",
          { default: 0.8, min: 0.0, max: 1.0, step: 0.01 },
        ],
        stability_score_thresh: [
          "FLOAT",
          { default: 0.95, min: 0.0, max: 1.0, step: 0.01 },
        ],
        stability_score_offset: [
          "FLOAT",
          { default: 1.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        mask_threshold: [
          "FLOAT",
          { default: 0.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        crop_n_layers: ["INT", { default: 0 }],
        box_nms_thresh: [
          "FLOAT",
          { default: 0.7, min: 0.0, max: 1.0, step: 0.01 },
        ],
        crop_nms_thresh: [
          "FLOAT",
          { default: 0.7, min: 0.0, max: 1.0, step: 0.01 },
        ],
        crop_overlap_ratio: [
          "FLOAT",
          { default: 0.34, min: 0.0, max: 1.0, step: 0.01 },
        ],
        crop_n_points_downscale_factor: ["INT", { default: 1 }],
        min_mask_region_area: [
          "FLOAT",
          { default: 0.0, min: 0.0, max: 1.0, step: 0.01 },
        ],
        use_m2m: ["BOOLEAN", { default: false }],
        keep_model_loaded: ["BOOLEAN", { default: true }],
      },
    },
    input_order: {
      required: [
        "sam2_model",
        "image",
        "points_per_side",
        "points_per_batch",
        "pred_iou_thresh",
        "stability_score_thresh",
        "stability_score_offset",
        "mask_threshold",
        "crop_n_layers",
        "box_nms_thresh",
        "crop_nms_thresh",
        "crop_overlap_ratio",
        "crop_n_points_downscale_factor",
        "min_mask_region_area",
        "use_m2m",
        "keep_model_loaded",
      ],
    },
    output: ["MASK", "IMAGE", "BBOX"],
    output_is_list: [false, false, false],
    output_name: ["mask", "segmented_image", "bbox"],
    name: "Sam2AutoSegmentation",
    display_name: "Sam2AutoSegmentation",
    description: "",
    python_module: "custom_nodes.ComfyUI-segment-anything-2",
    category: "SAM2",
    output_node: false,
  },
  Sam2VideoSegmentationAddPoints: {
    input: {
      required: {
        sam2_model: ["SAM2MODEL"],
        coordinates_positive: ["STRING", { forceInput: true }],
        frame_index: ["INT", { default: 0 }],
        object_index: ["INT", { default: 0 }],
      },
      optional: {
        image: ["IMAGE"],
        coordinates_negative: ["STRING", { forceInput: true }],
        prev_inference_state: ["SAM2INFERENCESTATE"],
      },
    },
    input_order: {
      required: [
        "sam2_model",
        "coordinates_positive",
        "frame_index",
        "object_index",
      ],
      optional: ["image", "coordinates_negative", "prev_inference_state"],
    },
    output: ["SAM2MODEL", "SAM2INFERENCESTATE"],
    output_is_list: [false, false],
    output_name: ["sam2_model", "inference_state"],
    name: "Sam2VideoSegmentationAddPoints",
    display_name: "Sam2VideoSegmentationAddPoints",
    description: "",
    python_module: "custom_nodes.ComfyUI-segment-anything-2",
    category: "SAM2",
    output_node: false,
  },
  Sam2VideoSegmentation: {
    input: {
      required: {
        sam2_model: ["SAM2MODEL"],
        inference_state: ["SAM2INFERENCESTATE"],
        keep_model_loaded: ["BOOLEAN", { default: true }],
      },
    },
    input_order: {
      required: ["sam2_model", "inference_state", "keep_model_loaded"],
    },
    output: ["MASK"],
    output_is_list: [false],
    output_name: ["mask"],
    name: "Sam2VideoSegmentation",
    display_name: "Sam2VideoSegmentation",
    description: "",
    python_module: "custom_nodes.ComfyUI-segment-anything-2",
    category: "SAM2",
    output_node: false,
  },
  ChannelSelector: {
    input: {
      required: {
        image: ["IMAGE"],
        channel: [
          "INT",
          { default: 0, min: 0, max: 100, step: 1, display: "number" },
        ],
      },
    },
    input_order: { required: ["image", "channel"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "ChannelSelector",
    display_name: "ChannelSelector",
    description: "",
    python_module: "custom_nodes.comfyui-tensorops",
    category: "tensorops",
    output_node: false,
  },
  MaskImage: {
    input: { required: { image: ["IMAGE"], mask: ["MASK"] } },
    input_order: { required: ["image", "mask"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "MaskImage",
    display_name: "MaskImage",
    description: "",
    python_module: "custom_nodes.comfyui-tensorops",
    category: "tensorops",
    output_node: false,
  },
  SaveImageToS3: {
    input: {
      required: {
        database: ["STRING", { multiline: false }],
        key: ["STRING", { multiline: false }],
        image: ["IMAGE"],
      },
    },
    input_order: { required: ["database", "key", "image"] },
    output: [],
    output_is_list: [],
    output_name: [],
    name: "SaveImageToS3",
    display_name: "SaveImageToS3",
    description: "",
    python_module: "custom_nodes.comfyui-tensorops",
    category: "database_ops",
    output_node: true,
  },
  SaveJsonToSurreal: {
    input: {
      required: {
        database: ["STRING", { multiline: false }],
        json: ["JSON"],
        id: ["STRING", { multiline: false }],
        key: ["STRING", { multiline: false }],
      },
    },
    input_order: { required: ["database", "json", "id", "key"] },
    output: [],
    output_is_list: [],
    output_name: [],
    name: "SaveJsonToSurreal",
    display_name: "SaveJsonToSurreal",
    description: "",
    python_module: "custom_nodes.comfyui-tensorops",
    category: "database_ops",
    output_node: true,
  },
  SaveTextToSurreal: {
    input: {
      required: {
        database: ["STRING", { multiline: false }],
        text: ["STRING", { forceInput: true }],
        id: ["STRING", { multiline: false }],
        key: ["STRING", { multiline: false }],
      },
    },
    input_order: { required: ["database", "text", "id", "key"] },
    output: [],
    output_is_list: [],
    output_name: [],
    name: "SaveTextToSurreal",
    display_name: "SaveTextToSurreal",
    description: "",
    python_module: "custom_nodes.comfyui-tensorops",
    category: "database_ops",
    output_node: true,
  },
  FetchJsonFromSurreal: {
    input: {
      required: {
        database: ["STRING", { multiline: false }],
        id: ["STRING", { multiline: false }],
        key: ["STRING", { multiline: false }],
      },
    },
    input_order: { required: ["database", "id", "key"] },
    output: ["JSON"],
    output_is_list: [false],
    output_name: ["JSON"],
    name: "FetchJsonFromSurreal",
    display_name: "FetchJsonFromSurreal",
    description: "",
    python_module: "custom_nodes.comfyui-tensorops",
    category: "database_ops",
    output_node: true,
  },
  ForegroundMask: {
    input: { required: { image: ["IMAGE"], json_data: ["JSON"] } },
    input_order: { required: ["image", "json_data"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "ForegroundMask",
    display_name: "ForegroundMask",
    description: "",
    python_module: "custom_nodes.comfyui-tensorops",
    category: "tensorops",
    output_node: false,
  },
  SaveToRedis: {
    input: {
      required: { key: ["STRING", { multiline: false }], data: ["JSON"] },
    },
    input_order: { required: ["key", "data"] },
    output: [],
    output_is_list: [],
    output_name: [],
    name: "SaveToRedis",
    display_name: "SaveToRedis",
    description: "",
    python_module: "custom_nodes.comfyui-tensorops",
    category: "database_ops",
    output_node: true,
  },
  FetchFromRedis: {
    input: { required: { key: ["STRING", { multiline: false }] } },
    input_order: { required: ["key"] },
    output: ["JSON"],
    output_is_list: [false],
    output_name: ["JSON"],
    name: "FetchFromRedis",
    display_name: "FetchFromRedis",
    description: "",
    python_module: "custom_nodes.comfyui-tensorops",
    category: "database_ops",
    output_node: true,
  },
  "Image Remove Background (rembg)": {
    input: { required: { image: ["IMAGE"] } },
    input_order: { required: ["image"] },
    output: ["IMAGE"],
    output_is_list: [false],
    output_name: ["IMAGE"],
    name: "Image Remove Background (rembg)",
    display_name: "Image Remove Background (rembg)",
    description: "",
    python_module: "custom_nodes.rembg-comfyui-node",
    category: "image",
    output_node: false,
  },
  SaveImageWebsocket: {
    input: { required: { images: ["IMAGE"] } },
    input_order: { required: ["images"] },
    output: [],
    output_is_list: [],
    output_name: [],
    name: "SaveImageWebsocket",
    display_name: "SaveImageWebsocket",
    description: "",
    python_module: "custom_nodes.websocket_image_save",
    category: "api/image",
    output_node: true,
  },
};
